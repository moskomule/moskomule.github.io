<!doctype html><html lang=ja><head><meta name=generator content="Hugo 0.124.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="chrome=1"><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer"><meta name=description content="..."><title>...
</title><link href=/ja/index.xml rel=alternate type=application/rss+xml title=...><meta property="og:title" content="&mldr;"><meta property="og:type" content="website"><meta property="og:description" content="..."><meta property="og:url" content="https://hataya.tokyo/ja/"><meta property="og:site_name" content="&mldr;"><meta property="og:image" content="https://hataya.tokyo/home/bird.png"><meta property="og:image" content="https://hataya.tokyo/home/prague.png"><meta property="og:image" content="https://hataya.tokyo/ja/home/profile.png"><link rel="shortcut icon" href=/img/fav.ico><link rel=stylesheet href=/css/main.min.36f9d8263432beffbd6094f57fb28719ed0c231274aff928d0a0f8820a88d26f.css integrity="sha256-NvnYJjQyvv+9YJT1f7KHGe0MIxJ0r/ko0KD4ggqI0m8=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/custom.css integrity crossorigin=anonymous media=screen><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],macros:{argmax:"\\DeclareMathOperator*{\\argmax}{argmax}",argmin:"\\DeclareMathOperator*{\\argmin}{argmin}"},tags:"ams"}}</script><link rel=stylesheet href=https://hataya.tokyo/styles/owlCarousel.min.b1f26e29c43c61fe8b5a6f225b4ee7c5f969a7b33cfe512706271e07246d93d1.css integrity="sha256-sfJuKcQ8Yf6LWm8iW07nxflpp7M8/lEnBiceByRtk9E=" crossorigin=anonymous media=screen></head><body><section id=top class="hero is-medium"><div class=hero-head></div><div class=hero-body><div class="container has-text-centered"><h1 class=bold-title>Hello World!</h1><div class="subtitle is-3"><p>å¹¡è°·é¾ä¸€éƒã®ãƒšãƒ¼ã‚¸ã§ã™</p></div><div><div class=social-icons><a href=https://github.com/moskomule><i class="fab fab fa-github"></i>
</a><a href=https://www.linkedin.com/in/ryuichiro-hataya-7940a1125><i class="fab fab fa-linkedin"></i>
</a><a href="https://scholar.google.com/citations?user=84l6KcEAAAAJ"><i class="fas fab fa-graduation-cap"></i></a></div></div></div></div><div class=hero-foot><div class=container><hr><nav class=navbar role=navigation aria-label="main navigation"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a><div class="navbar-menu has-content-centered" id=navMenu><a class=navbar-item href=#about>ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«</a>
<a class=navbar-item href=/ja/#%E7%A0%94%E7%A9%B6%E6%A6%82%E8%A6%81>ç ”ç©¶æ¦‚è¦</a>
<a class=navbar-item href=/ja/#%E8%A8%98%E4%BA%8B>è¨˜äº‹</a>
<a class=navbar-item href=#publications>è«–æ–‡ãªã©</a>
<a class=navbar-item href=#activities>ç ”ç©¶æ´»å‹•</a>
<a class=navbar-item href=#contact>Contact</a>
<a class=navbar-item href=https://hataya.tokyo/>English</a></div></nav><hr></div></div></section><div class=section id=about><div class=container><h2 class="title is-2 has-text-centered">ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«</h2><div class=columns><div class="column is-one-third has-text-centered"><img class="img-responsive avatar" src=https://hataya.tokyo/ja/home/profile_hu3f81d9e12a1296f5cf2539942e44e89a_596626_320x0_resize_box_3.png alt=profile.png></div><div class="markdown column"><p>å¹¡è°·é¾ä¸€éƒã§ã™ï¼ˆåšå£«ï¼ˆæƒ…å ±ç†å·¥å­¦ï¼‰ï¼‰ã€‚</p><ul><li>ç‰¹åˆ¥ç ”ç©¶å“¡ï¼ˆç†åŒ–å­¦ç ”ç©¶æ‰€é©æ–°çŸ¥èƒ½çµ±åˆç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼é«˜æ¬¡å…ƒå› æœè§£æãƒãƒ¼ãƒ ï¼‰</li></ul><h3 id=news class=anchor-link><a href=#news>News</a></h3><h4 id=2024 class=anchor-link><a href=#2024>2024</a></h4><ul><li>CENTAIğŸ‡®ğŸ‡¹ã‚’è¨ªå•ã—ã¾ã™ï¼</li><li>ICMLã«å‚åŠ ã—ã¾ã™ğŸ‡¦ğŸ‡¹ï¼</li><li>Aix-Marseiileå¤§å­¦ğŸ‡«ğŸ‡·ã‚’è¨ªå•ã—ã¾ã™ï¼</li><li>A*STAR-CFARã«æ»åœ¨ã—ï¼Œ<a href=/ja/>A*STAR-CFAR_RIKEN-AIP Workshop </a>ã«å‚åŠ ã—ã¾ã™ï¼</li><li><a href=https://zappingseminar.connpass.com/event/320972/>Zapping seminar</a> ã«ãŠã„ã¦æ‹›å¾…è¬›æ¼” &ldquo;Automatic Domain Adaptation by Transformers in In-Context Learning&rdquo; ã‚’è¡Œã„ã¾ã™ï¼</li><li><a href=https://aip.riken.jp/events/event_172747/>RIKEN-IIT Joint Workshop in ML/AI</a>ã«å‚åŠ ã—ã¾ã™ï¼</li><li>äº¬éƒ½å¤§å­¦ãƒ»åŒ…ã•ã‚“ã¨ã®å…±è‘—è«–æ–‡ &ldquo;Self-attention Networks Localize When QK-eigenspectrum Concentrates&rdquo; ãŒICMLã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼</li><li>ECCV 2024ã«ãŠã„ã¦ï¼Œãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ— <a href=https://sites.google.com/view/darksideofgenaiandbeyond>&ldquo;The Dark Side of Generative AIs and Beyond&rdquo;</a> ã‚’é–‹å‚¬ã—ã¾ã™ï¼</li></ul><details><summary>æ˜”ã®è©±</summary><ul><li>ç ”ç©¶èª²é¡ŒãŒæ±äº¬å¤§å­¦æƒ…å ±åŸºç›¤ã‚»ãƒ³ã‚¿ãƒ¼ã€€è‹¥æ‰‹ãƒ»å¥³æ€§åˆ©ç”¨è€…æ¨è–¦ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼</li><li>ç ”ç©¶èª²é¡ŒãŒJST ACT-Xæ•°ç†æƒ…å ±ã®ãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢é ˜åŸŸã®åŠ é€Ÿãƒ•ã‚§ãƒ¼ã‚ºã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼</li><li><a href=https://ismseminar.github.io/fimi2024/>Workshop on Functional Inference and Machine Intelligence</a>ã«å‚åŠ ã—ã¾ã™ï¼</li><li><a href=https://sites.google.com/view/dl2024/>DL 2024</a>ã«å‚åŠ ã—ã¾ã™ï¼</li><li><a href=https://groups.oist.jp/mlss/>Machine Learning Summer School Okinawa</a>ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒ å§”å“¡ã¨ã—ã¦å‚åŠ ã—ã¾ã™ï¼</li><li><a href=https://ibisml.org/ibisml053>ç¬¬53å›IBISMLç ”ç©¶ä¼š</a>ã«ãŠã„ã¦æ‹›å¾…è¬›æ¼”ã€Œå‹¾é…æ³•ã‚’ç”¨ã„ãŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã€ã‚’è¡Œã„ã¾ã™ï¼</li><li><a href="https://docs.google.com/forms/d/e/1FAIpQLSdS2RB1mkBL9S2F-CnOT8aYqMOSLr9INfolbmosAbRsRGYK8A/viewform?vc=0&c=0&w=1&flr=0&pli=1">çµ±æ•°ç ”å…±åŒç ”ç©¶é›†ä¼š å…¼ ç¬¬4å›TREFOILç ”ç©¶ä¼š</a>ã§æ‹›å¾…è¬›æ¼”ã€Œæ·±å±¤å­¦ç¿’ã¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€ã‚’è¡Œã„ã¾ã™ï¼</li></ul><h4 id=2023 class=anchor-link><a href=#2023>2023</a></h4><ul><li>å›½ç«‹ãŒã‚“ç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼ãƒ»å°æ—ã•ã‚“ã¨ã®å…±è‘—è«–æ–‡ &ldquo;Sketch-based Semantic Retrieval of Medical Images&rdquo; ãŒMedical Image AnalysisèªŒã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼<a href=https://www.ncc.go.jp/jp/information/researchtopics/2023/1222/index.html>ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹</a>ï¼</li><li>ã‚¹ã‚¤ã‚¹ã®ã‚¸ãƒ¥ãƒãƒ¼ãƒ–ã§é–‹å‚¬ã•ã‚Œã‚‹<a href=https://qtml-2023.web.cern.ch/>QTML 2023</a>ã«ãŠã„ã¦"Non-commutative $C^\ast$-algebra Net"ã‚’ç™ºè¡¨ã—ã¾ã™ï¼</li><li>ãƒ¢ãƒ³ãƒˆãƒªã‚ªãƒ¼ãƒ«å¤§/MILAãƒ»é•·æ²¼ã•ã‚“ã¨ã®å…±è‘—è«–æ–‡ &ldquo;An Empirical Investigation of Pre-trained Model Selection for Out-of-Distribution Generalization and Calibration&rdquo; ãŒICCV 2023 Workshop on Uncertainty Quantification for Computer Visionã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼</li><li>9æœˆæœ«ã«ãƒãƒ¼ãƒ©ãƒ³ãƒ‰ã®ãƒ‹ã‚³ãƒ©ã‚¦ã‚¹ï½¥ã‚³ãƒšãƒ«ãƒ‹ã‚¯ã‚¹å¤§å­¦ã‚’è¨ªå•ã—ã¾ã™ï¼</li><li>ä¸»è‘—è«–æ–‡ &ldquo;Will Large-scale Generative Models Corrupt Future Datasets?&rdquo; ãŒICCV 2023ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼äº¬å¤§ãƒ»åŒ…ã•ã‚“ï¼Œç†ç ”ãƒ»è’äº•ã•ã‚“ã¨ã®å…±è‘—ã§ã™ï¼</li><li>å›½ç«‹ãŒã‚“ç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼ãƒ»å°æ—ã•ã‚“ã¨ã®å…±è‘—è«–æ–‡ &ldquo;Towards AI-driven radiology education: A self-supervised segmentation-based framework for high-precision medical image editing&rdquo; ãŒMICCAI2023ã«ã‚ªãƒ¼ãƒ©ãƒ«ã¨ã—ã¦æ¡æŠã•ã‚Œã¾ã—ãŸï¼</li><li>6æœˆã«ãƒ¢ãƒ³ãƒˆãƒªã‚ªãƒ¼ãƒ«ã®MILAã‚’è¨ªå•ã—ã¾ã™ï¼ãƒãƒ³ã‚¯ãƒ¼ãƒãƒ¼ã§é–‹å‚¬ã•ã‚Œã‚‹CVPRã«å‚åŠ ã—ã¾ã™ï¼</li><li>æ±äº¬å¤§å­¦ç´ ç²’å­ç‰©ç†å›½éš›ç ”ç©¶ã‚»ãƒ³ã‚¿ãƒ¼ã§æ‹›å¾…è¬›æ¼”ã‚’è¡Œã„ã¾ã™ï¼</li><li>5æœˆã«ã‚¸ã‚§ãƒãƒã®IITã‚’è¨ªå•ã—ã¾ã™ï¼</li><li>AISTATSã«å‚åŠ ã—ã¾ã™ï¼</li><li>4æœˆã«Vietnam Institute for Advanced Study in Mathematicsã‚’è¨ªå•ã—ã¾ã™ï¼</li><li>3æœˆã«EPFL CISãƒ»Fraunhofer IISã‚’è¨ªå•ã—ã¾ã™ï¼</li><li>ç¬¬4å›ç†ç ”AIPæ•°å­¦ç³»åˆåŒã‚»ãƒŸãƒŠãƒ¼ã«å‚åŠ ã—ã¾ã—ãŸï¼</li><li>ä¸»è‘—è«–æ–‡ &ldquo;NystrÃ¶m Method for Accurate and Scalable Implicit Differentiation&rdquo; ãŒAISTATS 2023ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼äº¬å¤§ãƒ»å±±ç”°å…ˆç”Ÿã¨ã®å…±è‘—ã§ã™ï¼</li></ul><h4 id=2022 class=anchor-link><a href=#2022>2022</a></h4><ul><li>ç†åŒ–å­¦ç ”ç©¶æ‰€ã®ç‰¹åˆ¥ç ”ç©¶å“¡ã¨ãªã‚Šã¾ã—ãŸï¼</li><li>æ±äº¬å¤§å­¦å¤§å­¦é™¢æƒ…å ±ç†å·¥å­¦ç³»ç ”ç©¶ç§‘ã‚’ä¿®äº†ã—ã€åšå£«ï¼ˆæƒ…å ±ç†å·¥å­¦ï¼‰ã‚’æˆä¸ã•ã‚Œã¾ã—ãŸï¼</li><li>7æœˆ8æ—¥ã‹ã‚‰IIT(ã‚¤ã‚¿ãƒªã‚¢)ã‚’è¨ªå•ã—ã¾ã™ï¼</li><li>ä¸»è‘—è«–æ–‡ &ldquo;DJMix: Unsupervised Task-agnostic Image Augmentation for Improving Robustness of Convolutional Neural Networks
" ãŒIJCNN 2022ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼</li><li>3æœˆ10æ—¥ã«<a href=https://zappingseminar.connpass.com/event/239765/>ã‚¶ãƒƒãƒ”ãƒ³ã‚°ã‚»ãƒŸãƒŠãƒ¼</a>ã«ãŠã„ã¦ç™ºè¡¨ã‚’è¡Œã„ã¾ã™ï¼</li></ul><h4 id=2021 class=anchor-link><a href=#2021>2021</a></h4><ul><li>12æœˆ2æ—¥ã«æ„›åª›å¤§å­¦DSç ”ç©¶ã‚»ãƒŸãƒŠãƒ¼ã«ãŠã„ã¦ <a href=https://www.cdse.ehime-u.ac.jp/>æ·±å±¤å­¦ç¿’ã¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ</a> ã‚’ç™ºè¡¨ã—ã¾ã™ï¼</li><li>10æœˆ1æ—¥ã‹ã‚‰IITï¼ˆã‚¤ã‚¿ãƒªã‚¢ï¼‰ã‚’è¨ªå•ã—ã¦ã„ã¾ã™.</li><li>ä¸»è‘—è«–æ–‡ &ldquo;Meta Approach to Data Augmentation Optimization"ãŒWACV2022ã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼</li><li>ç ”ç©¶ææ¡ˆãŒJSTã®ACT-Xã«æ¡æŠã•ã‚Œã¾ã—ãŸï¼</li><li>JSPSã®è‹¥æ‰‹ç ”ç©¶è€…æµ·å¤–æŒ‘æˆ¦ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«ã‚ˆã‚Š10æœˆã‹ã‚‰ã‚¤ã‚¿ãƒªã‚¢ã®IITã«ã¦è¨ªå•ç ”ç©¶ã‚’è¡Œã„ã¾ã™ï¼</li><li>ç”»åƒã®èªè­˜ãƒ»ç†è§£ã‚·ãƒ³ãƒã‚¸ã‚¦ãƒ ï¼ˆMIRUï¼‰ã§ã€ŒiMADAO: ç”»åƒäº‹ä¾‹ã«å¿œã˜ãŸãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥ã®è¨­è¨ˆæ‰‹æ³•ã€ã‚’ç™ºè¡¨ã—ã¾ã—ãŸï¼</li><li><a href=https://neurips.cc/Conferences/2021/CallForMeetups>NeurIPS meetups</a>ã®å‹Ÿé›†ã‚’é–‹å§‹ã—ã¾ã—ãŸï¼</li><li>æ±äº¬å¤§å­¦RIISEã®<a href=https://www.riise.u-tokyo.ac.jp/news-vxe-interview-hataya/>å–æè¨˜äº‹</a>ãŒå…¬é–‹ã•ã‚Œã¾ã—ãŸ</li><li>6æœˆ10æ—¥ã«SSIIã®ã‚ªãƒ¼ã‚¬ãƒŠã‚¤ã‚ºåœŸã‚»ãƒƒã‚·ãƒ§ãƒ³<a href="https://confit.atlas.jp/guide/event/ssii2021/subject/OS2-03/category?cryptoId=">ã€Œç¶šãƒ»é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®æ·±å±¤å­¦ç¿’ã€ã§ã€Œæ·±å±¤å­¦ç¿’ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®åŸç†ã¨æœ€æ–°å‹•å‘ã€</a>ã‚’ç™ºè¡¨ã—ã¾ã™</li><li>5æœˆ12æ—¥ã«ç†ç ”AIPã®ã‚»ãƒŸãƒŠãƒ¼ã«ãŠã„ã¦<a href=https://c5dc59ed978213830355fc8978.doorkeeper.jp/events/115877>ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã«ã¤ã„ã¦ã®ç™ºè¡¨</a>ã‚’è¡Œã„ã¾ã™ï¼ˆç™ºè¡¨ã¯è‹±èªã§ã™ï¼‰ï¼</li><li>ä¸»è‘—è«–æ–‡ <a href="https://openreview.net/forum?id=I2AD-xWJ2-J">&ldquo;Graph Energy-based Model for Molecular Graph Generation&rdquo;</a>ãŒEBM Workshopã«contributed talkã¨ã—ã¦æ¡æŠã•ã‚Œã¾ã—ãŸ</li><li>NeurIPS 2021ã®Meetup Chairã¨ãªã‚Šã¾ã—ãŸ</li></ul></details></div></div></div><div class="container has-text-centered top-pad"><a href=#top><i class="fa fa-arrow-up"></i></a></div></div><div class=container><hr></div><div class=section id=%E7%A0%94%E7%A9%B6%E6%A6%82%E8%A6%81><div class=container><h2 class="title is-2 has-text-centered">ç ”ç©¶æ¦‚è¦</h2><div class=section><div class="columns is-multiline"></div></div></div><div class="container has-text-centered top-pad"><a href=#top><i class="fa fa-arrow-up"></i></a></div></div><div class=container><hr></div><div class=section id=%E8%A8%98%E4%BA%8B><div class=container><h2 class="title is-2 has-text-centered">æœ€æ–°ã®è¨˜äº‹</h2><div class=summary>Jul 15, 2023<h3 class="title is-3 latest-post-title"><a href=https://hataya.tokyo/ja/blog/iccv2023_ja/>é«˜å“è³ªãªç”Ÿæˆç”»åƒã¯å°†æ¥ã®ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³ã«æ‚ªå½±éŸ¿ã‚’ä¸ãˆã‚‹ã®ã‹</a></h3><div class=markdown>æ˜¨ä»Šï¼Œæ–‡ç« ã‹ã‚‰ç”»åƒã‚’ç”Ÿæˆã™ã‚‹StableDiffusionã‚„Midjourneyã‚’ã¯ã˜ã‚ã¨ã™ã‚‹é«˜å“è³ªãªï¼ˆtext2imgï¼‰ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ãŒæ¬¡ã€…ã«ç™»å ´ã—ï¼Œå®Ÿéš›ã®ç”»åƒã¨åŒºåˆ¥ã®ä»˜ã‹ãªã„ã‚ˆã†ãªç”Ÿæˆç”»åƒãŒå¤šé‡ã«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã™ 1ï¼ ã“ã®ã‚ˆã†ãªç¾è±¡ã¯ï¼Œå°†æ¥çš„ã«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã‹ã‚‰ç”»åƒã‚’åé›†ã—ï¼Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ãŸå ´åˆã«ï¼Œç”»åƒèªè­˜ã‚’ã¯ã˜ã‚ã¨ã™ã‚‹ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ãƒ“ã‚¸ãƒ§ãƒ³ã«å¯¾ã—ã¦ã©ã®ã‚ˆã†ãªå½±éŸ¿ãŒã‚ã‚‹ã®ã§ã—ã‚‡ã†ã‹2ï¼Ÿ
<a href=https://hataya.tokyo/ja/blog/iccv2023_ja/>ã¤ã¥ãã‚’èª­ã‚€</a></div></div></div></div><div class="container has-text-centered top-pad"><a href=https://hataya.tokyo/ja/blog/>å…¨è¨˜äº‹</a></div><div class="container has-text-centered top-pad"><a href=#top><i class="fa fa-arrow-up"></i></a></div><div class=container><hr></div><div class=section id=publications><div class=container><h2 class="title is-2 has-text-centered">è«–æ–‡ãªã©</h2><div class=columns><div class="column is-one-third has-text-centered"><img class="img-responsive avatar" src=https://hataya.tokyo/home/bird_hu90fba32c573027ee130a110cc35684ea_562092_320x0_resize_box_3.png alt=bird.png></div><div class="markdown column"><h4 id=åŸè‘—è«–æ–‡ class=anchor-link><a href=#%e5%8e%9f%e8%91%97%e8%ab%96%e6%96%87>åŸè‘—è«–æ–‡</a></h4><ul><li>Kazuma Kobayashi, Lin Gu, <strong>Ryuichiro Hataya</strong>, Takaaki Mizuno, Mototaka Miyake, Hirokazu Watanabe, Masamichi Takahashi, Yasuyuki Takamizawa, Yukihiro Yoshida, Satoshi Nakamura, Nobuji Kouno, Amina Bolatkan, Yusuke Kurose, Tatsuya Harada, Ryuji Hamamoto, <a href=https://www.sciencedirect.com/science/article/pii/S1361841523003201>&ldquo;Sketch-based Semantic Retrieval of Medical Images.&rdquo;</a> <em>Medical Image Analysis,</em> Vol 92, Feb. 2024.</li><li>Kazuma Kobayashi, <strong>Ryuichiro Hataya</strong>, Yusuke Kurose, Mototaka Miyake, Masamichi Takahashi, Akiko Nakagawa, Tatsuya Harada, and Ryuji Hamamoto, <a href=https://www.sciencedirect.com/science/article/pii/S1361841521002723>&ldquo;Decomposing Normal and Abnormal Features of Medical Images for Content-Based Image Retrieval of Glioma Imaging.&rdquo;</a> <em>Medical Image Analysis</em>, Vo74, Dec. 2021.</li></ul><h4 id=æŸ»èª­ã‚ã‚Šä¼šè­°è«–æ–‡ class=anchor-link><a href=#%e6%9f%bb%e8%aa%ad%e3%81%82%e3%82%8a%e4%bc%9a%e8%ad%b0%e8%ab%96%e6%96%87>æŸ»èª­ã‚ã‚Šä¼šè­°è«–æ–‡</a></h4><ul><li>Han Bao, <strong>Ryuichiro Hataya</strong>, Ryo Karakida, &ldquo;Self-attention Networks Localize When QK-eigenspectrum Concentrates,&rdquo; <em>International Conference on Machine Learning,</em> 2024. <a href=https://arxiv.org/abs/2402.02098>arXiv</a></li><li><strong>Ryuichiro Hataya</strong>, Han Bao, and Hiromi Arai, <a href=https://openaccess.thecvf.com/content/ICCV2023/html/Hataya_Will_Large-scale_Generative_Models_Corrupt_Future_Datasets_ICCV_2023_paper.html>&ldquo;Will Large-scale Generative Models Corrupt Future Datasets?,&rdquo;</a> <em>International Conference on Computer Vision</em>, France, 2023.</li><li>Kazuma Kobayashi, Lin Gu, <strong>Ryuichiro Hataya</strong>, Mototaka Miyake, Yasuyuki Takamizawa, Sono Ito, Hirokazu Watanabe, Yukihiro Yoshida, Hiroki Yoshimura, Tatsuya Harada, Ryuji Hamamoto, &ldquo;Towards AI-driven radiology education: A self-supervised segmentation-based framework for high-precision medical image editing,&rdquo; <em>Medical Image Computing and Computer-Assisted Intervention</em>, Canada, 2023.</li><li><strong>Ryuichiro Hataya</strong>, and Makoto Yamada, &ldquo;<a href=https://arxiv.org/abs/2302.09726>NystrÃ¶m Method for Accurate and Scalable Implicit Differentiation</a>,&rdquo; <em>International Conference on Artificial Intelligence and Statistics</em>, Spain, 2023.</li><li><strong>Ryuichiro Hataya</strong>, and Hideki Nakayama, &ldquo;DJMix: Unsupervised Task-agnostic Image Augmentation for Improving Robustness of Convolutional Neural Networks,&rdquo; <em>International Joint Conference on Neural Networks</em>, 2022.</li><li><strong>Ryuichiro Hataya</strong>, Jan Zdenek, Kazuki Yoshizoe, and Hideki Nakayama, <a href=https://openaccess.thecvf.com/content/WACV2022/papers/Hataya_Meta_Approach_to_Data_Augmentation_Optimization_WACV_2022_paper.pdf>&ldquo;Meta Approach to Data Augmentation Optimization.&rdquo;</a> <em>Winter Conference on Applications of Computer Vision</em>, 2022.</li><li>Taiga Kashima, <strong>Ryuichiro Hataya</strong>, and Hideki Nakayama, &ldquo;Visualizing Association in Exemplar-based Classification.&rdquo; <em>International Conference on Acoustics, Speech, and Signal Processing</em>, 2021.</li><li><strong>Ryuichiro Hataya</strong>, Jan Zdenek, Kazuki Yoshizoe, and Hideki Nakayama, <a href=http://www.ecva.net/papers/eccv_2020/papers_ECCV/html/4830_ECCV_2020_paper.php>&ldquo;Faster AutoAugment: Learning Augmentation Strategies using Backpropagation.&rdquo;</a> <em>European Conference on Computer Vision</em>, 2020.</li><li><strong>Ryuichiro Hataya</strong>, and Hideki Nakayama, &ldquo;LOL: Learning To Optimize Loss Switching Under Label Noise.&rdquo; <em>International Conference on Image Processing</em>, 2019.</li></ul><details><summary>ãã®ã»ã‹</summary><h4 id=ãƒ—ãƒ¬ãƒ—ãƒªãƒ³ãƒˆ class=anchor-link><a href=#%e3%83%97%e3%83%ac%e3%83%97%e3%83%aa%e3%83%b3%e3%83%88>ãƒ—ãƒ¬ãƒ—ãƒªãƒ³ãƒˆ</a></h4><ul><li><strong>Ryuichiro Hataya</strong>, Kota Matsui, Masaaki Imaizumi, &ldquo;Automatic Domain Adaptation by Transformers in In-Context Learning,&rdquo; 2024. <a href=https://arxiv.org/abs/2405.16819>arXiv</a></li><li>Yuka Hashimoto${}^\star$, <strong>Ryuichiro Hataya</strong>${}^\star$, &ldquo;Quantum Circuit $C^\ast$-algebra Net,&rdquo; 2024. <a href=https://arxiv.org/abs/2404.06218>arXiv</a></li><li><strong>Ryuichiro Hataya</strong>, Yoshinobu Kawahara, &ldquo;Glocal Hypergradient Estimation with Koopman Operator,&rdquo; 2024. <a href=https://arxiv.org/abs/2402.02741>arXiv</a></li><li>Hiroki Naganuma${}^\star$, <strong>Ryuichiro Hataya</strong>${}^\star$, Ioannis Mitliagkas, &ldquo;An Empirical Investigation of Pre-trained Model Selection for Out-of-Distribution Generalization and Calibration,&rdquo; 2023. <a href=https://arxiv.org/abs/2307.08187>arXiv</a></li><li>Leonardo Placidi, <strong>Ryuichiro Hataya</strong>, Toshio Mori, Koki Aoyama, Hayata Morisaki, Kosuke Mitarai, and Keisuke Fujii, &ldquo;MNISQ: A Large-Scale Quantum Circuit Dataset for Machine Learning on/for Quantum Computers in the NISQ era,&rdquo; 2023. <a href=https://arxiv.org/abs/2306.16627>arXiv</a></li><li><strong>Ryuichiro Hataya</strong>${}^\star$, and Yuka Hashimoto${}^\star$, &ldquo;Noncommutative $C^\ast$-algebra Net: Learning Neural Networks with Powerful Product Structure in $C^\ast$-algebra,&rdquo; 2023. <a href=https://arxiv.org/abs/2302.01191>arXiv</a></li><li><strong>Ryuichiro Hataya</strong>, Hideki Nakayama, and Kazuki Yoshizoe, &ldquo;Graph Energy-based Model for Substructure Preserving Molecular Design.&rdquo; 2021. <a href=https://arxiv.org/abs/2102.04600>arxiv</a></li></ul><p>(${}^\star$ indicates equal contribution)</p><h4 id=ãã®ã»ã‹ class=anchor-link><a href=#%e3%81%9d%e3%81%ae%e3%81%bb%e3%81%8b>ãã®ã»ã‹</a></h4><ul><li><strong>Ryuichiro Hataya</strong>, Yuka Hashimoto, &ldquo;Noncommutative $C^\ast$-algebra Nets,&rdquo; International Conference on Quantum Techinques in Machine Learning, 2023. (Peer Reviewed Etended Abstract)</li><li>Hiroki Naganuma, <strong>Ryuichiro Hataya</strong>, &ldquo;An Empirical Investigation of Pre-trained Model Selection for Out-of-Distribution Generalization and Calibration,&rdquo; ICCV 2023 Workshop on Uncertainty Quantification for Computer Vision, 2023. (Peer Reviewed Etended Abstract <a href=https://arxiv.org/abs/2307.08187>arXiv</a>)</li><li><strong>Ryuichiro Hataya</strong>, Hideki Nakayama, and Kazuki Yoshizoe, <a href="https://openreview.net/forum?id=I2AD-xWJ2-J">&ldquo;Graph Energy-based Model for Molecular Graph Generation.&rdquo;</a> <em>EBM Workshop at ICLR 2021</em>, 2021. (Peer Reviewed, Contributed Talk)</li><li>Kazuma Kobayashi, Ryuichiro Hataya, Yusuke Kurose, Tatsuya Harada, and Ryuji Hamamoto, &ldquo;Decomposing Normal and Abnormal Features of Medical Images for Content-based Image Retrieval.&rdquo; <em>Machine Learning for Health Workshop at NeurIPS 2020</em>. (Peer Reviewed, Extended Abstract)</li><li><strong>Ryuichiro Hataya</strong>, Kumiko Matsui, and Tomoki Karasawa, &ldquo;Learning to Identify Large Fossils using Deep Convolutional Neural Networks&rdquo;, <em>Geological Society of America Abstracts with Programs</em>. Vol 52, No. 6, 2020.</li><li><strong>Ryuichiro Hataya</strong>, and Hideki Nakayama, &ldquo;Unifying semi-supervised and robust leaning by mixup.&rdquo; <em>Workshop on Learning from Limited Labeled Data at ICLR 2019</em>, 2019. (Peer Reviewed, Spotlight)</li></ul></details></div></div></div><div class="container has-text-centered top-pad"><a href=#top><i class="fa fa-arrow-up"></i></a></div></div><div class=container><hr></div><div class=section id=activities><div class=container><h2 class="title is-2 has-text-centered">ç ”ç©¶æ´»å‹•</h2><div class=columns><div class="column is-one-third has-text-centered"><img class="img-responsive avatar" src=https://hataya.tokyo/home/prague_hue5748f1b5a29a01e8c5caabf9a788fdf_418430_320x0_resize_box_3.png alt=prague.png></div><div class="markdown column"><h4 id=æ‹›å¾…è¬›æ¼” class=anchor-link><a href=#%e6%8b%9b%e5%be%85%e8%ac%9b%e6%bc%94>æ‹›å¾…è¬›æ¼”</a></h4><ul><li>&ldquo;Automatic Domain Adaptation by Transformers in In-Context Learning,&rdquo; <a href=/ja/>A*STAR-CFAR_RIKEN-AIP Workshop</a>, 2024å¹´6æœˆ <a href=/slides/astar_aip_workshop.pdf>ã‚¹ãƒ©ã‚¤ãƒ‰</a></li><li>&ldquo;Automatic Domain Adaptation by Transformers in In-Context Learning,&rdquo; <a href=/ja/>ã‚¶ãƒƒãƒ”ãƒ³ã‚°ã‚»ãƒŸãƒŠãƒ¼</a>, 2024å¹´6æœˆ <a href=/slides/astar_aip_workshop.pdf>ã‚¹ãƒ©ã‚¤ãƒ‰</a></li><li>&ldquo;å‹¾é…æ³•ã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–&rdquo;ï¼Œ<a href=https://ibisml.org/ibisml053>ç¬¬53å›IBISMLç ”ç©¶ä¼š</a>ï¼Œ2024å¹´3æœˆ <a href=/slides/ibisml_202403.pdf>ã‚¹ãƒ©ã‚¤ãƒ‰</a>ï¼</li><li>&ldquo;æ·±å±¤å­¦ç¿’ã¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ&rdquo;ï¼Œ<a href="https://docs.google.com/forms/d/e/1FAIpQLSdS2RB1mkBL9S2F-CnOT8aYqMOSLr9INfolbmosAbRsRGYK8A/viewform?vc=0&c=0&w=1&flr=0&pli=1">çµ±æ•°ç ”å…±åŒç ”ç©¶é›†ä¼š å…¼ ç¬¬4å›TREFOILç ”ç©¶ä¼š</a>ï¼Œ2024å¹´2æœˆï¼</li></ul><details><summary>éå»ã®æƒ…å ±</summary><ul><li><p>&ldquo;è¡Œåˆ—å¼ç‚¹éç¨‹ã®æ©Ÿæ¢°å­¦ç¿’ã¸ã®å¿œç”¨,&rdquo; <a href=https://www.icepp.s.u-tokyo.ac.jp/collaboration/seminar.html>ICEPPã‚»ãƒŸãƒŠãƒ¼</a>, 2023å¹´6æœˆï¼</p></li><li><p>&ldquo;Towards accurate and scalable gradient-based hyperparameter optimization,&rdquo; Istituto Italiano di Tecnologia, 2023å¹´5æœˆï¼</p></li><li><p>&ldquo;Noncommutative $C^\star$-algebra Nets,&rdquo; <a href=https://viasm.edu.vn/en/hdkh/jvaif>Japan-Vietnam AI Forum</a>, 2023å¹´4æœˆ.</p></li><li><p>ã€Œãƒ™ã‚¤ã‚ºãƒ¢ãƒ‡ãƒ«é¸æŠã«ã‚ˆã‚‹å¼±æ•™å¸«ã‚ã‚Šæ·±å±¤å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã€, <a href=https://zappingseminar.connpass.com/event/239765/>ã‚¶ãƒƒãƒ”ãƒ³ã‚°ã‚»ãƒŸãƒŠãƒ¼</a>, 2022.</p></li><li><p>ã€Œæ·±å±¤å­¦ç¿’ã¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€, <a href=https://www.cdse.ehime-u.ac.jp/>æ„›åª›å¤§å­¦DSç ”ç©¶ã‚»ãƒŸãƒŠãƒ¼</a>ï¼Œ2021.</p></li><li><p>ã€Œæ·±å±¤å­¦ç¿’ã«ãŠã‘ã‚‹ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã®åŸç†ã¨æœ€æ–°å‹•å‘ã€, Symposium on Sensing via Image Information, 2021.</p></li><li><p>ã€Œæ·±å±¤å­¦ç¿’ã‚’æ”¯ãˆã‚‹ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€, <a href=https://sites.google.com/view/statsmlsymposium20/>StatsML Symposium</a>, 2020.</p></li><li><p>ã€Œå‹¾é…é™ä¸‹æ³•ã«ã‚ˆã‚‹ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥æœ€é©åŒ–ã¸ã®å¿œç”¨ã€, <a href=https://zappingseminar.connpass.com/event/189061/>ã‚¶ãƒƒãƒ”ãƒ³ã‚°ã‚»ãƒŸãƒŠãƒ¼ </a>, 2020.</p></li></ul><h4 id=è¬›æ¼” class=anchor-link><a href=#%e8%ac%9b%e6%bc%94>è¬›æ¼”</a></h4><ul><li>ã€Œç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ±šæŸ“ã€, äººå·¥çŸ¥èƒ½å­¦ä¼š, é™å²¡, 2024å¹´5æœˆ.</li><li>ã€Œç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ±šæŸ“ã€, æ•°ç†æƒ…å ±ç ”ç©¶é›†ä¼š, ç§‹ç”°, 2023å¹´10æœˆ.</li><li>&ldquo;Stable Gradient-based Hyperparameter Optimization,&rdquo; <a href=https://about.bci-lab.info/events/riken-aip-unc-workshops-2023>RIKEN AIP & NCU Workshops 2023</a>, September 2023.</li></ul></details><h4 id=ç ”ç©¶è²» class=anchor-link><a href=#%e7%a0%94%e7%a9%b6%e8%b2%bb>ç ”ç©¶è²»</a></h4><ul><li>JST ACT-XåŠ é€Ÿãƒ•ã‚§ãƒ¼ã‚ºï¼Œ500ä¸‡å††ï¼Œ2024ï¼</li><li>ç ”ç©¶æ´»å‹•ã‚¹ã‚¿ãƒ¼ãƒˆæ”¯æ´ï¼ŒJSPSï¼Œ220ä¸‡å††ï¼Œ2023-2024.</li><li>JST ACT-X, 450ä¸‡å††, 2021-2024.</li><li>JSPSè‹¥æ‰‹ç ”ç©¶è€…æµ·å¤–æŒ‘æˆ¦ãƒ—ãƒ­ã‚°ãƒ©ãƒ , 140ä¸‡å††, 2021.</li><li>Microsoft Research Asia Collaborative Research Program (D-CORE 2021) by MSRA, 100ä¸‡å††, 2021.</li><li>æ±å¤§RIISEä¾¡å€¤äº¤æ›å·¥å­¦èŒèŠ½RA, 200ä¸‡å††, 2020-2022.</li></ul><h4 id=å—è³ class=anchor-link><a href=#%e5%8f%97%e8%b3%9e>å—è³</a></h4><ul><li>Microsoft Research Asia D-Core Award, 2020.</li><li>Best Student Paper Award, The 23rd Meeting on Image Recognition and Understanding, 2020.</li></ul><h4 id=ãã®ã»ã‹ class=anchor-link><a href=#%e3%81%9d%e3%81%ae%e3%81%bb%e3%81%8b>ãã®ã»ã‹</a></h4><ul><li>Program Committee of <a href=https://groups.oist.jp/mlss>MLSS Okinawa 2024</a>.</li><li>Program Committee of <a href=https://ibisml.org/ibis2023/>IBIS 2023</a>.</li><li>Meetup Chair of <a href=https://neurips.cc/Conferences/2021>NeurIPS, 2021</a>.</li><li>Organizer of <a href=https://neuripsmeetupjapan.github.io/2020>NeurIPS meetup Japan & Women in ML, 2020</a>.</li><li>Volunteer for ICML, and ICLR, 2020.</li><li>Reviewer for NeurIPS, ICCV, ICLR, CVPR, ICML 2019~.</li></ul></div></div></div><div class="container has-text-centered top-pad"><a href=#top><i class="fa fa-arrow-up"></i></a></div></div><div class=container><hr></div><div class=section id=contact><div class="container has-text-centered"><h2 class="title is-2">Contact</h2><div class=markdown><p><code>${firstname}.${lastname}@riken.jp</code>ã‹ã‚‰ã”é€£çµ¡ãã ã•ã„ï¼</p></div><div class=social-icons><a href=https://github.com/moskomule><i class="fab fab fa-github"></i>
</a><a href=https://www.linkedin.com/in/ryuichiro-hataya-7940a1125><i class="fab fab fa-linkedin"></i>
</a><a href="https://scholar.google.com/citations?user=84l6KcEAAAAJ"><i class="fas fab fa-graduation-cap"></i></a></div></div><div class="container has-text-centered top-pad"><a href=#top><i class="fa fa-arrow-up"></i></a></div></div><div class=container><hr></div><div class=section id=footer><div class="container has-text-centered">2019-2024, by Ryuichiro Hataya, Powered by <a href=https://gohugo.io>hugo</a> with <a href=https://github.com/victoriadrake/hugo-theme-introduction>Introduction</a></div></div><script src=https://hataya.tokyo/js/bundle.5c23c0437f001a469ca373a465a6f7487203d18e10cdff76d86a60af66d5ee28.js integrity="sha256-XCPAQ38AGkaco3OkZab3SHID0Y4Qzf922Gpgr2bV7ig="></script><script src=https://hataya.tokyo/js/bundleOwlCarousel.bc6b73f0a36bf19c70c5df8fc352d322988ca2bc40743fb836ee7371d555c28a.js integrity="sha256-vGtz8KNr8Zxwxd+Pw1LTIpiMorxAdD+4Nu5zcdVVwoo="></script></body></html>