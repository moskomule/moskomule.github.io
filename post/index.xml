<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on moskomule log</title>
    <link>http://mosko.tokyo/post/</link>
    <description>Recent content in Posts on moskomule log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Written by Ryuichiro Hataya</copyright>
    <lastBuildDate>Sat, 28 Jan 2017 07:31:45 +0900</lastBuildDate>
    
	<atom:link href="http://mosko.tokyo/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PyTorchでテキスト生成</title>
      <link>http://mosko.tokyo/post/pytorch_text_generation/</link>
      <pubDate>Sat, 28 Jan 2017 07:31:45 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/pytorch_text_generation/</guid>
      <description>相変わらずPyTorchをいじっている．後発のこともあって，まだDocは完全ではないけれど，Discussionなどのサポート体制は充実している(気がする)．
コミュニティの助けを借りてRNNでのテキスト生成をおこなった．これはKerasのサンプルをPyTorchで書き換えたもので時流に乗ってオーウェルの 1984 を学習する．Kerasのように内部状態を特に考える必要がないのとは異なって，隠れ変数$h_{\star}$を意識しなくてはいけないので勉強になる．
 function var: CUDAが使えればtorch.autograd.VariableをGPUにおく(variable.cuda())．
 function sample: RNNモデルの出力から適当なindexを取り出す．
 function __init__ in class Net: inputはfeature数で，今回であればアルファベットをonehotにしているので，len(chars)．
  def __init__(self, features, cls_size): super(Net, self).__init__() self.rnn1 = nn.GRU(input_size=features, hidden_size=hidden_size, num_layers=1) self.dense1 = nn.Linear(hidden_size, cls_size)   function forward in class Net: 系列の最後の入力に対する隠れ層の状態をとるためにx=select(0, maxlen-1)を行っている(追記:実はx[-1]で充分)．reshapeに相当するviewを行うためにはcontiguousが必要．またテンソルxは$\text{系列の長さ}\times\text{バッチ数}\times\text{feature数}$である点に注意．  def forward(self, x, hidden): x, hidden = self.rnn1(x, hidden) x = x.select(0, maxlen-1).contiguous() x = x.view(-1, hidden_size) x = F.softmax(self.dense1(x)) return x, hidden   function train: 入力した文を1通り読み込むのを1エポックにしている．Kerasと異なり，PyTorchのCrossEntropyLossではtargetはクラスのインデックスである．この目標のインデクス配列の型はnp.</description>
    </item>
    
    <item>
      <title>PyTorchはじめ</title>
      <link>http://mosko.tokyo/post/getting_started_pytorch/</link>
      <pubDate>Tue, 24 Jan 2017 15:15:55 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/getting_started_pytorch/</guid>
      <description>先日Facebookが PyTorch を公開していたので，早速試してみた．PyTorchは
 Tensors and Dynamic neural networks in Python with strong GPU acceleration.
 とのことで，TensorFlowやTheanoより，Chainerに似ている気がする．後発ということもあってか，ウェブページにある導入の説明が丁寧で，Linux，Python 3.5，conda，Cuda8.0なら
conda install pytorch torchvision cuda80 -c soumith  を叩くだけでよい．その下にはMNISTなどの例やJupyterのチュートリアルへのリンクがあるのも丁寧．ただ，ニューラルネットワークの知識に乏しくともレイヤーを重ねてscikit-learn風によしなにすればよいkerasよりは難しいが，その分柔軟に書けそう．メモリを大量消費するTensorFlowに較べて，GPUに対する負荷はかなり小さそう．
基本的にはnn.Moduleを継承してネットワークを定義する． 以下のコードはGithubに挙げた．
class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_bn = nn.BatchNorm2d(20) self.dense1 = nn.Linear(in_features=320, out_features=50) self.dense1_bn = nn.BatchNorm1d(50) self.dense2 = nn.Linear(50, 10) def forward(self, x): x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_bn(self.conv2(x)), 2)) x = x.</description>
    </item>
    
    <item>
      <title>「日本古典籍字形データセット」で遊ぶ</title>
      <link>http://mosko.tokyo/post/mnist_kuzushiji/</link>
      <pubDate>Fri, 13 Jan 2017 13:18:40 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/mnist_kuzushiji/</guid>
      <description>日本語版MNIST,というわけではないけれど日本古典籍字形データセットの識別をkerasで実装したresnetによって行った．現在validation accuracyは93.3%．少なくとも自分よりはきちんと分類できるようだ．
このデータセットには2017年1月現在，「8点の画像データから切り取ったくずし字1,521文字種の字形データ86,176文字」が収録されているので，そのまま1521に分類している．
今回はMNIST的に使うので，つまり文脈を考慮しないので変体仮名の「志」（し）と漢字としての「志」とを区別する，というようなタスクも含まれてしまうが，特に考慮しない．kerasのImageDataGeneratorで前処理を一括して行う．本当はもう少し丁寧にした方がいいのかもしれないけれど，とりあえず．
 # data generator train_datagen = ImageDataGenerator( shear_range=0.05, width_shift_range=0.05, height_shift_range=0.05, rotation_range=10, fill_mode=&amp;quot;constant&amp;quot;, cval=200, zoom_range=0.2) train_generator = train_datagen.flow_from_directory( &#39;train&#39;, color_mode=&amp;quot;grayscale&amp;quot;, target_size=target_size, batch_size=batch_size, class_mode=&#39;categorical&#39; ) val_datagen = ImageDataGenerator() val_generator = val_datagen.flow_from_directory( &#39;val&#39;, color_mode=&amp;quot;grayscale&amp;quot;, target_size=target_size, batch_size=batch_size, class_mode=&#39;categorical&#39; )  training dataには変形を施した．resnetはkeras.jsを参考にして実装(下記のres_a,res_b)．
# model input_layer = Input(shape=input_shape) x = Convolution2D(nb_filters, 4, 4, subsample=(2,2))(input_layer) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = MaxPooling2D(pool_size, strides=stride_size)(x) x = res_a([32,32,128])(x) x = res_b([32,32,128])(x) x = res_b([32,32,128])(x) x = res_a([64,64,256])(x) x = res_b([64,64,256])(x) x = res_b([128,128,256])(x) x = res_a([128,128,512])(x) x = res_b([128,128,512])(x) x = res_b([256,256,512])(x) x = AveragePooling2D((4,4))(x) x = Flatten()(x) output_layer = Dense(nb_classes, activation=&#39;softmax&#39;)(x) model = Model(input=input_layer, output=output_layer) model.</description>
    </item>
    
    <item>
      <title>dotfilesを公開</title>
      <link>http://mosko.tokyo/post/dotfiles/</link>
      <pubDate>Sat, 12 Nov 2016 01:11:08 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/dotfiles/</guid>
      <description>研究室の人々もすなるdotfilesなるものを，我も公開してみんとてするなり．それの年のかむなつきの廿日あまり一日の，戌の時に部屋の人のいふやう，「dotfilesを見せよ」．
公開して，人のdotfilesを見るようになると段々充実してきて諸々使いやすくなった一方忘れやすくもなったので備忘録をば．
Vim(NeoVim) 新しいもの好きなのでNeoVim ，プラグインマネージャーとしてdein.nvimを使っている．
denite.nvim dein.nvimの設定ファイルに
 [[plugins]] repo = &#39;Shougo/denite.nvim&#39;  を追加する．基本的にここを参考にしてマッピングした．&amp;lt;C-u&amp;gt;&amp;lt;C-g&amp;gt;でgrepによるファイルの検索のようなことが高速に行える．
vim-easy-align  [[plugins]] repo = &#39;junegunn/vim-easy-align&#39;  Githubを見れば一目瞭然なのだが，gaで起動するように設定しておくだけで，vipga=のみで上から下を実現する．
 apple = red sky = blue banana=yellow --------------- apple = red sky = blue banana = yellow  ともかく上記のREADMEが非常に充実しているのでこれを見る．
misc  &amp;lt;C-v&amp;gt;でヴィジュアルモードに入り，範囲選択してI#で選択した行のコメントアウト．  tmux どうして今まで知らなかったのだろう，tmux．
さまざまな機能があるけれども，サーバとのsshの接続を切ってしまってもプロセスを動かし続けることが出来る，というのがいちばんありがたい．それまでは時間のかかるプロセスを動かしてしまった日はノートパソコンが据え置き機と化してしまっていた．
tmux aで前回のセッションにつないで，tmux上でCtrl+dで離れる．プレフィックスキーはzshのCtrl+aを多用するので標準のCtrl+bのままにしてある．マウス/タッチパッドの使用を有効にする設定がバージョンによって違うのでそれが多少厄介で，今回のdotfilesではtmuxディレクトリを作っておき，バージョンによって読み込むファイルを変えることで解決している．</description>
    </item>
    
    <item>
      <title>scikit-learn, Xgboost そしてTensorFlow</title>
      <link>http://mosko.tokyo/post/on-sklearn-xgboost-and-tensorflow/</link>
      <pubDate>Sat, 29 Oct 2016 00:16:01 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/on-sklearn-xgboost-and-tensorflow/</guid>
      <description>新しいもの好きなので色々と触ってはみるものの，必要とならないと理解しようとしないので結果的には無駄に時間を使ってしまう．研究でPythonの機械学習・ディープラーニングライブラリに触っているので備忘録に．
scikit-learn scikit-learn a.k.a. sklearnは機械学習のライブラリで，多くの機械学習アルゴリズムが収録されている．機械学習プロパーの人からすると色々問題もあるのかもしれないが，とりあえず色々な手法が同じような書き方で使えるのはありがたい．とはいいながら，結局今回使っているのはSVMとRandom Forestだけなのだけれど．
from sklearn import svm svc = svm.SVC(kernel=&#39;linear&#39;) svc.fit(train_X,train_Y) predict_Y = svc.predict(test_X)  これだけ．あと便利なのがclassification_reportとGridSearchCV．
from sklearn.metrics import classification_report print(classification_report(test_Y, predict_Y))  で
 precision recall f1-score support 0.0 0.56 0.96 0.71 364 1.0 0.87 0.24 0.38 364 avg / total 0.72 0.60 0.55 728  まで表示される．グリッドサーチの方はクロスバリデーション付きで以下のように使う．n_jobsは使用するCPU数で，-1のときは全CPUを使って並列で処理を進めるので，モデルによっては注意が必要．今回はCPUはよいのだけれども，並列で処理するためかメモリを相当喰っている印象を受けた．
from sklearn.model_selection import GridSearchCV tuned_parameters = [{&#39;kernel&#39;: [&#39;poly&#39;,&#39;linear&#39;], &#39;gamma&#39;: [1e-3, 1e-4], &#39;C&#39;: [0.1,1,10]}] gsc = GridSearchCV(svm.SVC(), tuned_parameters, cv=5, scoring=score, n_jobs=-1) gsc.</description>
    </item>
    
    <item>
      <title>Juliaに触ってみた</title>
      <link>http://mosko.tokyo/post/julia-boxmuller/</link>
      <pubDate>Sun, 23 Oct 2016 22:36:34 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/julia-boxmuller/</guid>
      <description>我らがJupyterのJu,であるところのJupyterに触って，IPythonに相当するIJuliaを導入してJupyterから操作してみた．ちょっと触った感想は，強いR-lang．
IJuliaの導入． Juliaは ここから導入する．ターミナルから開いて，
 Package.add(&amp;quot;IJulia&amp;quot;) using IJulia notebook()  これでJupyterが起動する．あとは普段通り．
触る． 折角なので手元にあったPRMLにあった，一様乱数からガウス分布を得るBox-Muller法によって得られる分布をプロットする．以下ではプロットツールのGadflyを用いている．
using Gadfly set_default_plot_size(10cm,10cm); # Box-Muller法 function box_muller(num) x = [] y = [] for i = 0:num a = rand() b = rand() η = 2a -1 #1 ζ = 2b -1 r2 = η ^ 2 + ζ ^ 2 if (r2) &amp;lt;= 1 x = push!(x, η * √(-2 * log(r2) / r2)) #2 y = push!</description>
    </item>
    
    <item>
      <title>PythonでMySQLを使う</title>
      <link>http://mosko.tokyo/post/python-and-mysql/</link>
      <pubDate>Sat, 22 Oct 2016 00:21:34 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/python-and-mysql/</guid>
      <description>現在開発しているものはScalaで前処理を行っているので，本番の処理も本当は全部Scalaで書ければよかったのだけれども，そうは問屋が卸さず，種々の原因によりPythonが必要になってしまった． これなら最初から全部Pythonでよかったのでは，とも思うけれど，PythonはJupyterで小さなものを色々弄るのには使うものの，大きいものをPythonで書いた経験が無いので心配．型が違う，という注意が沢山出そうだ．
ともかく，そのためにPythonからMySQLを扱う必要が出てきた．Pythonists3は新しいもの好きなのか，いまやNoSQLを使うのがトレンドなのか，MySQL周りの情報が少ないのだが，pymysqlを使うことに落ち着いた．
connection = pymysql.connect(host=&amp;quot;HOSTNAME&amp;quot;, user=&amp;quot;USERNAME&amp;quot;, password=&amp;quot;PASSWORD&amp;quot;, db=&amp;quot;DB_NAME&amp;quot;, charset=&#39;utf8&#39;, cursorclass=pymysql.cursors.DictCursor) #1 with connection.cursor() as cursor: sql = &amp;quot;SELECT name FROM table WHERE id=%s&amp;quot; cursor.execute(sql, (900)) results = cursor.fetchall() for r in results: b = r[&#39;name&#39;] print(bytes.decode(b)) #2  #1を指定することで，返ってくる結果がdict形式になって分かりやすい．
最後，#2でnameに相当する列がvarbinaryであったので，文字列に変換するのにbytes.decode()が必要だった．とりあえずこれで一件落着．</description>
    </item>
    
    <item>
      <title>TensorflowでCNN入門</title>
      <link>http://mosko.tokyo/post/started-cnn-with-tensorflow/</link>
      <pubDate>Wed, 19 Oct 2016 20:04:20 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/started-cnn-with-tensorflow/</guid>
      <description>いよいよDeep Learningからは逃れられない運命，真剣に向かい合わざるを得ないことを悟り，TensorFlow Tutorial-used by Nvidiaを始めた．
前半は実は正しくなくて，今までも何度かTensorflowのTutorialを触ったものの，また，TensorFlowやChainerを使ったものの，まったく理解できないまま終わってしまっていた．
今回は偶然にも前述のTutorialと出逢うことが出来たので試してみた．
環境構築 細かいことは考えずにAnacondaを入れてしまうのが早い．基本的なパッケージは揃っているし，IntelのMKLが使えるNumpyなども特に設定せずに導入できる．導入後，
conda update --all conda install tensorflow  を行えば終了．ではあるが，GPUを使いたい場合は公式にしたがってpipを叩く必要がある．なお，このTutorialはPython2向けに書かれているので，すでにAnaconda py35を入れてしまっている場合には
conda create -n py27 python=2.7 anaconda source activate py27  が必要となる．pyenvを使うと環境への影響が少ないのだけれど，自分の環境ではAnacondaのIntel Math Kernel Libraryが上手く動かないようなので使っていない．
Tutorial Tutorial Lab2．Jupyter Notebookの偉大さが分かる．
構成もよく出来ていて，MNISTをMulti-Layer Parceptronで解く，Convolutional層を追加する，Pooling層を追加する，重ねてみる，Dropoutも追加してみる，というような流れなのでそれぞれの層の意味がよく理解できるし，岡谷先生の本ではそうかそうか，と式だけ追っていたようなことが目に見える形で現れるのは純粋に楽しいので捗るし，理解が深まる．
MNISTなので上手くいって当然なのだろうけれど，試行錯誤していくと正答率があがって過学習が減っていくのは面白い．
{% asset_img mnist.png 最終結果 %}
チャネル数 途中で，channels，チャネル数がよく分からなかったのだけれども，岡谷先生の本が参考になった．入力がRGB画像の場合は入力層の場合はチャンネル数はRGBの3である．ここで，チャンネル数 $K$ ,大きさ $W\times W$ であるものを $W\times W\times K$ と表すこととする．
いま，Convolutional層の入力のサイズを$W\times W\times K$，$m$種類のフィルターのサイズを$H\times H\times K$とすると，
$$
u_{ijm}=\sum_{k=0}^{K-1}\sum_{p=0}^{H-1}\sum_{q=0}^{H-1}z_{i+p,j+q,k}^{(l-1)}h_{pqkm}+b_{ijm}
$$
畳み込み層の出力としてはこれに活性化函数を適用した $z_{ijm}=f(u_{ijm})$ が得られる．したがって，$W\times W\times K$であった入力は，出力時には$W\times W\times M$となっている．この$M$が次の層ではチャネル数となる．ということのようだ．</description>
    </item>
    
    <item>
      <title>MeCabのJavaバインドをIntelliJで使う．</title>
      <link>http://mosko.tokyo/post/use-mecab-java-with-intellij/</link>
      <pubDate>Sat, 08 Oct 2016 19:57:29 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/use-mecab-java-with-intellij/</guid>
      <description>MeCabのJavaバインドのセットアップ MeCab公式からJavaバインドをダウンロードし，解凍する．Linuxであればこのままmakeなのだが，macOSであれば， MeCab のJava バインディングをMacOSX10.8.3(Mountain Lion) でScala から使うを参考に，Makefileを書き換えてmake．
 xcode-select --installを実行し，xcodeのコマンドラインツールを導入する．
 Makefileのスペースをタブで置き換える．
  必要があった．ここで
javac org/chasen/mecab/*.java  などを試す．エラーが出なければ，インストールは出来ているはず．
IntelliJで使う． stackoverflowにあった通りなのだが，run/debug congfigurationのJava
 VM option: -Djava.library.path=&amp;quot;/usr/local/bin/mecab-java&amp;quot;  とする必要があった．これがないと，以下のエラーが生じる．
 Exception in thread &amp;quot;main&amp;quot; java.lang.UnsatisfiedLinkError: no MeCab in java.library.path at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1867) at java.lang.Runtime.loadLibrary0(Runtime.java:870) at java.lang.System.loadLibrary(System.java:1122) at Mecab_test$.main(Mecab_test.scala:11) at Mecab_test.main(Mecab_test.scala) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)  はじめ，java.library.pathというのは環境変数で設定するものと思って苦労した</description>
    </item>
    
    <item>
      <title>JUMAN&#43;&#43; on Ubuntu</title>
      <link>http://mosko.tokyo/post/juman-install/</link>
      <pubDate>Wed, 05 Oct 2016 14:40:43 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/juman-install/</guid>
      <description>日本語形態素解析には MeCabを使ってきたが，京大の JUMAN++が進化してWikipediaやWiktionaryの用語を取り込んでMeCabを追い越した，とのことなのでインストールしてみた．
インストール  必須ライブラリ
 gcc (4.9+)
 Boost C++ Libraries (1.57+)
  推奨ライブラリ
 gpreftool
 libunwind(gpreftoolを64bit環境で使用する場合)
   gccと推奨ライブラリはapt-get installで導入できたのだが，Boostはapt-getでは1.57以上が入らなかったので，boost.orgから最新版を解凍して
cd boost_* sudo ./bootstrap.sh --prefix=&amp;lt;INSTALL_PATH&amp;gt; sudo ./b2 install export PATH=$PATH:&amp;lt;INSTALL_PATH&amp;gt;/include/:&amp;lt;INSTALL_PATH&amp;gt;/lib/ export BOOST_ROOT=&amp;lt;INSTALL_PATH&amp;gt;  続いて，JUMAN++をダウンロードし，解凍する．
cd jumanapp-1.0* ./configure --with-boost=&amp;lt;INSTALL_PATH&amp;gt; sudo make install  こうして，jumanappが使えるようになる．
比較 JUMAN++
 入り口から入って振り返ると，善き羊飼いとしてのキリストの図像がある． 入り口 いりぐち 入り口 名詞 6 普通名詞 1 * 0 * 0 &amp;quot;代表表記:入り口/いりぐち カテゴリ:場所-その他&amp;quot; から から から 助詞 9 格助詞 1 * 0 * 0 NIL 入って はいって 入る 動詞 2 * 0 子音動詞ラ行 10 タ系連用テ形 14 &amp;quot;代表表記:入る/はいる 自他動詞:他:入れる/いれる 反義:動詞:出る/でる&amp;quot; 振り返る ふりかえる 振り返る 動詞 2 * 0 子音動詞ラ行 10 基本形 2 &amp;quot;代表表記:振り返る/ふりかえる&amp;quot; と と と 助詞 9 格助詞 1 * 0 * 0 NIL ， ， ， 特殊 1 読点 2 * 0 * 0 NIL 善き よき 善い 形容詞 3 * 0 イ形容詞アウオ段 18 文語連体形 21 &amp;quot;代表表記:良い/よい 反義:形容詞:悪い/わるい&amp;quot; @ 善き よき 善い 形容詞 3 * 0 イ形容詞アウオ段 18 文語連体形 21 &amp;quot;代表表記:良い/よい 反義:形容詞:悪い/わるい&amp;quot; 羊飼い ひつじかい 羊飼い 名詞 6 普通名詞 1 * 0 * 0 &amp;quot;代表表記:羊飼い/ひつじかい カテゴリ:人&amp;quot; と と と 助詞 9 格助詞 1 * 0 * 0 NIL して して する 動詞 2 * 0 サ変動詞 16 タ系連用テ形 14 &amp;quot;代表表記:する/する 付属動詞候補（基本） 自他動詞:自:成る/なる&amp;quot; の の の 助詞 9 接続助詞 3 * 0 * 0 NIL キリスト キリスト キリスト 名詞 6 普通名詞 1 * 0 * 0 &amp;quot;自動獲得:Wikipedia Wikipedia多義&amp;quot; の の の 助詞 9 接続助詞 3 * 0 * 0 NIL 図像 ずぞう 図像 名詞 6 普通名詞 1 * 0 * 0 &amp;quot;代表表記:図像/ずぞう カテゴリ:抽象物 ドメイン:文化・芸術&amp;quot; が が が 助詞 9 格助詞 1 * 0 * 0 NIL ある ある ある 動詞 2 * 0 子音動詞ラ行 10 基本形 2 &amp;quot;代表表記:有る/ある 補文ト 反義:形容詞:無い/ない&amp;quot; ． ． ． 特殊 1 句点 1 * 0 * 0 NIL EOS  MeCab</description>
    </item>
    
    <item>
      <title>Jupyterをサーバー上で使う</title>
      <link>http://mosko.tokyo/post/using-jupyter-on-an-external-server/</link>
      <pubDate>Wed, 31 Aug 2016 18:30:08 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/using-jupyter-on-an-external-server/</guid>
      <description>2016-08-29 サーバー上のJupyter notebookを使う サーバー上でPythonを実行するのに，ターミナルで弄っていたが何かと不便だったのでJupyterを導入した．
 jupyter notebook --generate-config vim ~/.jupyter/jupyter_notebook_config.py  でjupyter_notebook_config.pyに以下を加える．
 c.NotebookApp.ip = &#39;*&#39; # localhost以外からもアクセス可能にする。 c.NotebookApp.port = 9999 # サーバのポートを指定。デフォルト8888。 c.NotebookApp.open_browser = False # ブラウザが自動で開かないようにする。 c.NotebookApp.notebook_dir = &#39;/home/USER_NAME/notebooks&#39; # 作業ディレクトリを指定。デフォルト起動ディレクトリ。  かくして，jupyter notebookコマンドを叩くとhttp://hoge.hoge:9999でJupyterが扱える．
scikit-learnでのMKLエラー解決 Ubuntuサーバー上のAnaconda3でscikit-learnを動かしたところ
 Intel MKL FATAL ERROR: Cannot load libmkl_avx.so or libmkl_def.so  というような表示が出て終了してしまう．とりあえず
 conda install nomkl numpy scipy scikit-learn numexpr  で解決させたものの，MKL使った方が速そうなので早々に解決したい．MROのMKLが悪かったりするのだろうか．
参考
Jupyter Notebook（IPython）サーバの起動方法</description>
    </item>
    
  </channel>
</rss>