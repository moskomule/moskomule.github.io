<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on moskomule log</title>
    <link>https://mosko.tokyo/post/</link>
    <description>Recent content in Posts on moskomule log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Written by Ryuichiro Hataya</copyright>
    <lastBuildDate>Wed, 12 Jul 2017 12:37:12 +0900</lastBuildDate>
    
	<atom:link href="https://mosko.tokyo/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>最適化手法について—SGDからYelloFinまで—</title>
      <link>https://mosko.tokyo/post/optimization2/</link>
      <pubDate>Wed, 12 Jul 2017 12:37:12 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/optimization2/</guid>
      <description>はじめに 前回の記事に，「ベンチマーク函数があるよ」というフィードバックを頂きました．test functions for optimizationというWikipediaの記事にまとまっていたので，今回はこちらにあるRosenbrock function($f_{R}=100(y-x^2)^2+(x-1)^2$,大域解$f_{R}(1,1)=0$)を使います．Rosenbrock函数には大域解を含む広い濠があって大域解が見つけにくいのが特徴です．
一般に勾配法の更新方法はバッチ更新と呼ばれます．つまり勾配降下法であれば学習事例$n=1,2,\ldots,N$に対して個々の誤差函数$E_n$の和
\[E(x)=\sum_n E_n(x)\]
について$x\gets x-\alpha\nabla E$と更新していました．
また，確率的な(stochastic)，または逐次的な(online)勾配降下法では$n\in\{1,\ldots,N\}$を乱択し$x\gets x-\alpha\nabla E_n(x)$により更新を行います．
また，ディープラーニングの文脈では$B\subset\{1,\ldots,N\}$によって$x\gets x-\frac{\alpha}{|B|}\sum_{i\in B}\nabla E_i(x)$を更新するミニバッチ更新がしばしば用いられます．ミニバッチの大きさ$|B|$は32,64,128などがよく用いられるように思われます．この大きさが大きいほど計算は速くなりますが，あまり大きくない方が汎化性能が上がるという話もあります1．
今回紹介する手法は主にディープラーニングの文脈で用いられるため，ミニバッチ更新を行うことでよりよい性能が出せる可能性がありますが，記事中では可視化の都合もあり$x\gets x-\alpha d$によって更新を行います．
SGD(Stochastic Gradient Descent) 基本的に勾配降下法と同一で，以下により更新を行います．
\[x_{k+1}=x_{k}-\alpha_k\nabla f(x_{k})\]
$\alpha$の調整には段階的に$\alpha$を小さくするstep decay，$\alpha_k=\alpha_0 e^{-rk}$とするexponential decay，$\alpha_k=\frac{\alpha_0}{1+rk}$とする1/k decayなどの手法がありますが，職人の勘による調整法も多いようです．
 初期位置(-0.7, -0.7),(0, 2.5),(-1, 2)からのSGDによる1000ステップの移動の軌跡．黄色の点が大域解(1,1)．   Momentum SGDは$\nabla f(x)$が0に近い時に更新ができなくなるという問題がありました．Momentum法では
\[\begin{aligned} v_{k+1} &amp;amp;= \mu v_k-\alpha\nabla f(x_k)~,v_0=0 \cr\cr x_{k+1} &amp;amp;= x_k+v_{k+1} \end{aligned}\]
によって更新を行うことでこの問題を解決しています．またSGDは各点の勾配変化に敏感でしたが，以前の状態を引き継ぐ慣性力のようなmomentum term$v$を用いることで些細な変化に対しての感度を低下させているとみることもできます．
 初期位置(-0.7, -0.7),(0, 2.5),(-1, 2)からのmomentumつきのSGDによる1000ステップの移動の軌跡．黄色の点が大域解(1,1)．   Nestrov Accelerated Gradient Momentum法を改良し，$v_{k+1}$の更新に$x_k$よりも$x_{k+1}$に近いと期待される$x_k+\mu v_k$を用いたのがNestrov Accelerated Gradientです．</description>
    </item>
    
    <item>
      <title>最適化手法についてー勾配法，ニュートン法，準ニュートン法などー</title>
      <link>https://mosko.tokyo/post/optimization/</link>
      <pubDate>Sun, 09 Jul 2017 12:37:12 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/optimization/</guid>
      <description>以前Eve optimizerの実装を行ったのですが，肝心の非線型函数の最適化手法について知らなかったので調べました．
はじめに 最適化に関して，微分を用いない手法としてはランダム法やシンプレックス法がありますが，今回は微分を用いて反復的に解に近づく方法である反復法について述べます．
なお今回可視化に際して利用した函数は$(x+1)x(x-1)(x-3)+y^2+xy$で，2つの局所解と1つの鞍点を持ちます．
反復法 反復法は函数$f(x)$について，
\[\begin{aligned} d_k &amp;amp;= -H_k\nabla f(x_k) \cr\cr x_{k+1} &amp;amp;= x_{k}+\alpha_{k}d_{k} \end{aligned}\]
によって位置を更新しながら列$(x_k)_{k\in\mathscr{N}}$を局所解または大局解$x^{\star}$に近づけていく手法です．
実際は$k$は有限なので，適当な回数で打ち切ったり，$|x_{k+1}-x_{k}|&amp;lt;\epsilon$で中止したりします．
$x$から$x+\delta x$へと移動した際の$f$の変化$\delta f(x)$とします．$\delta f(x)=\delta x\nabla f(x)$は$\delta x$と$\nabla f(x)$とが並行の時に最大となりますので，$\nabla f(x)$は$x$において$f(x)$の値が最も変化する方向です．そのため局所的には$-\nabla f(x)$に進むのが望ましいですが，それが全体として望ましいとは必ずしもいえません．反復法ではこの方向に適当な$H_k$をかけて調整した上で，順次移動していきます．
$a_k$は学習率，ステップ幅などと呼ばれ一回の更新で進む量を表します．$\alpha_k$にはヒューリスティックな更新方法もありますが($\alpha_k \sim \frac{1}{\sqrt{k}}$など)，Armijoの基準やWolfeの基準といったより客観的な指標もあります．
\[\begin{aligned} f(x_k+\alpha_k d_k) &amp;amp;\le f(x_k)+c_1\alpha_k\nabla f(x_k)^{\top}d_k \cr\cr \nabla f(x_k+\alpha_k d_k)^{\top}d_k &amp;amp;\ge c_2\nabla f(x_k)d_k \end{aligned}\]
上の式がArmijoの基準で，2つ合わせるとWolfeの基準となります．$\alpha_k$がこの範囲に収まるように変化させていきます(line search method1)．
勾配降下法 勾配降下法(gradient descent method)，または最急降下法(steepest descent method)は$H_k=I$とする手法です．すなわち
\[x_{k+1}=x_{k}-\alpha_k\nabla f(x_{k})\]
によって更新していきます．最急方向に適当な学習率$\alpha_k$を乗じて進んでいくので「直感的には合理的」2ですが，収束が遅く，適切な学習率の調整が難しいなど，実際の性能はあまりよくありません．
  $\alpha_k=0.1$で100回の更新を行った際の$x_k$の軌跡    $\alpha_k=0.01$で100回の更新を行った際の$x_k$の軌跡    $\alpha_k=0.001$で100回の更新を行った際の$x_k$の軌跡    最急降下法に対してWolfe基準を用いて学習率を調整した際の$x_k$の軌跡   ニュートン法 ニュートン法，またはニュートン・ラフソン法(Newton-Raphson method)は$H_k$に$(\nabla^2 f(x))^{-1}$，つまりHessianの逆行列を用いた手法です．これはニュートンの近似法3によって$f(x)$の極値を求めていると見ることができます．ニュートンの近似法は函数$g(t)=0$の根を</description>
    </item>
    
    <item>
      <title>PyTorchでRNN入門</title>
      <link>https://mosko.tokyo/post/pytorch_rnn/</link>
      <pubDate>Sat, 24 Jun 2017 15:37:12 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/pytorch_rnn/</guid>
      <description>RNNの概説 RNNは再帰型ニューラルネットワーク(recurrent neural network)の略です．各層は以前の自分自身の出力も入力とする再帰的な構造をもつため，この名がつけられています．時間依存のある文や信号といった入力を処理することができます．
 RNN（左）とCNNなどのネットワーク（右）．RNNは自分自身の出力も入力として取り込むことで，時間に依存した情報を扱うことができると考えられた．   RNN自体は90年代初頭にJ.Elmanらによって提案され1，文生成や分散表現の獲得などの研究が行われています．現在でもよく使われる，より長い系列にも対応できるLSTMも90年代末に提案されており，伝統のあるネットワークであるといえるでしょう．
画像におけるCNNの華々しい活躍と比較すると劣りますが，それでもGoogle翻訳の昨今の「自然な」翻訳の背景にはRNNがあります．
単純なRNN 入力とする系列$x_0,x_1,\cdots,x_T$を$x_0$から順次与えていきます．ここでは下付き文字$\star_t$は時刻を表します．また上付き文字$\star^l$を$l$層目の状態として，時刻$t$における$l$層目の隠れ状態を$h_t^l$，出力を$y_t$と表します．
再帰型ではないニューラルネットワークでは，ある層$l$の隠れ状態$h^l$は，その前の層への状態に重み$W^l$をかけ，活性化函数$f$に与えたもので，
\[h^l = f(W^lh^{l-1})\]
でした（ただし簡便のためにバイアスは省きました．今後も同様です．）．
一方で，RNNには時刻の概念があり，さらに一つ前の状態を考慮するため，ある時刻$t$における，層$l$の状態$h^l_t$は
\[h^l_t = f(W^lh_{t}^{l-1}+U^lh_{t-1}^l)\]
です．つまり，前の層の出力$W^lh_t^{l-1}$に，前時刻の自分の出力$U^lh_{t-1}^l$が加わったものを活性化函数に与えることとなります．活性化函数$f$としては$\tanh,\mathrm{relu},\mathrm{sigmoid}$などが用いられます．
それでは実際に系列を入力してみましょう．まず，$x_0$を入力します．
 時刻 $\sim 0$   このとき$t=0$では，上の式から
\[h^1_0=f(W^1x_0+U^1h_{-1}^1),h^2_0=f(W^2h^1_0+U^2h_{-1}^2)\]
となります．この$h_{-1}^1,h_{-1}^2$は最初は隠れ状態がないために与える必要がある「仮の隠れ状態」で，$0$など適当に初期化されたベクトルを用います．同様にして，recurrent層が$L$層あれば時刻0において$x_0$と$h_{-1}^1,h_{-1}^2,\cdots,h_{-1}^L$を用意する必要があります．また，最終層は
\[y_t=f_y(W^{L}h_t^{L})\]
で与えられます．
その後は隠れ状態があるので，順次
\[h^1_1=f(W^1x_1+U^lh_{0}^1)\]
などとなります．
  時刻 $0\sim 1$    時刻 $1\sim 2$    時刻 $2\sim $   重みの更新は一つの系列が終了してから行います．このとき用いる損失は，目標を$d_0,d_1,\cdots,d_T$として，すべての時刻に対して出力が必要な場合，例えば文章生成の場合，
\[\sum_t\mathrm{loss}(y_t,d_t)\]
とします．または，二値分類などでは$y_T$には$y_0,\cdots,y_{T-1}$の情報が蓄積されていると考えて
\[\mathrm{loss}(y_T, d_T)\]
を用います．
いずれにしても，このとき$t=T$での損失から$t=0$での隠れ状態も考慮することとなります．上の図では$t=2$までしかありませんが，$h_0^1$から$y_2$までの経路は，例えば$h_0^1\to h_1^1\to h_1^2\to h_2^2\to y_2$などのように，一般のネットワークでは隠れ層4のネットワークに相当します．
そのため，理論的には長い系列を処理することができますが，実際にはこのような単純なRNNでは容易に勾配消失がおこり，長い系列は学習できなくなることが知られています．
PyTorchではこの単純なRNNはnn.RNNに用意されています（後述）．</description>
    </item>
    
    <item>
      <title>カスタムドメインのGitHub Pagesをhttps化する</title>
      <link>https://mosko.tokyo/post/githubpages-and-https/</link>
      <pubDate>Thu, 15 Jun 2017 22:14:39 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/githubpages-and-https/</guid>
      <description>はじめに このmosko.tokyoは何年か前に試しに買ってみたカスタムドメインである．現在，このページはGithub Pagesによってホスティングされていて，Hugoによって生成されている．
今回，Cloudflareを使うことでhttps化した．
GitHub Pages GitHub PagesはGitHub上に個人・組織，プロジェクトの静的なページを作れるサービスで，username.github.ioというドメインが割り当てられる．このドメインを使う限りはhttpsが有効にである．
&amp;ldquo;Settings&amp;gt;custom domain&amp;rdquo;を編輯することで，カスタムドメインが使用できるが，その場合はhttpsが無効化される．
Cloudflare 初めはLet&amp;rsquo;s Encryptの利用を考えていたが，このページを読み，より簡単そうなCloudflareを用いることとした．
CloudflareはDNS/CDNで，機能が制限された個人の使用に限れば無料である．
 登録する カスタムドメインを入力する ネームサーバをCloudflareのものに移行する  ネームサーバの変更までに1日ほどかかった．その後，Dashboardにて
 &amp;ldquo;Crypto&amp;gt;SSL&amp;rdquo;を&amp;rdquo;full&amp;rdquo;に変更 &amp;ldquo;Page Rules&amp;rdquo;の&amp;rdquo;create page rule&amp;rdquo;に  if http://hoge.hoge/* then &amp;ldquo;always use https&amp;rdquo; if https://hoge.hoge/* then &amp;ldquo;cache everything&amp;rdquo;   を設定する．前者でhttpでの接続をhttpsに切り替え，後者でドメイン以下のコンテンツをキャッシュさせている．</description>
    </item>
    
    <item>
      <title>PyTorchでCNN入門</title>
      <link>https://mosko.tokyo/post/pytorch_cnn/</link>
      <pubDate>Sat, 10 Jun 2017 15:37:12 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/pytorch_cnn/</guid>
      <description>CNNの概説 CNNは畳み込みニューラルネットワーク(convolutional neural network)の略です．CNNは四天王のひとりLeCun(1989)に始まり，2012年の一般物体認識のコンテスト(ILSVRC)で優勝しディープラーニングを一躍有名にしたAlexNet(Krizhevsky)を経て，現在の画像認識には欠かせないネットワークです．
畳み込み CNNでは畳み込み(convolution)という操作を行います．ここでは簡単のためにすべて2次元で考えます．
以下のように入力の行列とフィルタが与えられたときに，
\[I=ar+bs+tc+du+ev+fw+gz+hy+iz\]
を畳み込みと呼びます．本来画像認識の分野では$ax+by+cz+\cdots$を畳み込みと呼び，上記の演算は相関と呼ばれるようですが，CNNの文脈ではこれを畳み込みと呼ぶよう1なので慣例に倣います．
 左が入力の一部，右がフィルター．   入力に対して，この操作を同じフィルタをずらしながら適用していきます．下の図では上部の入力とフィルタの畳み込み結果を下の出力行列の各要素にする様子を書きました．こうして畳み込みによる出力が得られます．
 上が入力とフィルタ，下が出力．   畳み込みは画像の対応部分とフィルタとの内積を取ることですから，それらの関連ぐらいを見ていることになります（それ故に相関と呼ばれるのですが）．従って，出力は入力画像のフィルタとの関連度を凝縮したものになるわけです．以上の畳み込み（あるいは相関）自体はCNN以前から画像認識の分野で用いられてきましたが，CNNではフィルタ自体を誤差逆伝播法で学習していく点が従来とは異なります2．
上では入力，フィルタとも1枚ずつである場合を考えましたが，一般にそれらは複数枚あり，テンソルとして扱われます．この「枚数方向」の次元はチャネルと呼ばれます．特にRGB画像は3チャネルです．
複数チャネルの場合は，入力の各チャネルに対して同一のフィルタを適用し，その和をとります．従って，出力のチャネル数はフィルタ数と一致します．
プーリング CNNではその他にプーリングという操作を行う場合もあります．その中でもよく用いられる最大プーリング(max pooling)は下に示したように，領域内の最大値を取り出して出力とする操作です．画像認識では位置がずれた同じ物体も同じものとして認識したいので，この操作を加えて位置に対する不変性を向上させます．
 最大プーリング．上部が入力で下部が出力．   最大プーリングのほかに，平均値を用いるプーリングもあります．
用語 説明に用いる画像はこちらのもので，今までと異なり下が入力，上が出力です．
kernel 上記の畳み込みのフィルタやプーリングの領域のことをカーネルと呼ぶこともあります．
stride カーネルの動く際のステップです．プーリングの場合は領域幅と同じ幅で動かし，重複する範囲がないようにすることが多い気がします．
 stride=1   padding 畳み込み，プーリングを上記のように行った場合，出力は入力よりも小さくなります．入力の周りに「枠」を付けることで出力サイズを調整するのがpaddingです．「枠」を0で埋めるゼロパディングがしばしば用いられます．
 stride=1,padding=1   dilation カーネルにあける隙間の大きさです．プーリングの代わりにdilationを用いることもあるようです．
 stride=1,dilation=1   relu 活性化函数の一つで，“rectified linear unit”の略です．函数としては
\[\mathrm{relu}(x)=\max(0,x)\]
と極めて単純ですが，これがなければ現在のディープニューラルネットワーク時代はなかった，とも言えるような，強力な存在です．以前はsigmoid函数(S字状函数)，たとえば
\[\mathrm{sigmoid}(x)=\frac{1}{1+e^{-x}}\]
が用いられていましたが，ネットワークが深くなると勾配が消失する問題を抱えていました．
 sigmoid函数とrelu函数との比較   PyTorchにおけるCNN PyTorchの簡単なチュートリアルはこちらにあります．
コード中のFはnn.functionalのことです．
nn nn.Conv2dを用います．F.conv2dというものもありますが，こちらは自分で明示的にweight,biasのテンソルを用意し，必要であれば重みを更新しなくてはいけません．他方，nn.Conv2dであれば入出力のチャネル数およびカーネルの大きさを定めるだけです．今回は用いていませんが，上で説明したpadding,dilationを用いることもできます．
プーリングには，畳み込みのように更新すべきテンソルがないのでF.max_pool2dを用いても差はありません．</description>
    </item>
    
    <item>
      <title>PyTorchでディープラーニング</title>
      <link>https://mosko.tokyo/post/pytorch_tutorial/</link>
      <pubDate>Thu, 08 Jun 2017 16:33:50 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/pytorch_tutorial/</guid>
      <description>PyTorchとは PyTorchはFacebookの開発するPython上でのテンソル計算・自動微分ライブラリで，特にディープラーニングに必要な機能が充実しています．2017年の初頭に公開され，瞬く間にTensorflow, Keras, Caffeに続くディープラーニングライブラリとして人気を博すこととなりました．
Bonus: stars (not an indicator of usage, just proportional to how many people have landed on the GitHub page over the period). pic.twitter.com/IugHJqHSii
&amp;mdash; François Chollet (@fchollet) April 12, 2017  PyTorchはPreferred NetworkのディープラーニングライブラリChainerから影響を受けており，GoogleのTensorFlowやUniversité de MontréalのTheanoとは異なり，実行時に動的にグラフを構築するため，柔軟なコードを書くことができます．
PyTorchは，製品にも用いられているTensorFlowとは異なり，研究向けであることが明言されています．新機能の変更は多いものの，疎テンソルにいち早く対応するなど，最新の研究動向を追うにはよいのではないでしょうか．また，適当なレベルで書くことができて，素のTensorflowのように低レベルでもなく，Kerasの様に高度に抽象化されているわけでもなく，ラッパーによって書き方が多様でサンプルを見てもよく分からない，ということはないので，学びやすいと思います．
チュートリアル とりあえず動かせるようになるチュートリアルです．
インストール GPU環境は勿論，CPU環境でも動かすことができます．Linux，macOSの場合は 公式, Windowsの場合は Anaconda Cloudからインストールできます．
GPUを利用する場合，環境の設定が面倒なことが多いですがPyTorchでは特に設定せずにGPU対応版をダウンロードするとGPUが使えるようになるようです．
Tensor PyTorchの基本はテンソルを操作するTensorです．テンソルというと難しく聞こえますが，この場合は多次元配列と同義で，物理学のテンソルのような共変・反変を意識する必要はありません．慣例に従ってテンソル，と言う語を用います．
PyTorchにおけるTensorは端的に言えば「GPU上でも動くnumpy.ndarrayのようなもの」ですが，違いも多いので注意が必要です．例えば
import numpy as np import torch # PyTorch &amp;gt;&amp;gt;&amp;gt; np_tensor = np.zeros([1, 2, 3]) array([[[ 0., 0., 0.</description>
    </item>
    
    <item>
      <title>PyTorchはじめ</title>
      <link>https://mosko.tokyo/post/getting_started_pytorch/</link>
      <pubDate>Tue, 24 Jan 2017 15:15:55 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/getting_started_pytorch/</guid>
      <description>先日Facebookが PyTorch を公開していたので，早速試してみた．PyTorchは
 Tensors and Dynamic neural networks in Python with strong GPU acceleration.
 とのことで，TensorFlowやTheanoより，Chainerに似ている気がする．後発ということもあってか，ウェブページにある導入の説明が丁寧で，Linux，Python 3.5，conda，Cuda8.0なら
conda install pytorch torchvision cuda80 -c soumith  を叩くだけでよい．その下にはMNISTなどの例やJupyterのチュートリアルへのリンクがあるのも丁寧．ただ，ニューラルネットワークの知識に乏しくともレイヤーを重ねてscikit-learn風によしなにすればよいkerasよりは難しいが，その分柔軟に書けそう．メモリを大量消費するTensorFlowに較べて，GPUに対する負荷はかなり小さそう．
基本的にはnn.Moduleを継承してネットワークを定義する． 以下のコードはGithubに挙げた．
class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_bn = nn.BatchNorm2d(20) self.dense1 = nn.Linear(in_features=320, out_features=50) self.dense1_bn = nn.BatchNorm1d(50) self.dense2 = nn.Linear(50, 10) def forward(self, x): x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_bn(self.conv2(x)), 2)) x = x.</description>
    </item>
    
    <item>
      <title>「日本古典籍字形データセット」で遊ぶ</title>
      <link>https://mosko.tokyo/post/mnist_kuzushiji/</link>
      <pubDate>Fri, 13 Jan 2017 13:18:40 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/mnist_kuzushiji/</guid>
      <description>日本語版MNIST,というわけではないけれど日本古典籍字形データセットの識別をkerasで実装したresnetによって行った．現在validation accuracyは93.3%．少なくとも自分よりはきちんと分類できるようだ．
このデータセットには2017年1月現在，「8点の画像データから切り取ったくずし字1,521文字種の字形データ86,176文字」が収録されているので，そのまま1521に分類している．
今回はMNIST的に使うので，つまり文脈を考慮しないので変体仮名の「志」（し）と漢字としての「志」とを区別する，というようなタスクも含まれてしまうが，特に考慮しない．kerasのImageDataGeneratorで前処理を一括して行う．本当はもう少し丁寧にした方がいいのかもしれないけれど，とりあえず．
 # data generator train_datagen = ImageDataGenerator( shear_range=0.05, width_shift_range=0.05, height_shift_range=0.05, rotation_range=10, fill_mode=&amp;quot;constant&amp;quot;, cval=200, zoom_range=0.2) train_generator = train_datagen.flow_from_directory( &#39;train&#39;, color_mode=&amp;quot;grayscale&amp;quot;, target_size=target_size, batch_size=batch_size, class_mode=&#39;categorical&#39; ) val_datagen = ImageDataGenerator() val_generator = val_datagen.flow_from_directory( &#39;val&#39;, color_mode=&amp;quot;grayscale&amp;quot;, target_size=target_size, batch_size=batch_size, class_mode=&#39;categorical&#39; )  training dataには変形を施した．resnetはkeras.jsを参考にして実装(下記のres_a,res_b)．
# model input_layer = Input(shape=input_shape) x = Convolution2D(nb_filters, 4, 4, subsample=(2,2))(input_layer) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = MaxPooling2D(pool_size, strides=stride_size)(x) x = res_a([32,32,128])(x) x = res_b([32,32,128])(x) x = res_b([32,32,128])(x) x = res_a([64,64,256])(x) x = res_b([64,64,256])(x) x = res_b([128,128,256])(x) x = res_a([128,128,512])(x) x = res_b([128,128,512])(x) x = res_b([256,256,512])(x) x = AveragePooling2D((4,4))(x) x = Flatten()(x) output_layer = Dense(nb_classes, activation=&#39;softmax&#39;)(x) model = Model(input=input_layer, output=output_layer) model.</description>
    </item>
    
    <item>
      <title>dotfilesを公開</title>
      <link>https://mosko.tokyo/post/dotfiles/</link>
      <pubDate>Sat, 12 Nov 2016 01:11:08 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/dotfiles/</guid>
      <description>研究室の人々もすなるdotfilesなるものを，我も公開してみんとてするなり．それの年のかむなつきの廿日あまり一日の，戌の時に部屋の人のいふやう，「dotfilesを見せよ」．
公開して，人のdotfilesを見るようになると段々充実してきて諸々使いやすくなった一方忘れやすくもなったので備忘録をば．
Vim(NeoVim) 新しいもの好きなのでNeoVim ，プラグインマネージャーとしてdein.nvimを使っている．
denite.nvim dein.nvimの設定ファイルに
[[plugins]] repo = &#39;Shougo/denite.nvim&#39;  を追加する．基本的にここを参考にしてマッピングした．&amp;lt;C-u&amp;gt;&amp;lt;C-g&amp;gt;でgrepによるファイルの検索のようなことが高速に行える．
vim-easy-align [[plugins]] repo = &#39;junegunn/vim-easy-align&#39;  Githubを見れば一目瞭然なのだが，gaで起動するように設定しておくだけで，vipga=のみで上から下を実現する．
apple = red sky = blue banana=yellow --------------- apple = red sky = blue banana = yellow  ともかく上記のREADMEが非常に充実しているのでこれを見る．
misc  &amp;lt;C-v&amp;gt;でヴィジュアルモードに入り，範囲選択してI#で選択した行のコメントアウト．  tmux どうして今まで知らなかったのだろう，tmux．
さまざまな機能があるけれども，サーバとのsshの接続を切ってしまってもプロセスを動かし続けることが出来る，というのがいちばんありがたい．それまでは時間のかかるプロセスを動かしてしまった日はノートパソコンが据え置き機と化してしまっていた．
tmux aで前回のセッションにつないで，tmux上でCtrl+dで離れる．プレフィックスキーはzshのCtrl+aを多用するので標準のCtrl+bのままにしてある．マウス/タッチパッドの使用を有効にする設定がバージョンによって違うのでそれが多少厄介で，今回のdotfilesではtmuxディレクトリを作っておき，バージョンによって読み込むファイルを変えることで解決している．</description>
    </item>
    
    <item>
      <title>Juliaに触ってみた</title>
      <link>https://mosko.tokyo/post/julia-boxmuller/</link>
      <pubDate>Sun, 23 Oct 2016 22:36:34 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/julia-boxmuller/</guid>
      <description>我らがJupyterのJu,であるところのJupyterに触って，IPythonに相当するIJuliaを導入してJupyterから操作してみた．ちょっと触った感想は，強いR-lang．
IJuliaの導入． Juliaは ここから導入する．ターミナルから開いて，
 Package.add(&amp;quot;IJulia&amp;quot;) using IJulia notebook()  これでJupyterが起動する．あとは普段通り．
触る． 折角なので手元にあったPRMLにあった，一様乱数からガウス分布を得るBox-Muller法によって得られる分布をプロットする．以下ではプロットツールのGadflyを用いている．
using Gadfly set_default_plot_size(10cm,10cm); # Box-Muller法 function box_muller(num) x = [] y = [] for i = 0:num a = rand() b = rand() η = 2a -1 #1 ζ = 2b -1 r2 = η ^ 2 + ζ ^ 2 if (r2) &amp;lt;= 1 x = push!(x, η * √(-2 * log(r2) / r2)) #2 y = push!</description>
    </item>
    
    <item>
      <title>PythonでMySQLを使う</title>
      <link>https://mosko.tokyo/post/python-and-mysql/</link>
      <pubDate>Sat, 22 Oct 2016 00:21:34 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/python-and-mysql/</guid>
      <description>現在開発しているものはScalaで前処理を行っているので，本番の処理も本当は全部Scalaで書ければよかったのだけれども，そうは問屋が卸さず，種々の原因によりPythonが必要になってしまった． これなら最初から全部Pythonでよかったのでは，とも思うけれど，PythonはJupyterで小さなものを色々弄るのには使うものの，大きいものをPythonで書いた経験が無いので心配．型が違う，という注意が沢山出そうだ．
ともかく，そのためにPythonからMySQLを扱う必要が出てきた．Pythonists3は新しいもの好きなのか，いまやNoSQLを使うのがトレンドなのか，MySQL周りの情報が少ないのだが，pymysqlを使うことに落ち着いた．
connection = pymysql.connect(host=&amp;quot;HOSTNAME&amp;quot;, user=&amp;quot;USERNAME&amp;quot;, password=&amp;quot;PASSWORD&amp;quot;, db=&amp;quot;DB_NAME&amp;quot;, charset=&#39;utf8&#39;, cursorclass=pymysql.cursors.DictCursor) #1 with connection.cursor() as cursor: sql = &amp;quot;SELECT name FROM table WHERE id=%s&amp;quot; cursor.execute(sql, (900)) results = cursor.fetchall() for r in results: b = r[&#39;name&#39;] print(bytes.decode(b)) #2  #1を指定することで，返ってくる結果がdict形式になって分かりやすい．
最後，#2でnameに相当する列がvarbinaryであったので，文字列に変換するのにbytes.decode()が必要だった．とりあえずこれで一件落着．</description>
    </item>
    
    <item>
      <title>MeCabのJavaバインドをIntelliJで使う．</title>
      <link>https://mosko.tokyo/post/use-mecab-java-with-intellij/</link>
      <pubDate>Sat, 08 Oct 2016 19:57:29 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/use-mecab-java-with-intellij/</guid>
      <description>MeCabのJavaバインドのセットアップ MeCab公式からJavaバインドをダウンロードし，解凍する．Linuxであればこのままmakeなのだが，macOSであれば， MeCab のJava バインディングをMacOSX10.8.3(Mountain Lion) でScala から使うを参考に，Makefileを書き換えてmake．
 xcode-select --installを実行し，xcodeのコマンドラインツールを導入する．
 Makefileのスペースをタブで置き換える．
  必要があった．ここで
javac org/chasen/mecab/*.java  などを試す．エラーが出なければ，インストールは出来ているはず．
IntelliJで使う． stackoverflowにあった通りなのだが，run/debug congfigurationのJava
 VM option: -Djava.library.path=&amp;quot;/usr/local/bin/mecab-java&amp;quot;  とする必要があった．これがないと，以下のエラーが生じる．
 Exception in thread &amp;quot;main&amp;quot; java.lang.UnsatisfiedLinkError: no MeCab in java.library.path at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1867) at java.lang.Runtime.loadLibrary0(Runtime.java:870) at java.lang.System.loadLibrary(System.java:1122) at Mecab_test$.main(Mecab_test.scala:11) at Mecab_test.main(Mecab_test.scala) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)  はじめ，java.library.pathというのは環境変数で設定するものと思って苦労した</description>
    </item>
    
    <item>
      <title>JUMAN&#43;&#43; on Ubuntu</title>
      <link>https://mosko.tokyo/post/juman-install/</link>
      <pubDate>Wed, 05 Oct 2016 14:40:43 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/juman-install/</guid>
      <description>日本語形態素解析には MeCabを使ってきたが，京大の JUMAN++が進化してWikipediaやWiktionaryの用語を取り込んでMeCabを追い越した，とのことなのでインストールしてみた．
インストール  必須ライブラリ
 gcc (4.9+)
 Boost C++ Libraries (1.57+)
  推奨ライブラリ
 gpreftool
 libunwind(gpreftoolを64bit環境で使用する場合)
   gccと推奨ライブラリはapt-get installで導入できたのだが，Boostはapt-getでは1.57以上が入らなかったので，boost.orgから最新版を解凍して
cd boost_* sudo ./bootstrap.sh --prefix=&amp;lt;INSTALL_PATH&amp;gt; sudo ./b2 install export PATH=$PATH:&amp;lt;INSTALL_PATH&amp;gt;/include/:&amp;lt;INSTALL_PATH&amp;gt;/lib/ export BOOST_ROOT=&amp;lt;INSTALL_PATH&amp;gt;  続いて，JUMAN++をダウンロードし，解凍する．
cd jumanapp-1.0* ./configure --with-boost=&amp;lt;INSTALL_PATH&amp;gt; sudo make install  こうして，jumanappが使えるようになる．
比較 JUMAN++
 入り口から入って振り返ると，善き羊飼いとしてのキリストの図像がある． 入り口 いりぐち 入り口 名詞 6 普通名詞 1 * 0 * 0 &amp;quot;代表表記:入り口/いりぐち カテゴリ:場所-その他&amp;quot; から から から 助詞 9 格助詞 1 * 0 * 0 NIL 入って はいって 入る 動詞 2 * 0 子音動詞ラ行 10 タ系連用テ形 14 &amp;quot;代表表記:入る/はいる 自他動詞:他:入れる/いれる 反義:動詞:出る/でる&amp;quot; 振り返る ふりかえる 振り返る 動詞 2 * 0 子音動詞ラ行 10 基本形 2 &amp;quot;代表表記:振り返る/ふりかえる&amp;quot; と と と 助詞 9 格助詞 1 * 0 * 0 NIL ， ， ， 特殊 1 読点 2 * 0 * 0 NIL 善き よき 善い 形容詞 3 * 0 イ形容詞アウオ段 18 文語連体形 21 &amp;quot;代表表記:良い/よい 反義:形容詞:悪い/わるい&amp;quot; @ 善き よき 善い 形容詞 3 * 0 イ形容詞アウオ段 18 文語連体形 21 &amp;quot;代表表記:良い/よい 反義:形容詞:悪い/わるい&amp;quot; 羊飼い ひつじかい 羊飼い 名詞 6 普通名詞 1 * 0 * 0 &amp;quot;代表表記:羊飼い/ひつじかい カテゴリ:人&amp;quot; と と と 助詞 9 格助詞 1 * 0 * 0 NIL して して する 動詞 2 * 0 サ変動詞 16 タ系連用テ形 14 &amp;quot;代表表記:する/する 付属動詞候補（基本） 自他動詞:自:成る/なる&amp;quot; の の の 助詞 9 接続助詞 3 * 0 * 0 NIL キリスト キリスト キリスト 名詞 6 普通名詞 1 * 0 * 0 &amp;quot;自動獲得:Wikipedia Wikipedia多義&amp;quot; の の の 助詞 9 接続助詞 3 * 0 * 0 NIL 図像 ずぞう 図像 名詞 6 普通名詞 1 * 0 * 0 &amp;quot;代表表記:図像/ずぞう カテゴリ:抽象物 ドメイン:文化・芸術&amp;quot; が が が 助詞 9 格助詞 1 * 0 * 0 NIL ある ある ある 動詞 2 * 0 子音動詞ラ行 10 基本形 2 &amp;quot;代表表記:有る/ある 補文ト 反義:形容詞:無い/ない&amp;quot; ． ． ． 特殊 1 句点 1 * 0 * 0 NIL EOS  MeCab</description>
    </item>
    
    <item>
      <title>Jupyterをサーバー上で使う</title>
      <link>https://mosko.tokyo/post/using-jupyter-on-an-external-server/</link>
      <pubDate>Wed, 31 Aug 2016 18:30:08 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/using-jupyter-on-an-external-server/</guid>
      <description>2016-08-29 サーバー上のJupyter notebookを使う サーバー上でPythonを実行するのに，ターミナルで弄っていたが何かと不便だったのでJupyterを導入した．
jupyter notebook --generate-config vim ~/.jupyter/jupyter_notebook_config.py  でjupyter_notebook_config.pyに以下を加える．
 c.NotebookApp.ip = &#39;*&#39; # localhost以外からもアクセス可能にする。 c.NotebookApp.port = 9999 # サーバのポートを指定。デフォルト8888。 c.NotebookApp.open_browser = False # ブラウザが自動で開かないようにする。 c.NotebookApp.notebook_dir = &#39;/home/USER_NAME/notebooks&#39; # 作業ディレクトリを指定。デフォルト起動ディレクトリ。  かくして，jupyter notebookコマンドを叩くとhttp://hoge.hoge:9999でJupyterが扱える．
scikit-learnでのMKLエラー解決 Ubuntuサーバー上のAnaconda3でscikit-learnを動かしたところ
Intel MKL FATAL ERROR: Cannot load libmkl_avx.so or libmkl_def.so  というような表示が出て終了してしまう．とりあえず
conda install nomkl numpy scipy scikit-learn numexpr  で解決させたものの，MKL使った方が速そうなので早々に解決したい．MROのMKLが悪かったりするのだろうか．
参考
Jupyter Notebook（IPython）サーバの起動方法</description>
    </item>
    
  </channel>
</rss>