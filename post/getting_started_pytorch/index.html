
<!DOCTYPE html>
<html lang="ja">
<head>

  
  <meta charset="UTF-8">
  <title>
    Pytorchはじめ | moskomule log
  </title>


  
  <meta name="viewport" content="width=device-width,user-scalable=no,maximum-scale=1,initial-scale=1">

  
  <link rel="canonical" href="http://mosko.tokyo/post/getting_started_pytorch/"/>

  
  <link rel="stylesheet" href="/css/sanitize.css">
  <link rel="stylesheet" href="/css/responsive.css">
  <link rel="stylesheet" href="/css/highlight_monokai.css">
  <link rel="stylesheet" href="/css/theme.css">
  <link rel="stylesheet" href="/css/custom.css">
  
  
  <link href="http://mosko.tokyo/index.xml" rel="alternate" type="application/rss+xml" title="moskomule log" />
  <link href="http://mosko.tokyo/index.xml" rel="feed" type="application/rss+xml" title="moskomule log" />

  
  

  
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

</head>



<body>
<div class="container">

  
  <header role="banner">
    <div class="row gutters">
      <div id="site-title" class="col span_6">
        <h1><a href="http://mosko.tokyo/">moskomule log</a></h1>
        <h2>carpe diem</h2>
      </div>
      <div id="social" class="col span_6">
        <ul>
          <li><a href="https://twitter.com/mosko_mule" target="_blank">Twitter</a></li>
          
          <li><a href="https://github.com/moskomule" target="_blank">GitHub</a></li>
          <li><a href="http://mosko.tokyo/index.xml" type="application/rss+xml" target="_blank">RSS</a></li>
        </ul>
      </div>
    </div>
  </header>


  
  <main id="single" role="main">
    <div class="article-header">
      <h1>Pytorchはじめ</h1>
      <div class="meta">
        Jan 24, 2017 &nbsp;
        
          #<a href="/tags/pytorch">Pytorch</a>&nbsp;
        
          #<a href="/tags/deep-learning">Deep Learning</a>&nbsp;
        
      </div>
    </div>
    <article>
      <p>先日Facebookが <a href="http://pytorch.org/">Pytorch</a> を公開していたので，早速試してみた．<code>Pytorch</code>は</p>

<blockquote>
<p>Tensors and Dynamic neural networks in Python with strong GPU acceleration.</p>
</blockquote>

<p>とのことで，<code>TensorFlow</code>や<code>Theano</code>より，<code>Chainer</code>に似ている気がする．後発ということもあってか，ウェブページにある導入の説明が丁寧で，Linux，Python 3.5，conda，Cuda8.0なら</p>

<pre><code>conda install pytorch torchvision cuda80 -c soumith
</code></pre>

<p>を叩くだけでよい．その下にはMNISTなどの例やJupyterのチュートリアルへのリンクがあるのも丁寧．ただ，ニューラルネットワークの知識に乏しくともレイヤーを重ねて<code>scikit-learn</code>風によしなにすればよい<code>keras</code>よりは難しいが，その分柔軟に書けそう．メモリを大量消費する<code>TensorFlow</code>に較べて，GPUに対する負荷はかなり小さそう．</p>

<hr />

<p>基本的には<code>nn.Module</code>を継承してネットワークを定義する． 以下のコードは<a href="https://github.com/moskomule/pytorch_learn/blob/master/simple/mnist.py">Github</a>に挙げた．</p>

<pre><code>class Net(nn.Module):
  def __init__(self):
    super(Net, self).__init__()
    self.conv1 = nn.Conv2d(in_channels=1, out_channels=10,
                           kernel_size=5,
                           stride=1)
    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
    self.conv2_bn = nn.BatchNorm2d(20)
    self.dense1 = nn.Linear(in_features=320, out_features=50)
    self.dense1_bn = nn.BatchNorm1d(50)
    self.dense2 = nn.Linear(50, 10)

  def forward(self, x):
    x = F.relu(F.max_pool2d(self.conv1(x), 2))
    x = F.relu(F.max_pool2d(self.conv2_bn(self.conv2(x)), 2))
    x = x.view(-1, 320) #reshape
    x = F.relu(self.dense1_bn(self.dense1(x)))
    x = F.relu(self.dense2(x))
    return F.log_softmax(x)
</code></pre>

<p><code>__init__</code>で層を用意して<code>forward</code>でレイヤーを繋げる感じ．各レイヤーでは入力数と出力数を明示する必要があって，<code>keras</code>慣れしていたので畳み込み数の入出力数が分からず最初は戸惑ってしまった．</p>

<pre><code>model = Net()

optimizer = optim.Adam(model.parameters(),lr=5e-4)

model.train()
for batch_idx, (data, target) in enumerate(train_loader):
  data, target = Variable(data), Variable(target)
  optimizer.zero_grad() # optimizerの勾配を0にする
  output = model(data)
  loss = F.nll_loss(output, target) # negative log likelihood loss
  loss.backward() # 逆伝播させる
  optimizer.step() # 進める
</code></pre>

<p><code>train_loader</code>から出てきた<code>data</code>,<code>target</code>は<code>Tensor</code>型だが，そのままではネットワークに渡せないので<code>Variable</code>で包む．<code>Chainer</code>もこのような感じで，<code>Tensorflow</code>では<code>placeholder</code>と呼ばれているもの．<code>keras</code>では何も考えずに<code>Numpy</code>配列のまま与えられたので気をつけないと．</p>

<hr />

<p><code>Keras</code>でRNNを書こうとしたら，難しそうだったのでこうして<code>Pytorch</code>を触っているのだけれども，<code>Chainer</code>とどちらの方がいいのだろうか．</p>

      
      
      
    </article>
    


  </main>
  
  <nav class="pagination-single">
    
      <span class="previous">&larr; <a href="http://mosko.tokyo/post/mnist_kuzushiji/" rel="prev">「日本古典籍字形データセット」で遊ぶ</a></span>
    
    
      <span class="next"><a href="http://mosko.tokyo/post/pytorch_text_generation/" rel="next">PyTorchでテキスト生成</a> &rarr;</span>
    
  </nav>


  
  <footer role="contentinfo">
    <div style="text-align:center;">
      
      Written by Ryuichiro Hataya
    </div>
  </footer>


</div>

<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



</body>
</html>

