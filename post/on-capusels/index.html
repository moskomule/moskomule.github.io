<!DOCTYPE HTML>

<html>

<head>
    <title>
        Dynamic Routing Between Capsules | moskomule log
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="/css/font-awesome.min.css" />
    <link rel="stylesheet" href="/css/highlight_monokai.css" />
    <link rel="stylesheet" href="/css/material-components-web.css" />

    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha256-tkzDFSl16wERzhCWg0ge2tON2+D6Qe9iEaJqM4ZGd4E=" crossorigin="anonymous" type="text/css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha256-gNVpJCw01Tg4rruvtWJp9vS0rRchXP2YF+U+b2lp8Po=" crossorigin="anonymous" type="text/javascript"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha256-ExtbCSBuYA7kq1Pz362ibde9nnsHYPt6JxuxYeZbU+c=" crossorigin="anonymous" type="text/javascript"></script>
    <link rel="stylesheet" href="/css/custom.css" />
</head>

<body>
    <div class="top">
        
        <div class="mdc-toolbar mdc-toolbar--fixed mdc-toolbar--waterfall mdc-toolbar--flexible mdc-toolbar--flexible-default-behavior mdc-toolbar--flexible-space-maximized">
            <div class="mdc-toolbar__row">
                <section class="mdc-toolbar__section mdc-toolbar__section--align-start">
                    <button class="header-menu material-icons mdc-toolbar__icon--menu">menu</button>
                    <span class="mdc-toolbar__title">Dynamic Routing Between Capsules | moskomule log</span>
                </section>
                <section class="mdc-toolbar__section mdc-toolbar__section--align-end" role="toolbar">
                    
                </section>
            </div>
        </div>

        
        <aside class="mdc-temporary-drawer">
            <nav class="mdc-temporary-drawer__drawer">
                <header class="mdc-temporary-drawer__header">
                    <div class="mdc-temporary-drawer__header-content mdc-theme--primary-bg mdc-theme--text-primary-on-primary">
                        <div id="introduction">
                            <a href="https://mosko.tokyo/" class="mdc-list">
                                moskomule log
                            </a>
                        </div>
                    </div>
                </header>
                <nav class="mdc-temporary-drawer__content mdc-list-group">
                    <div id="icon-with-text" class="mdc-list">
                        <a class="mdc-list-item" href="/#about">
                            <i class="material-icons mdc-list-item__start-detail" aria-hidden="true">star</i>About
                        </a>
                        <a class="mdc-list-item" href="/#articles">
                            <i class="material-icons mdc-list-item__start-detail" aria-hidden="true">book</i>Articles
                        </a>
                    </div>
                    <hr class="mdc-list-divider">
                    <div class="mdc-list">
                        <a class="mdc-list-item" href="/#contact">
                            <i class="material-icons mdc-list-item__start-detail" aria-hidden="true">send</i>Contact
                        </a>
                    </div>
                    <hr class="mdc-list-divider" />
                    
                    <div class="mdc-list social">
                        <a class="mdc-list-item" href="https://twitter.com/mosko_mule">
                            <i class="fa fa-2x fa-twitter" aria-hidden="true"></i> twitter
                        </a>
                    </div>
                    
                    <div class="mdc-list social">
                        <a class="mdc-list-item" href="https://github.com/moskomule">
                            <i class="fa fa-2x fa-github" aria-hidden="true"></i> github
                        </a>
                    </div>
                    

                    
                    
                    
                    <hr class="mdc-list-divider">
                    
                    
                    <div class="languages">
                        <a class="mdc-list-item selected_lang" href="https://mosko.tokyo/ja">
                            <i class="material-icons mdc-list-item__start-detail">language</i> <span>日本語</span>
                        </a>
                    </div>
                    
                    
                    <div class="languages">
                        <a class="mdc-list-item " href="https://mosko.tokyo/en">
                            <i class="material-icons mdc-list-item__start-detail">language</i> <span>English</span>
                        </a>
                    </div>
                    
                    

                </nav>
            </nav>
        </aside>
    </div>
    <main>
        <div class="mdc-toolbar-fixed-adjust"></div>



<div id="main">
    <div class="container">
        <div class="article-header">
            <h1>Dynamic Routing Between Capsules</h1>
            <div class="meta-data">
                Nov 13, 2017 &nbsp;  <span class="article-tag"><a href="/tags/deep-learning">#Deep Learning</a></span>&nbsp;  <span class="article-tag"><a href="/tags/capsules">#Capsules</a></span>&nbsp; 
            </div>
        </div>
        <aside>
            <nav id="TableOfContents">
<ul>
<li><a href="#はじめに">はじめに</a></li>
<li><a href="#cnnの問題点">CNNの問題点</a></li>
<li><a href="#but-my-capsules-can-do">“But my CAPSULES can do”</a>
<ul>
<li><a href="#capsules">Capsules</a></li>
<li><a href="#routing">routing</a></li>
</ul></li>
<li><a href="#capsnet">CapsNet</a>
<ul>
<li><a href="#アーキテクチャ">アーキテクチャ</a></li>
<li><a href="#学習方法">学習方法</a></li>
</ul></li>
<li><a href="#結果">結果</a>
<ul>
<li><a href="#mnist-multi-mnist">MNIST/multi-MNIST</a></li>
<li><a href="#その他">その他</a></li>
</ul></li>
<li><a href="#まとめと感想">まとめと感想</a></li>
<li><a href="#参考">参考</a></li>
</ul>
</nav>
        </aside>
        <article>

            

<h1 id="はじめに">はじめに</h1>

<p>ディープラーニングの帝王<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>Geoffrey Hinton先生が20年来温め続けてきたというCapsules Network(CapsNet)を実装し成果を出して論文を出しました（<a href="https://arxiv.org/abs/1710.09829">Dynamic Routing Between Capsules</a>）．この記事ではこのCapsNetについて簡単にまとめます．</p>

<p>Hinton先生の業績は並べても感嘆するばかりで仕方ないのですが，帝王でおはしますと同時に認知心理学者でもあります．このCapsules Networkも脳のコラム構造を真似ることでCNNよりも人間の認知機能に近い認識器をつくることが目標です．</p>

<p>本論文の要点は以下の通りです．</p>

<ul>
<li>今まで重みと入力の内積というスカラーの塊であった層を，Capsulesという「ベクトルの塊」とすることで「姿勢」などの情報を扱えるようにした．</li>
<li>層間のCapsulesの結合（routing）を学習できるようにした．</li>
<li>実際にCapsulesを用いた3層のネットワーク（CapsNet）を構築した．</li>
<li>CapsNetはデータ拡張なしにMNISTのテストエラー0.25%を達成した．</li>
<li>文字が重なったMNISTに対してもAttentionを用いた複雑なネットワークと同等以上の性能を発揮した．</li>
</ul>

<h1 id="cnnの問題点">CNNの問題点</h1>

<p>さて，Hinton先生は度々（AlexNet登場以前から！）畳み込みニューラルネットワーク（CNN）の問題点を指摘しており，Capsulesはその解決策のひとつでもあります．</p>

<p>各所で&rdquo;What is wrong with Convolutional Neural Nets&rdquo;という題の講演を行っているようです．（<a href="https://github.com/WalnutiQ/walnut/issues/157">受講者のノート</a>，<a href="http://moreisdifferent.com/2017/09/hinton-whats-wrong-with-CNNs">まとめ</a>）．</p>


<div style="position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/Mqt8fs6ZbHk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" allowfullscreen frameborder="0" title="YouTube Video"></iframe>
 </div>


<hr />

<p>LeNetにはじまるCNNでは，ゆがみや並行移動に対する不変性を得るためにpooling（sub-sampling）が行われます．これは却って，位置に関する重要な情報を取り去って特徴を学習していることに他なりません．</p>

<p>従ってCNNでは，以下の図のように位置関係を無視して「目」や「口」といった個々の特徴のみで画像を認識することとなり，左図のようなそれぞれの要素がばらばらのものも右図のような顔であるものも同じように認識してしまいます．</p>

<p>一方で人間などの認知では目鼻と顔の階層関係から顔であることを認識しているので，両者を区別することができます．言及はされていませんがイラストや顔文字，さらに一部が隠れた顔をも顔と認識できるのもこのお陰でしょう．</p>


<figure>
    
        <img src="/img/post/caps/face1.png" />
    
    
    <figcaption>
        <h4>CNNは位置を無視してしまうので左の画像も右の画像も同じ特徴を持った「人」であると認識してしまう．</h4>
        
    </figcaption>
    
</figure>


<p>またCNNでは同じものに対しても，僅かな差異を学習するために大量のデータとデータ拡張を必要とします．</p>

<p>以下に「傾いた人の顔」を示しましたが，CNNでこれを「人」と認識するためには，そのような多くのデータによる学習が不可欠です．更に，これによって認識できるようになって右の画像が「人」であることは分かっても，「傾いた人の顔」であるかどうかは分かりません．</p>

<p>一方で人間などの認知ではたとえ「傾いた人の顔」を見たことがなくても，例えば鼻の傾きから座標を割り出して画像が「人の顔」であり更に「傾いている」ことが分かります．</p>


<figure>
    
        <img src="/img/post/caps/face2.png" />
    
    
    <figcaption>
        <h4>CNNでは右の画像が「人」であることを学習するのに多くのデータとデータ拡張を要するが，それでも「傾いた人の顔」であることは分からない．</h4>
        
    </figcaption>
    
</figure>


<h1 id="but-my-capsules-can-do">“But my CAPSULES can do”</h1>

<p>一方のCapsNetでは位置や姿勢などの情報をcapsuleというベクトルの形で保持し，capsule同士が階層的な「構文木」をなすように結合の仕方（routing）を学習します．Capsulesは脳にあるコラム構造に影響を受けているようです．</p>

<h2 id="capsules">Capsules</h2>

<p>各capsuleには階層によって異なりますが「目」や「顔」などが対応します<sup class="footnote-ref" id="fnref:2"><a href="#fn:2">2</a></sup>．capsuleはベクトルで，長さがそのcapsuleに対応するものが存在する確率であり，各要素が位置や姿勢を表します．</p>

<p>$l+1$層目のcapsule $j$は$l$層目のcapsulesの出力に，以下で説明するroutingを施した入力$s_j$を受けます．これはそのままでは上記の条件を満たさないので以下のsquashing（押し潰し）によって，$[0,1)$に閉じ込めます．</p>

<p>\[v_j=\frac{|s_j|^2}{1+|s_j|^2}\frac{s_j}{|s_j}\]</p>


<figure>
    
        <img src="/img/post/caps/caps.png" />
    
    
    <figcaption>
        <h4>$l,l&#43;1$層での記号の関係．</h4>
        
    </figcaption>
    
</figure>


<h2 id="routing">routing</h2>

<p>「目」のcapsuleと「顔」のcapsuleとは結びつくべきですが，「花」のcapsuleとは結びつくことはありません．これを学習するのがroutingであり，ここでは特に本論文で提案されているdynamic routingを扱います．このほかにEMアルゴリズムを用いた手法も<a href="https://openreview.net/forum?id=HJWLfGWRb">何者かによって提案されています</a>．</p>

<p>$l+1$層目のcapsule $j$が$l$層目のcapsules $i$の出力を受けます．先ほどのroutingされた$j$への入力$s_j$は以下によって計算されます．capsule $i$の出力を$u_i(=v_i)$とします．</p>

<p>\[s_j=\sum_i c_{ij}\hat{u}_{j|i}~~(\hat{u}_{j|i}=W_{ij}u_i)\]</p>

<p>ただし$c_{ij}$は$b_{ij}\leftarrow b_{ij}+\hat{u}_{j|i}\cdot v_j$と逐次的に更新される$b_{ij}$によって</p>

<p>\[c_{ij}=\mathrm{softmax}(b_{ij})=\frac{\exp(b_{ij})}{\sum_k\exp(b_{ik})}\]</p>

<p>と表される係数です．$\hat{u}_{j|i}\cdot v_j$はagreement（一致）と呼ばれる量で$i,j$の接続の強さを表します．</p>

<p>ここで入力として顔写真，$i$として「目」「鼻」，$j$として「顔」「花」を考えてみましょう．入力画像の中に顔があるとき，目があれば顔があり，また鼻があれば顔がありますが，花はありません．そのため適当な重みによって，鼻があるもとでの顔$\hat{u}_{\text{顔}|\text{鼻}}$や，目があるもとでの顔$\hat{u}_{\text{顔}|\text{目}}$と$v_{\text{顔}}$は近くなり，一方で$v_{\text{花}}$とは遠くなるようにすることができるでしょう．またその時$|v_{\text{顔}}|$は1に近く，$|v_{\text{花}}|$は0に近いことが求められます．従って，この時，$c_{\text{鼻顔}}$や$c_{\text{目顔}}$は大きく$c_{\text{鼻花}}$や$$c_{\text{目花}}$$は小さくなることが期待できます．</p>

<p>こうして$i\times j$通りの組み合わせから重要な組み合わせを見つけていくのでdynamic routingなのではないかと忖度しています．</p>

<!-- 逐次更新によって$\hat{u}\_{\text{顔}|\text{鼻}}\cdot v\_{\text{顔}}$は大きくなるので$c\_{\text{鼻顔}}$が大きくなり$c\_{\text{鼻花}}$は小さくなります． -->

<p>以下にroutingのアルゴリズムを載せました．</p>


<figure>
    
        <img src="/img/post/caps/algorithm.png" />
    
    
    <figcaption>
        <h4>routingのアルゴリズム．</h4>
        
    </figcaption>
    
</figure>


<h1 id="capsnet">CapsNet</h1>

<h2 id="アーキテクチャ">アーキテクチャ</h2>

<p>CapsNetのアーキテクチャは1層目が普通の畳み込み層（256チャネル，$9\times9$カーネル，ストライド1）で，ReLuを施します．2層目は畳み込みcapsule（32グループ，各8チャネル，$9\times9$カーネル，ストライド2）を施します．MNISTの場合ここまでの出力は$(8\times 32)\times6\times6$となりますが，各capsuleは$32\times6\times6$個の8次元ベクトルとなります．この各capsuleが$256\times9\times9$のカーネルをすべて見ています．</p>

<p>3層目は全結合のcapsule層で先の8次元capsule $u_i~(i=1,\ldots,32\times6\times6)$から，MNISTの場合10個16次元capsule $v_j~(j=1,\ldots,10)$に接続します．どのクラスに分類されるかは$|v_j|$を比較します．</p>


<figure>
    
        <img src="/img/post/caps/capsnet.png" />
    
    
    <figcaption>
        <h4>CapsNetのアーキテクチャ．1層目は普通の畳み込み層，2層目は畳み込みcapsule層，3層目は全結合capsule層．</h4>
        
    </figcaption>
    
</figure>


<h2 id="学習方法">学習方法</h2>

<p>分類に対する損失函数は最終層の各capsulesについてとります．これはラベルクラス$k$に対しては</p>

<p>\[L_k=\max(0, m^{+}-|v_k|)^2\]</p>

<p>ラベルのないクラス$-k$に対しては</p>

<p>\[L_{-k}=\lambda\max(0,|v_{-k}|-m^{-})^2\]</p>

<p>によって与えられます．$(m^{+},m^{-})=(0.9,0.1),~\lambda=0.5$が提案値で，これを誤差逆伝播によって伝播させて学習を行います．論文ではAdam Optimizerが用いられています．</p>

<p>また，学習の正規化のために画像の再構成を行い，その再構成損失$R$を上の分類損失に加えます．画像の再構成はラベルが$k$であるときに最終層のcapsule $v_k$を3層の全結合のネットワーク($16\to512$,$512\to1024$,$1024\to784$)によって行います．ただしこの$784$はMNISTの画像サイズ$28\times28$です．</p>

<p>以上から，損失は充分に小さい$\alpha$によって</p>

<p>\[L_k+\sum_{-k}L_{-k}+\alpha R\]</p>

<p>と与えられます．$\alpha$は論文中では0.0005が用いられています．</p>

<h1 id="結果">結果</h1>

<p>結果の一部をあげます．</p>

<h2 id="mnist-multi-mnist">MNIST/multi-MNIST</h2>

<p>MNISTではデータ拡張やアンサンブルを用いずにエラー率0.25%を達成しました．また重なりのあるmulti-MNISTでも高い性能を発揮しています．またMNISTにAffine変換を施したものに対しても認識を行うことができます．</p>

<p>
<figure>
    
        <img src="/img/post/caps/mnist.png" />
    
    
    <figcaption>
        <h4>MNISTによる結果．</h4>
        
    </figcaption>
    
</figure>


<figure>
    
        <img src="/img/post/caps/multimnist.png" />
    
    
    <figcaption>
        <h4>multi-MNISTの入力と再構成の結果．</h4>
        
    </figcaption>
    
</figure>
</p>

<h2 id="その他">その他</h2>

<p>CIFAR10やsmallNORBなどでの結果も報告しているのですが，データ拡張やアンサンブルを用いており，気になりました．</p>

<h1 id="まとめと感想">まとめと感想</h1>

<p>簡単にCapsNetについてまとめました．</p>

<p>脳のコラム構造に示唆を受けたcapsulesを導入することで，単純な構造にも関わらず，従来の畳み込みニューラルネットワークと比較できる性能を発揮しています．</p>

<p>一方で，かつてのCNNのAutoEncoderような部分など，改善できそうな箇所多くあります．またCIFAR10などにはデータ拡張やアンサンブルを用いるなど，データによっては期待される機能が発揮できないように思えるところもあります．更にcapsuleが「構文木」を構築するという仮説は検証されていないなど，不思議な点も多いです．今後，帝王に恐れずどんどん反駁や，改善手法が出てくることを期待します．</p>

<h1 id="参考">参考</h1>

<p>上記の他に以下を参考にしました．</p>

<ul>
<li><p><a href="http://cseweb.ucsd.edu/~gary/cs200/s12/Hinton.pdf">Does the Brain do Inverse Graphics?</a></p></li>

<li><p><a href="https://kndrck.co/posts/capsule_networks_explained/">Capsule Networks Explained</a></p></li>
</ul>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1">文献によって異なりますが，「Hinton,Bengio,LeCun」の三聖とするもの，Andrew Ngを足して四天王とするもの，女帝FeiFei Liを加えたものが見られますが常に筆頭はHinton先生です．
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
<li id="fn:2">厳密に対応しているかは分かりませんが，対応していることが期待されます．
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>
</ol>
</div>


        </article>
        <nav class="pagination-single">
            
            <span class="previous">&larr; <a href="https://mosko.tokyo/notes/info_ml/4/" rel="prev">情報論的学習理論4</a></span>  
            <span class="next"><a href="https://mosko.tokyo/notes/info_ml/5/" rel="next">情報論的学習理論5</a> &rarr;</span> 
        </nav>

        <div class="disqus-comments">
            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "moskomule-log" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        </div>
    </div>

</div>


<footer class="copyright">

    
    <span class="copyright">
                <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="クリエイティブ・コモンズ・ライセンス" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/80x15.png" /></a>&nbspWritten by Ryuichiro Hataya, Powered by <a href="https://gohugo.io/">Hugo</a>
    </span>

</footer>
</div>
</main>




<script type="text/javascript" src="/js/highlight.pack.js"></script>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>


<script type="text/javascript" src="/js/material-components-web.js"></script>
<script type="text/javascript">
    var drawerEl = document.querySelector('.mdc-temporary-drawer');
    var MDCTemporaryDrawer = mdc.drawer.MDCTemporaryDrawer;
    var drawer = new MDCTemporaryDrawer(drawerEl);
    document.querySelector('.header-menu').addEventListener('click', function() {
        drawer.open = true;
    });
    drawerEl.addEventListener('MDCTemporaryDrawer:open', function() {
        console.log('Received MDCTemporaryDrawer:open');
    });
    drawerEl.addEventListener('MDCTemporaryDrawer:close', function() {
        console.log('Received MDCTemporaryDrawer:close');
    });
</script>

<script type="text/javascript">
    (function() {
        var pollId = 0;
        pollId = setInterval(function() {
            var pos = getComputedStyle(document.querySelector('.mdc-toolbar')).position;
            if (pos === 'fixed' || pos === 'relative') {
                init();
                clearInterval(pollId);
            }
        }, 250);

        function init() {
            var toolbar = mdc.toolbar.MDCToolbar.attachTo(document.querySelector('.mdc-toolbar'));
            toolbar.listen('MDCToolbar:change', function(evt) {
                var flexibleExpansionRatio = evt.detail.flexibleExpansionRatio;
                ratioSpan.innerHTML = flexibleExpansionRatio.toFixed(2);
            });
            toolbar.fixedAdjustElement = document.querySelector('.mdc-toolbar-fixed-adjust');
        }
    })();
</script>


<script>
    renderMathInElement(
        document.body, {
            delimiters: [{
                    left: "$$",
                    right: "$$",
                    display: false
                },
                {
                    left: "\\[",
                    right: "\\]",
                    display: true
                },
                {
                    left: "$",
                    right: "$",
                    display: false
                }
            ],
            ignoredTags: [
                "script",
                "noscript",
                "style",
                "textarea",
                "pre",
                "code"
            ]
        }
    );
</script>
</body>

</html>

