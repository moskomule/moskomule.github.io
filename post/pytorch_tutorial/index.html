<!DOCTYPE HTML>

<html>

<head>
    <title>
        PyTorchでディープラーニング | moskomule log
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="/css/font-awesome.min.css" />
    <link rel="stylesheet" href="/css/highlight_monokai.css" />
    <link rel="stylesheet" href="/css/material-components-web.css" />

    
    <link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha256-tkzDFSl16wERzhCWg0ge2tON2+D6Qe9iEaJqM4ZGd4E=" crossorigin="anonymous" type="text/css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha256-gNVpJCw01Tg4rruvtWJp9vS0rRchXP2YF+U+b2lp8Po=" crossorigin="anonymous" type="text/javascript"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha256-ExtbCSBuYA7kq1Pz362ibde9nnsHYPt6JxuxYeZbU+c=" crossorigin="anonymous" type="text/javascript"></script>
    <link rel="stylesheet" href="/css/custom.css" />
</head>

<body>
    <div class="top">
        
        <div class="mdc-toolbar mdc-toolbar--fixed mdc-toolbar--waterfall mdc-toolbar--flexible mdc-toolbar--flexible-default-behavior mdc-toolbar--flexible-space-maximized">
            <div class="mdc-toolbar__row">
                <section class="mdc-toolbar__section mdc-toolbar__section--align-start">
                    <button class="header-menu material-icons mdc-toolbar__icon--menu">menu</button>
                    <span class="mdc-toolbar__title">PyTorchでディープラーニング | moskomule log</span>
                </section>
                <section class="mdc-toolbar__section mdc-toolbar__section--align-end" role="toolbar">
                    
                </section>
            </div>
        </div>

        
        <aside class="mdc-temporary-drawer">
            <nav class="mdc-temporary-drawer__drawer">
                <header class="mdc-temporary-drawer__header">
                    <div class="mdc-temporary-drawer__header-content mdc-theme--primary-bg mdc-theme--text-primary-on-primary">
                        <div id="introduction">
                            <a href="https://mosko.tokyo/" class="mdc-list">
                                moskomule log
                            </a>
                        </div>
                    </div>
                </header>
                <nav class="mdc-temporary-drawer__content mdc-list-group">
                    <div id="icon-with-text" class="mdc-list">
                        <a class="mdc-list-item" href="/#about">
                            <i class="material-icons mdc-list-item__start-detail" aria-hidden="true">star</i>About
                        </a>
                        <a class="mdc-list-item" href="/#articles">
                            <i class="material-icons mdc-list-item__start-detail" aria-hidden="true">book</i>Articles
                        </a>
                    </div>
                    <hr class="mdc-list-divider">
                    <div class="mdc-list">
                        <a class="mdc-list-item" href="/#contact">
                            <i class="material-icons mdc-list-item__start-detail" aria-hidden="true">send</i>Contact
                        </a>
                    </div>
                    <hr class="mdc-list-divider" />
                    
                    <div class="mdc-list social">
                        <a class="mdc-list-item" href="https://twitter.com/mosko_mule">
                            <i class="fa fa-2x fa-twitter" aria-hidden="true"></i> twitter
                        </a>
                    </div>
                    
                    <div class="mdc-list social">
                        <a class="mdc-list-item" href="https://github.com/moskomule">
                            <i class="fa fa-2x fa-github" aria-hidden="true"></i> github
                        </a>
                    </div>
                    

                    
                    
                    
                    <hr class="mdc-list-divider">
                    
                    
                    <div class="languages">
                        <a class="mdc-list-item selected_lang" href="https://mosko.tokyo/ja">
                            <i class="material-icons mdc-list-item__start-detail">language</i> <span>日本語</span>
                        </a>
                    </div>
                    
                    
                    <div class="languages">
                        <a class="mdc-list-item " href="https://mosko.tokyo/en">
                            <i class="material-icons mdc-list-item__start-detail">language</i> <span>English</span>
                        </a>
                    </div>
                    
                    

                </nav>
            </nav>
        </aside>
    </div>
    <main>
        <div class="mdc-toolbar-fixed-adjust"></div>



<div id="main">
    <div class="container">
        <div class="article-header">
            <h1>PyTorchでディープラーニング</h1>
            <div class="meta-data">
                Jun 8, 2017 &nbsp;  <span class="article-tag"><a href="/tags/pytorch">#PyTorch</a></span>&nbsp;  <span class="article-tag"><a href="/tags/python">#Python</a></span>&nbsp; 
            </div>
        </div>
        <aside>
            <nav id="TableOfContents">
<ul>
<li><a href="#pytorchとは">PyTorchとは</a></li>
<li><a href="#チュートリアル">チュートリアル</a>
<ul>
<li><a href="#インストール">インストール</a></li>
<li><a href="#tensor"><em>Tensor</em></a></li>
<li><a href="#variable"><em>Variable</em></a></li>
<li><a href="#mnistの分類">MNISTの分類</a></li>
<li><a href="#nn"><em>nn</em></a></li>
<li><a href="#さらに複雑なモデルを書くには">さらに複雑なモデルを書くには</a></li>
</ul></li>
<li><a href="#リンク集">リンク集</a></li>
</ul>
</nav>
        </aside>
        <article>

            

<h1 id="pytorchとは">PyTorchとは</h1>

<p>PyTorchはFacebookの開発するPython上でのテンソル計算・自動微分ライブラリで，特にディープラーニングに必要な機能が充実しています．2017年の初頭に公開され，瞬く間にTensorflow, Keras, Caffeに続くディープラーニングライブラリとして人気を博すこととなりました．</p>

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Bonus: stars (not an indicator of usage, just proportional to how many people have landed on the GitHub page over the period). <a href="https://t.co/IugHJqHSii">pic.twitter.com/IugHJqHSii</a></p>&mdash; François Chollet (@fchollet) <a href="https://twitter.com/fchollet/status/852195774880526336?ref_src=twsrc%5Etfw">April 12, 2017</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<p>PyTorchはPreferred NetworkのディープラーニングライブラリChainerから影響を受けており，GoogleのTensorFlowやUniversité de MontréalのTheanoとは異なり，実行時に動的にグラフを構築するため，柔軟なコードを書くことができます．</p>

<p>PyTorchは，製品にも用いられているTensorFlowとは異なり，研究向けであることが明言されています．新機能の変更は多いものの，疎テンソルにいち早く対応するなど，最新の研究動向を追うにはよいのではないでしょうか．また，適当なレベルで書くことができて，素のTensorflowのように低レベルでもなく，Kerasの様に高度に抽象化されているわけでもなく，ラッパーによって書き方が多様でサンプルを見てもよく分からない，ということはないので，学びやすいと思います．</p>

<h1 id="チュートリアル">チュートリアル</h1>

<p>とりあえず動かせるようになるチュートリアルです．</p>

<h2 id="インストール">インストール</h2>

<p>GPU環境は勿論，CPU環境でも動かすことができます．Linux，macOSの場合は <a href="http://pytorch.org/">公式</a>,
Windowsの場合は <a href="https://anaconda.org/peterjc123/pytorch">Anaconda Cloud</a>からインストールできます．</p>

<p>GPUを利用する場合，環境の設定が面倒なことが多いですがPyTorchでは特に設定せずにGPU対応版をダウンロードするとGPUが使えるようになる<a href="https://discuss.pytorch.org/t/newbie-question-what-are-the-prerequisites-for-running-pytorch-with-gpu/698">ようです</a>．</p>

<h2 id="tensor"><em>Tensor</em></h2>

<p>PyTorchの基本はテンソルを操作する<code>Tensor</code>です．テンソルというと難しく聞こえますが，この場合は多次元配列と同義で，物理学のテンソルのような共変・反変を意識する必要はありません．慣例に従ってテンソル，と言う語を用います．</p>

<p>PyTorchにおける<code>Tensor</code>は端的に言えば「GPU上でも動く<code>numpy.ndarray</code>のようなもの」ですが，違いも多いので注意が必要です．例えば</p>

<pre><code class="language-python">import numpy as np
import torch  # PyTorch
&gt;&gt;&gt; np_tensor = np.zeros([1, 2, 3])
array([[[ 0.,  0.,  0.],
        [ 0.,  0.,  0.]]])

&gt;&gt;&gt; np_tensor.shape
(1, 2, 3)

&gt;&gt;&gt; torch_tensor = torch.zeros(1, 2, 3)
(0 ,.,.) =
  0  0  0
  0  0  0
[torch.FloatTensor of size 1x2x3]

&gt;&gt;&gt; torch_tensor.size()
torch.Size([1, 2, 3])
</code></pre>

<p>などです．なお，<code>numpy</code>の配列は</p>

<pre><code class="language-python">&gt;&gt;&gt; torch.from_numpy(np_tensor)
(0 ,.,.) =
  0  0  0
  0  0  0
[torch.DoubleTensor of size 1x2x3]
</code></pre>

<p>によって<code>Tensor</code>に変換されます．上記の<code>torch.**Tensor</code>はCPU上で計算を行いますが，GPUを用いる場合には<code>torch_tensor.cuda()</code>によって<code>torch.cuda.**Tensor</code>に変換します．反対に，GPUからCPUに移す場合は<code>torch_gpu_tensor.cpu()</code>です．</p>

<p>ほかのライブラリとの違いとして，画像のテンソルが$\text{ミニバッチ数}\times\text{チャンネル数}\times\text{高さ}\times\text{幅}$であることが挙げられます．</p>

<h2 id="variable"><em>Variable</em></h2>

<p><code>Variable</code>は<code>Tensor</code>と今までの計算の履歴を保持しており，計算グラフの葉(leaf)の勾配を得ることができます．</p>

<p><code>Tensor</code>は<code>Variable(torch_tensor)</code>によって<code>Variable</code>とすることができます．逆に<code>Variable</code>内の<code>Tensor</code>は<code>var.data</code>によって取り出すことができます．</p>

<pre><code class="language-python">from torch.autograd import Variable
&gt;&gt;&gt; a = Variable(torch.Tensor([3, 2]))
&gt;&gt;&gt; a.requires_grad = True
&gt;&gt;&gt; b = a * a * a
&gt;&gt;&gt; c = torch.sum(b)
&gt;&gt;&gt; c.backward()
&gt;&gt;&gt; a.grad
Variable containing:
 27
 12
[torch.FloatTensor of size 2]
</code></pre>

<p>つまり$c=\sum_i b_i=\sum_i a_i^3$に対して，$\frac{\partial c}{\partial a_i}=3a_i^2$なので$3\times(a_0^2, a_1^2)=(27, 12)$となります．</p>

<p>実際のニューラルネットワークでは下の図のように，<code>Variable</code>が<code>Conv2d</code>などのレイヤーに葉として接続しています．誤差逆伝播を行うことで葉のテンソルを更新していきます．</p>


<figure >
    
        <img src="/img/post/pytorch/graph.png" />
    
    
    <figcaption>
        <h4>計算グラフの一部</h4>
        
    </figcaption>
    
</figure>


<h2 id="mnistの分類">MNISTの分類</h2>

<p>ここまで扱った範囲だけで簡単なネットワークをつくることができます<sup class="footnote-ref" id="fnref:1"><a rel="footnote" href="#fn:1">1</a></sup>．手書きの数字認識を行ってみましょう．</p>

<p>手書き数字認識の課題には<a href="http://yann.lecun.com/exdb/mnist/">MNIST</a>というデータセットがよく用いられます．</p>

<p>weight $W\in\mathcal{R}^{10\times(28\times 28)}$ とbias $b\in\mathcal{R}^{10}$に対してMNISTの画像の入力$x\in\mathcal{R}^{(28\times 28)}$を与え，その$\mathrm{log softmax}$をとった$y\in\mathcal{R}^{10}$を出力とします．ここで$\displaystyle \mathrm{softmax}(z)=\frac{e^{z_i}}{\sum_je^{z_j}}$です．</p>

<p>\[y=\ln\text{softmax}(Wx+b)\]</p>

<p>損失函数lossにはnegative log likelihood(NLL)を用い，これを最小化します．$t$を目標のラベルだとすると，</p>

<p>\[-y_t\]</p>

<p>です．これが最小になるのは$y_t=0$つまり，$\text{softmax}(Wx+b)$の第$t$要素が1，ほかが0となるときです．以上が順伝播のフェーズです．</p>

<p>weight, biasの更新は</p>

<p>\[w \leftarrow w - \mathit{lr}\nabla_w\text{loss}\]</p>

<p>です．誤差を元に重みを更新していく過程が逆伝播です．</p>

<pre><code class="language-python"># simplified code!
weight = Variable(torch.randn(28*28, 10), requires_grad=True)
bias = Variable(torch.randn(10), requires_grad=True)
lr = 0.001

for epoch in range(2):
    for (input, target) in train_loader:
       input, target = Variable(input), Variable(target)
       input = input.view(-1, 28*28)
       # weight, biasの勾配を0にする
       weight.grad.data.zero_()
       bias.grad.data.zero_()

       # 順伝播
       output = F.log_softmax(input.mm(weight).add(bias))
       loss = F.nll_loss(output, target)

       # 逆伝播
       loss.backward()

       # weight, biasの更新
       weight.data -= lr * weight.grad.data
       bias.data -=  lr * bias.grad.data

correct =  0
for (input, target) in test_loader:
    input, target = Variable(input), Variable(target)
    input = input.view(-1, 28*28)
    output = F.log_softmax(input.mm(weight).add(bias))
    pred = output.data.max(1)[1]
    correct += pred.eq(target.data).sum()
</code></pre>

<p>2エポックでも87％ほどの精度が出ました.</p>

<p>コードを見れば大体分かるかと思いますが，以下の点に注意してください．</p>

<ul>
<li><p><code>input = input.view(-1, 28*28)</code>では $28\times 28$ のMNISTの画像を1次元にして，ベクトルとして扱っています．<code>view</code>を行うためにはメモリ上において連続である必要があるので，<code>torch.contiguous()</code>によって連続にすることが必要な場合があります．</p></li>

<li><p><code>F</code>は<code>torch.nn.functional</code>のことで，ニューラルネットワークに必要な函数類があります．</p></li>

<li><p><code>target</code>はonehotではなくてラベルで与えます．</p></li>
</ul>

<p>詳細は<a href="https://github.com/moskomule/pytorch.learning/blob/master/tutorial/mnist1.py">こちら</a>をご覧下さい．</p>

<h2 id="nn"><em>nn</em></h2>

<p>上述のMNISTの分類では重みを自分で定義し，手動で更新する必要がありましたが，複雑なモデルをつくっていくのは大変です．</p>

<p>PyTorchには上記が抽象化された<code>nn</code>モジュールが用意されています．<code>nn</code>を使うと上記のコードは</p>

<pre><code class="language-python">from torch import nn
from torch.nn import functional as F

class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.dense = nn.Linear(28*28, 10)

    def forward(self, x):
        x = self.dense(x)
        return F.log_softmax(x)

model = SimpleNet()
optimizer = torch.optim.SGD(model.parameters(), lr=lr)

for (input, target) in train_loader:
    data, target = Variable(data), Variable(target)
    # weight, biasの勾配を0にする
    optimizer.zero_grad()

    # 順伝播
    output = model(data)
    loss = F.nll_loss(output, target)

    # 逆伝播
    loss.backward()

    # weight, biasの更新
    optimizer.step()
...
</code></pre>

<p>のようになります．ここでは先ほどと違って<code>nn.Module</code>と<code>torch.optim.***</code>を使っています．</p>

<p><code>SimpleNet</code>の<code>__init__</code>メソッドではモデルのレイヤーやブロックを定義します．<code>forward</code>メソッドに順伝播時のデータの流れを記述していき，<code>model(input)</code>によって出力を得ます．<code>nn</code>には各種レイヤーが用意されていて，今回は全結合層，つまり$Wx+b$の<code>nn.Linear</code>を用いています．</p>

<p><code>torch.optim</code>にはSGDを初めとするoptimizerが用意されています．optimizerにモデルのパラメータを渡して，効率的に重みを更新していきます．今回は最も単純な<code>optim.SGD</code>を用いています．</p>

<h2 id="さらに複雑なモデルを書くには">さらに複雑なモデルを書くには</h2>

<p>上に示した例は1層でしたが，もちろん更に複雑なネットワークを構築することができます．ここでは例として畳み込み層2，全結合層2の畳み込みニューラルネットワーク(CNN)を考えます．</p>

<p><code>Conv2d</code>，<code>max_pool2d</code>の挙動については <a href="https://github.com/vdumoulin/conv_arithmetic">こちら</a>が分かりやすいです．</p>

<pre><code class="language-python">class Net1(nn.Module):
    def __init__(self):
        super(Net1, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1,
                               out_channels=10,
                               kernel_size=5,
                               stride=1)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.dense1 = nn.Linear(in_features=320,
                                out_features=50)
        self.dense2 = nn.Linear(50, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = F.max_pool2d(x, kernel_size=2)
        x = F.relu(x)
        x = self.conv2(x)
        x = F.max_pool2d(x, 2)
        x = F.relu(x)
        x = x.view(-1, 320)
        x = self.dense1(x)
        x = F.relu(x)
        x = self.dense2(x)
        return F.log_softmax(x)
</code></pre>

<p>以下のように書くこともできます．</p>

<pre><code class="language-python">class Net2(nn.Module):
    def __init__(self):
        super(Net2, self).__init__()
        self.head = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=10,
                      kernel_size=5, stride=1),
            nn.MaxPool2d(kernel_size=2),
            nn.ReLU(),
            nn.Conv2d(10, 20, kernel_size=5),
            nn.MaxPool2d(kernel_size=2),
            nn.ReLU())
        self.tail = nn.Sequential(
            nn.Linear(320, 50),
            nn.ReLU(),
            nn.Linear(50, 10))

    def forward(self, x):
        x = self.head(x)
        x = x.view(-1, 320)
        x = self.tail(x)
        return F.log_softmax(x)
</code></pre>

<p>両者は同一のネットワークを表していますが，</p>

<pre><code class="language-python">&gt;&gt;&gt; Net1()
Net1 (
  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (dense1): Linear (320 -&gt; 50)
  (dense2): Linear (50 -&gt; 10)
)

&gt;&gt;&gt; Net2()
Net2 (
  (head): Sequential (
    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))
    (1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
    (2): ReLU ()
    (3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
    (5): ReLU ()
  )
  (tail): Sequential (
    (0): Linear (320 -&gt; 50)
    (1): ReLU ()
    (2): Linear (50 -&gt; 10)
  )
)

&gt;&gt;&gt; Net2().head
Sequential (
  (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))
  (1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (2): ReLU ()
  (3): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))
  (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (5): ReLU ()
)
</code></pre>

<p>と違いがあります．前者は<code>forward</code>メソッドの自由度が高く，後者はブロックの一部を再利用するのに向いています．層を積んでいき，重みを再利用することの多いCNNでは後者を用いた方が便利かもしれません</p>

<h1 id="リンク集">リンク集</h1>

<p>PyTorchの基本は以上で説明できたと思います．更に知りたい方は以下をご覧下さい．</p>

<ul>
<li><a href="http://pytorch.org/docs/">Document</a></li>
<li><a href="https://github.com/pytorch">Github</a></li>
</ul>

<p>サポートが充実しているのも特徴です．</p>

<ul>
<li><a href="https://discuss.pytorch.org/">相談するところ</a></li>
<li><a href="http://pytorch.org/tutorials/">より進んだチュートリアル</a></li>
</ul>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1"><a href="https://discuss.pytorch.org/t/understanding-how-torch-nn-module-works/122">Raschka氏のdiscussion</a>を参考にしています．
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
</ol>
</div>


        </article>
        <nav class="pagination-single">
            
            <span class="previous">&larr; <a href="https://mosko.tokyo/travel/iran12/" rel="prev">イラン旅行記12日目</a></span>  
            <span class="next"><a href="https://mosko.tokyo/travel/iran13/" rel="next">イラン旅行記13日目</a> &rarr;</span> 
        </nav>

        <div class="disqus-comments">
            <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "moskomule-log" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        </div>
    </div>

</div>


<footer class="copyright">

    
    <span class="copyright">
                <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="クリエイティブ・コモンズ・ライセンス" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/80x15.png" /></a>&nbspWritten by Ryuichiro Hataya, Powered by <a href="https://gohugo.io/">Hugo</a>
    </span>

</footer>
</div>
</main>




<script type="text/javascript" src="/js/highlight.pack.js"></script>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>


<script type="text/javascript" src="/js/material-components-web.js"></script>
<script type="text/javascript">
    var drawerEl = document.querySelector('.mdc-temporary-drawer');
    var MDCTemporaryDrawer = mdc.drawer.MDCTemporaryDrawer;
    var drawer = new MDCTemporaryDrawer(drawerEl);
    document.querySelector('.header-menu').addEventListener('click', function() {
        drawer.open = true;
    });
    drawerEl.addEventListener('MDCTemporaryDrawer:open', function() {
        console.log('Received MDCTemporaryDrawer:open');
    });
    drawerEl.addEventListener('MDCTemporaryDrawer:close', function() {
        console.log('Received MDCTemporaryDrawer:close');
    });
</script>

<script type="text/javascript">
    (function() {
        var pollId = 0;
        pollId = setInterval(function() {
            var pos = getComputedStyle(document.querySelector('.mdc-toolbar')).position;
            if (pos === 'fixed' || pos === 'relative') {
                init();
                clearInterval(pollId);
            }
        }, 250);

        function init() {
            var toolbar = mdc.toolbar.MDCToolbar.attachTo(document.querySelector('.mdc-toolbar'));
            toolbar.listen('MDCToolbar:change', function(evt) {
                var flexibleExpansionRatio = evt.detail.flexibleExpansionRatio;
                ratioSpan.innerHTML = flexibleExpansionRatio.toFixed(2);
            });
            toolbar.fixedAdjustElement = document.querySelector('.mdc-toolbar-fixed-adjust');
        }
    })();
</script>


<script>
    renderMathInElement(
        document.body, {
            delimiters: [{
                    left: "$$",
                    right: "$$",
                    display: false
                },
                {
                    left: "\\[",
                    right: "\\]",
                    display: true
                },
                {
                    left: "$",
                    right: "$",
                    display: false
                }
            ],
            ignoredTags: [
                "script",
                "noscript",
                "style",
                "textarea",
                "pre",
                "code"
            ]
        }
    );
</script>
</body>

</html>

