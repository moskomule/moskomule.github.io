<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Math on moskomule log</title>
    <link>https://mosko.tokyo/tags/math/</link>
    <description>Recent content in Math on moskomule log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Wed, 12 Jul 2017 12:37:12 +0900</lastBuildDate>
    
	<atom:link href="https://mosko.tokyo/tags/math/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>最適化手法について—SGDからYellowFinまで—</title>
      <link>https://mosko.tokyo/post/optimization2/</link>
      <pubDate>Wed, 12 Jul 2017 12:37:12 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/optimization2/</guid>
      <description>はじめに 前回の記事に，「ベンチマーク函数があるよ」というフィードバックを頂きました．test functions for optimizationというWikipediaの記事にまとまっていたので，今回はこちらにあるRosenbrock function($f_{R}=100(y-x^2)^2+(x-1)^2$,大域解$f_{R}(1,1)=0$)を使います．Rosenbrock函数には大域解を含む広い濠があって大域解が見つけにくいのが特徴です．
一般に勾配法の更新方法はバッチ更新と呼ばれます．つまり勾配降下法であれば学習事例$n=1,2,\ldots,N$に対して個々の誤差函数$E_n$の和
\[E(x)=\sum_n E_n(x)\]
について$x\gets x-\alpha\nabla E$と更新していました．
確率的な(stochastic)では$n\in\{1,\ldots,N\}$を乱択して，または逐次的な(online)勾配降下法では$n=1,2,\ldots,$によって$x\gets x-\alpha\nabla E_n(x)$により更新を行います．
また，ディープラーニングの文脈では$B\subset\{1,\ldots,N\}$によって$x\gets x-\frac{\alpha}{|B|}\sum_{i\in B}\nabla E_i(x)$を更新するミニバッチ更新がしばしば用いられます．ミニバッチの大きさ$|B|$は32,64,128などがよく用いられるように思われます．この大きさが大きいほど計算は速くなりますが，あまり大きくない方が汎化性能が上がるという話もあります1．
今回紹介する手法は主にディープラーニングの文脈で用いられるため，ミニバッチ更新を行うことでよりよい性能が出せる可能性がありますが，記事中では可視化の都合もあり$x\gets x-\alpha d$によって更新を行います．
なお，表記にはこの記事特有のものも含まれていますので，その点にはお気をつけ下さい．
SGD(Stochastic Gradient Descent) 基本的に勾配降下法と同一で，以下により更新を行います．
\[x_{k+1}=x_{k}-\alpha_k\nabla f(x_{k})\]
$\alpha$の調整には段階的に$\alpha$を小さくするstep decay，$\alpha_k=\alpha_0 e^{-rk}$とするexponential decay，$\alpha_k=\frac{\alpha_0}{1+rk}$とする1/k decayなどの手法がありますが，職人の勘による調整法も多いようです．
  初期位置(-0.7, -0.7),(0, 2.5),(-1, 2)からのSGDによる1000ステップの移動の軌跡．黄色の点が大域解(1,1)．   Momentum SGDは$\nabla f(x)$が0に近い時に更新ができなくなるという問題がありました．Momentum法では
\[\begin{aligned} v_{k+1} &amp;amp;= \mu v_k-\alpha\nabla f(x_k)~,v_0=0 \cr\cr x_{k+1} &amp;amp;= x_k+v_{k+1} \end{aligned}\]
によって更新を行うことでこの問題を解決しています．またSGDは各点の勾配変化に敏感でしたが，以前の状態を引き継ぐ慣性力のようなmomentum term$v$を用いることで些細な変化に対しての感度を低下させているとみることもできます．
  初期位置(-0.7, -0.7),(0, 2.5),(-1, 2)からのmomentumつきのSGDによる1000ステップの移動の軌跡．黄色の点が大域解(1,1)．   Nestrov Accelerated Gradient Momentum法を改良し，$v_{k+1}$の更新に$x_k$よりも$x_{k+1}$に近いと期待される$x_k+\mu v_k$を用いたのがNestrov Accelerated Gradientです．</description>
    </item>
    
    <item>
      <title>最適化手法についてー勾配法，ニュートン法，準ニュートン法などー</title>
      <link>https://mosko.tokyo/post/optimization/</link>
      <pubDate>Sun, 09 Jul 2017 12:37:12 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/optimization/</guid>
      <description>以前Eve optimizerの実装を行ったのですが，肝心の非線型函数の最適化手法について知らなかったので調べました．
はじめに 最適化に関して，微分を用いない手法としてはランダム法やシンプレックス法がありますが，今回は微分を用いて反復的に解に近づく方法である反復法について述べます．
なお今回可視化に際して利用した函数は$(x+1)x(x-1)(x-3)+y^2+xy$で，2つの局所解と1つの鞍点を持ちます．
反復法 反復法は函数$f(x)$について，
\[\begin{aligned} d_k &amp;amp;= -H_k\nabla f(x_k) \cr\cr x_{k+1} &amp;amp;= x_{k}+\alpha_{k}d_{k} \end{aligned}\]
によって位置を更新しながら列$(x_k)_{k\in\mathscr{N}}$を局所解または大局解$x^{\star}$に近づけていく手法です．
実際は$k$は有限なので，適当な回数で打ち切ったり，$|x_{k+1}-x_{k}|&amp;lt;\epsilon$で中止したりします．
$x$から$x+\delta x$へと移動した際の$f$の変化$\delta f(x)$とします．$\delta f(x)=\delta x\nabla f(x)$は$\delta x$と$\nabla f(x)$とが並行の時に最大となりますので，$\nabla f(x)$は$x$において$f(x)$の値が最も変化する方向です．そのため局所的には$-\nabla f(x)$に進むのが望ましいですが，それが全体として望ましいとは必ずしもいえません．反復法ではこの方向に適当な$H_k$をかけて調整した上で，順次移動していきます．
$a_k$は学習率，ステップ幅などと呼ばれ一回の更新で進む量を表します．$\alpha_k$にはヒューリスティックな更新方法もありますが($\alpha_k \sim \frac{1}{\sqrt{k}}$など)，Armijoの基準やWolfeの基準といったより客観的な指標もあります．
\[\begin{aligned} f(x_k+\alpha_k d_k) &amp;amp;\le f(x_k)+c_1\alpha_k\nabla f(x_k)^{\top}d_k \cr\cr \nabla f(x_k+\alpha_k d_k)^{\top}d_k &amp;amp;\ge c_2\nabla f(x_k)d_k \end{aligned}\]
上の式がArmijoの基準で，2つ合わせるとWolfeの基準となります．$\alpha_k$がこの範囲に収まるように変化させていきます(line search method1)．
勾配降下法 勾配降下法(gradient descent method)，または最急降下法(steepest descent method)は$H_k=I$とする手法です．すなわち
\[x_{k+1}=x_{k}-\alpha_k\nabla f(x_{k})\]
によって更新していきます．最急方向に適当な学習率$\alpha_k$を乗じて進んでいくので「直感的には合理的」2ですが，収束が遅く，適切な学習率の調整が難しいなど，実際の性能はあまりよくありません．
  $\alpha_k=0.1$で100回の更新を行った際の$x_k$の軌跡     $\alpha_k=0.01$で100回の更新を行った際の$x_k$の軌跡     $\alpha_k=0.</description>
    </item>
    
  </channel>
</rss>