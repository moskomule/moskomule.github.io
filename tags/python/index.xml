<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on moskomule log</title>
    <link>https://mosko.tokyo/tags/python/</link>
    <description>Recent content in Python on moskomule log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Written by Ryuichiro Hataya</copyright>
    <lastBuildDate>Sat, 10 Jun 2017 15:37:12 +0900</lastBuildDate>
    
	<atom:link href="https://mosko.tokyo/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PyTorchでCNN入門</title>
      <link>https://mosko.tokyo/post/pytorch_cnn/</link>
      <pubDate>Sat, 10 Jun 2017 15:37:12 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/pytorch_cnn/</guid>
      <description>CNNの概説 CNNは畳み込みニューラルネットワーク(convolutional neural network)の略です．CNNは四天王のひとりLeCun(1989)に始まり，2012年の一般物体認識のコンテスト(ILSVRC)で優勝しディープラーニングを一躍有名にしたAlexNet(Krizhevsky)を経て，現在の画像認識には欠かせないネットワークです．
畳み込み CNNでは畳み込み(convolution)という操作を行います．ここでは簡単のためにすべて2次元で考えます．
以下のように入力の行列とフィルタが与えられたときに，
\[I=ar+bs+tc+du+ev+fw+gz+hy+iz\]
を畳み込みと呼びます．本来画像認識の分野では$ax+by+cz+\cdots$を畳み込みと呼び，上記の演算は相関と呼ばれるようですが，CNNの文脈ではこれを畳み込みと呼ぶよう1なので慣例に倣います．
 左が入力の一部，右がフィルター．   入力に対して，この操作を同じフィルタをずらしながら適用していきます．下の図では上部の入力とフィルタの畳み込み結果を下の出力行列の各要素にする様子を書きました．こうして畳み込みによる出力が得られます．
 上が入力とフィルタ，下が出力．   畳み込みは画像の対応部分とフィルタとの内積を取ることですから，それらの関連ぐらいを見ていることになります（それ故に相関と呼ばれるのですが）．従って，出力は入力画像のフィルタとの関連度を凝縮したものになるわけです．以上の畳み込み（あるいは相関）自体はCNN以前から画像認識の分野で用いられてきましたが，CNNではフィルタ自体を誤差逆伝播法で学習していく点が従来とは異なります2．
上では入力，フィルタとも1枚ずつである場合を考えましたが，一般にそれらは複数枚あり，テンソルとして扱われます．この「枚数方向」の次元はチャネルと呼ばれます．特にRGB画像は3チャネルです．
複数チャネルの場合は，入力の各チャネルに対して同一のフィルタを適用し，その和をとります．従って，出力のチャネル数はフィルタ数と一致します．
プーリング CNNではその他にプーリングという操作を行う場合もあります．その中でもよく用いられる最大プーリング(max pooling)は下に示したように，領域内の最大値を取り出して出力とする操作です．画像認識では位置がずれた同じ物体も同じものとして認識したいので，この操作を加えて位置に対する不変性を向上させます．
 最大プーリング．上部が入力で下部が出力．   最大プーリングのほかに，平均値を用いるプーリングもあります．
用語 説明に用いる画像はこちらのもので，今までと異なり下が入力，上が出力です．
kernel 上記の畳み込みのフィルタやプーリングの領域のことをカーネルと呼ぶこともあります．
stride カーネルの動く際のステップです．プーリングの場合は領域幅と同じ幅で動かし，重複する範囲がないようにすることが多い気がします．
 stride=1   padding 畳み込み，プーリングを上記のように行った場合，出力は入力よりも小さくなります．入力の周りに「枠」を付けることで出力サイズを調整するのがpaddingです．「枠」を0で埋めるゼロパディングがしばしば用いられます．
 stride=1,padding=1   dilation カーネルにあける隙間の大きさです．プーリングの代わりにdilationを用いることもあるようです．
 stride=1,dilation=1   relu 活性化函数の一つで，“rectified linear unit”の略です．函数としては
\[\mathrm{relu}(x)=\max(0,x)\]
と極めて単純ですが，これがなければ現在のディープニューラルネットワーク時代はなかった，とも言えるような，強力な存在です．以前はsigmoid函数(S字状函数)，たとえば
\[\mathrm{sigmoid}(x)=\frac{1}{1+e^{-x}}\]
が用いられていましたが，ネットワークが深くなると勾配が消失する問題を抱えていました．
 sigmoid函数とrelu函数との比較   PyTorch PyTorchの簡単なチュートリアルはこちらにあります．
コード中のFはnn.functionalのことです．
nn nn.Conv2dを用います．F.conv2dというものもありますが，こちらは自分で明示的にweight,biasのテンソルを用意し，必要であれば重みを更新しなくてはいけません．他方，nn.Conv2dであれば入出力のチャネル数およびカーネルの大きさを定めるだけです．今回は用いていませんが，上で説明したpadding,dilationを用いることもできます．
プーリングには，畳み込みのように更新すべきテンソルがないのでF.max_pool2dを用いても差はありません．</description>
    </item>
    
    <item>
      <title>PyTorchでディープラーニング</title>
      <link>https://mosko.tokyo/post/pytorch_tutorial/</link>
      <pubDate>Thu, 08 Jun 2017 16:33:50 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/pytorch_tutorial/</guid>
      <description>PyTorchとは PyTorchはFacebookの開発するPython上でのテンソル計算・自動微分ライブラリで，特にディープラーニングに必要な機能が充実しています．2017年の初頭に公開され，瞬く間にTensorflow, Keras, Caffeに続くディープラーニングライブラリとして人気を博すこととなりました．
Bonus: stars (not an indicator of usage, just proportional to how many people have landed on the GitHub page over the period). pic.twitter.com/IugHJqHSii
&amp;mdash; François Chollet (@fchollet) April 12, 2017  PyTorchはPreferred NetworkのディープラーニングライブラリChainerから影響を受けており，GoogleのTensorFlowやUniversité de MontréalのTheanoとは異なり，実行時に動的にグラフを構築するため，柔軟なコードを書くことができます．
PyTorchは，製品にも用いられているTensorFlowとは異なり，研究向けであることが明言されています．新機能の変更は多いものの，疎テンソルにいち早く対応するなど，最新の研究動向を追うにはよいのではないでしょうか．また，適当なレベルで書くことができて，素のTensorflowのように低レベルでもなく，Kerasの様に高度に抽象化されているわけでもなく，ラッパーによって書き方が多様でサンプルを見てもよく分からない，ということはないので，学びやすいと思います．
チュートリアル とりあえず動かせるようになるチュートリアルです．
インストール GPU環境は勿論，CPU環境でも動かすことができます．Linux，macOSの場合は 公式, Windowsの場合は Anaconda Cloudからインストールできます．
GPUを利用する場合，環境の設定が面倒なことが多いですがPyTorchでは特に設定せずにGPU対応版をダウンロードするとGPUが使えるようになるようです．
Tensor PyTorchの基本はテンソルを操作するTensorです．テンソルというと難しく聞こえますが，この場合は多次元配列と同義で，物理学のテンソルのような共変・反変を意識する必要はありません．慣例に従ってテンソル，と言う語を用います．
PyTorchにおけるTensorは端的に言えば「GPU上でも動くnumpy.ndarrayのようなもの」ですが，違いも多いので注意が必要です．例えば
import numpy as np import torch # PyTorch &amp;gt;&amp;gt;&amp;gt; np_tensor = np.zeros([1, 2, 3]) array([[[ 0., 0., 0.</description>
    </item>
    
    <item>
      <title>「日本古典籍字形データセット」で遊ぶ</title>
      <link>https://mosko.tokyo/post/mnist_kuzushiji/</link>
      <pubDate>Fri, 13 Jan 2017 13:18:40 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/mnist_kuzushiji/</guid>
      <description>日本語版MNIST,というわけではないけれど日本古典籍字形データセットの識別をkerasで実装したresnetによって行った．現在validation accuracyは93.3%．少なくとも自分よりはきちんと分類できるようだ．
このデータセットには2017年1月現在，「8点の画像データから切り取ったくずし字1,521文字種の字形データ86,176文字」が収録されているので，そのまま1521に分類している．
今回はMNIST的に使うので，つまり文脈を考慮しないので変体仮名の「志」（し）と漢字としての「志」とを区別する，というようなタスクも含まれてしまうが，特に考慮しない．kerasのImageDataGeneratorで前処理を一括して行う．本当はもう少し丁寧にした方がいいのかもしれないけれど，とりあえず．
 # data generator train_datagen = ImageDataGenerator( shear_range=0.05, width_shift_range=0.05, height_shift_range=0.05, rotation_range=10, fill_mode=&amp;quot;constant&amp;quot;, cval=200, zoom_range=0.2) train_generator = train_datagen.flow_from_directory( &#39;train&#39;, color_mode=&amp;quot;grayscale&amp;quot;, target_size=target_size, batch_size=batch_size, class_mode=&#39;categorical&#39; ) val_datagen = ImageDataGenerator() val_generator = val_datagen.flow_from_directory( &#39;val&#39;, color_mode=&amp;quot;grayscale&amp;quot;, target_size=target_size, batch_size=batch_size, class_mode=&#39;categorical&#39; )  training dataには変形を施した．resnetはkeras.jsを参考にして実装(下記のres_a,res_b)．
# model input_layer = Input(shape=input_shape) x = Convolution2D(nb_filters, 4, 4, subsample=(2,2))(input_layer) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = MaxPooling2D(pool_size, strides=stride_size)(x) x = res_a([32,32,128])(x) x = res_b([32,32,128])(x) x = res_b([32,32,128])(x) x = res_a([64,64,256])(x) x = res_b([64,64,256])(x) x = res_b([128,128,256])(x) x = res_a([128,128,512])(x) x = res_b([128,128,512])(x) x = res_b([256,256,512])(x) x = AveragePooling2D((4,4))(x) x = Flatten()(x) output_layer = Dense(nb_classes, activation=&#39;softmax&#39;)(x) model = Model(input=input_layer, output=output_layer) model.</description>
    </item>
    
    <item>
      <title>PythonでMySQLを使う</title>
      <link>https://mosko.tokyo/post/python-and-mysql/</link>
      <pubDate>Sat, 22 Oct 2016 00:21:34 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/python-and-mysql/</guid>
      <description>現在開発しているものはScalaで前処理を行っているので，本番の処理も本当は全部Scalaで書ければよかったのだけれども，そうは問屋が卸さず，種々の原因によりPythonが必要になってしまった． これなら最初から全部Pythonでよかったのでは，とも思うけれど，PythonはJupyterで小さなものを色々弄るのには使うものの，大きいものをPythonで書いた経験が無いので心配．型が違う，という注意が沢山出そうだ．
ともかく，そのためにPythonからMySQLを扱う必要が出てきた．Pythonists3は新しいもの好きなのか，いまやNoSQLを使うのがトレンドなのか，MySQL周りの情報が少ないのだが，pymysqlを使うことに落ち着いた．
connection = pymysql.connect(host=&amp;quot;HOSTNAME&amp;quot;, user=&amp;quot;USERNAME&amp;quot;, password=&amp;quot;PASSWORD&amp;quot;, db=&amp;quot;DB_NAME&amp;quot;, charset=&#39;utf8&#39;, cursorclass=pymysql.cursors.DictCursor) #1 with connection.cursor() as cursor: sql = &amp;quot;SELECT name FROM table WHERE id=%s&amp;quot; cursor.execute(sql, (900)) results = cursor.fetchall() for r in results: b = r[&#39;name&#39;] print(bytes.decode(b)) #2  #1を指定することで，返ってくる結果がdict形式になって分かりやすい．
最後，#2でnameに相当する列がvarbinaryであったので，文字列に変換するのにbytes.decode()が必要だった．とりあえずこれで一件落着．</description>
    </item>
    
    <item>
      <title>Jupyterをサーバー上で使う</title>
      <link>https://mosko.tokyo/post/using-jupyter-on-an-external-server/</link>
      <pubDate>Wed, 31 Aug 2016 18:30:08 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/using-jupyter-on-an-external-server/</guid>
      <description>2016-08-29 サーバー上のJupyter notebookを使う サーバー上でPythonを実行するのに，ターミナルで弄っていたが何かと不便だったのでJupyterを導入した．
jupyter notebook --generate-config vim ~/.jupyter/jupyter_notebook_config.py  でjupyter_notebook_config.pyに以下を加える．
 c.NotebookApp.ip = &#39;*&#39; # localhost以外からもアクセス可能にする。 c.NotebookApp.port = 9999 # サーバのポートを指定。デフォルト8888。 c.NotebookApp.open_browser = False # ブラウザが自動で開かないようにする。 c.NotebookApp.notebook_dir = &#39;/home/USER_NAME/notebooks&#39; # 作業ディレクトリを指定。デフォルト起動ディレクトリ。  かくして，jupyter notebookコマンドを叩くとhttp://hoge.hoge:9999でJupyterが扱える．
scikit-learnでのMKLエラー解決 Ubuntuサーバー上のAnaconda3でscikit-learnを動かしたところ
Intel MKL FATAL ERROR: Cannot load libmkl_avx.so or libmkl_def.so  というような表示が出て終了してしまう．とりあえず
conda install nomkl numpy scipy scikit-learn numexpr  で解決させたものの，MKL使った方が速そうなので早々に解決したい．MROのMKLが悪かったりするのだろうか．
参考
Jupyter Notebook（IPython）サーバの起動方法</description>
    </item>
    
  </channel>
</rss>