<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Note on moskomule log</title>
    <link>https://mosko.tokyo/tags/note/</link>
    <description>Recent content in Note on moskomule log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Written by Ryuichiro Hataya</copyright>
    <lastBuildDate>Mon, 20 Nov 2017 22:39:13 +0900</lastBuildDate>
    
	<atom:link href="https://mosko.tokyo/tags/note/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>情報論的学習理論5</title>
      <link>https://mosko.tokyo/notes/info_ml/5/</link>
      <pubDate>Mon, 20 Nov 2017 22:39:13 +0900</pubDate>
      
      <guid>https://mosko.tokyo/notes/info_ml/5/</guid>
      <description> MDL規準は
\[\begin{aligned} \mathrm{MDL}_k(x^n) &amp;amp;=-\ln p_{\mathrm{NML}}(x^n)\cr &amp;amp;=-\ln p(x^n;\theta)+\ln\sum_{x^n} p(x^n;\theta) \end{aligned}\]
であり，最右辺の第1項が情報量，第2項がparametric complexityという情報量と同じ尺度の量でこれを用いるのがMDLの肝要であった．ただしこの第2項の計算は困難であって漸近近似を使う方法と厳密計算を行う方法が知られている．
後者は，つまり厳密計算できる問題のクラスは限定されておりg函数を使った手法と漸化式を用いた方法がある．
g函数 確率密度函数を
\[p(x^n;\theta)=p(x^n|\hat{\theta}(x^n))g(\hat{\theta}(x^n);\theta)\]
と分解する．ただし$\displaystyle p(x^n|\hat{\theta})=\frac{p(x^n;\theta)}{g(\hat{\theta};\theta)}$で
\[g(\bar{\theta};\theta)=\sum_{x^n;\hat{\theta}(x^n)=\bar{\theta}}p(x^n;\theta)=\sum_{x^n} p(x^n;\theta)\delta(\hat{\theta}(x^n)-\theta)\]
である．この$\bar{\theta}$に関する確率密度函数をg函数と呼ぶ．実際，
\[\int g(\bar{\theta};\theta)d\theta=\int d\theta (\sum_{x^n;\hat{\theta}(x^n)=\bar{\theta}}p(x^n;\theta))=\sum_{x^n}p(x^n;\theta) = 1 \]
であるから確率密度函数である．
MDK規準の性質 情報の真の分布が既知であればシャノンの符号化定理を用いることができるのであった．未知の時には以下が成り立つ．
定理（Rissarrenの不等式） 中心極限定理を仮定する．任意の語頭符号長函数$\mathcal{L}$に対して$n\to\infty$でルベーグ測度が0に近づく$\theta\in\Theta$の集合を除いて次が成立する（つまりほとんどいたるところで以下が成立する）．
任意の$\epsilon &amp;gt;0$に対して
\[\mathbb{E}[\mathcal{L}(x^n)]_{\theta}\geq H_n(P)+\frac{k-\epsilon}{2}\ln n\]
ただし左辺は真の分布に対する平均，右辺第1項はエントロピーである．これは真の分布が未知の場合の符号長の下限を与えている．
 $\theta$が$\mathcal{L}(x^n)=-\ln p(x^n;\theta)$であるように（理想的に）とることができると$\mathcal{L}(x^n)$は下限を下回るが，このような$\theta$は確率0でしか存在しない．
 $\mathrm{MDL}_k(x^n)$はRissarrenの不等式を漸近的に成立する．
  </description>
    </item>
    
    <item>
      <title>情報論的学習理論4</title>
      <link>https://mosko.tokyo/notes/info_ml/4/</link>
      <pubDate>Sun, 05 Nov 2017 10:55:16 +0900</pubDate>
      
      <guid>https://mosko.tokyo/notes/info_ml/4/</guid>
      <description>情報・符号・確率 ここでは一見異なる概念である情報・符号・確率が（情報論的学習理論では）ほぼ同一視できることを見ていく．
$\mathscr{X}$を有限集合，$\mathscr{X}^n$を長さ$n$のデータ列の集合とする．また$\{0,1\}^{\star}$を任意の長さの二元列の集合とする．このとき符号化とは
\[\pi:\mathcal{X}^n\to \{0,1\}^{\star}\]
のことを指す．また語頭符号化を以下のように定める．
 $\mathcal{X}^n$に属する任意の元$x_1, x_2 ~(x_1\ne x_2)$について$\pi(x_1)$と$\pi(x_2)$の一方が他方の先頭部分の語頭に一致しないような$\pi$．これは符号後を連ねた際に，区切り記号を用いることなく原文を一意的に記述可能のことを意味する．たとえば$\mathcal{X}^2=\{0,1\}^2$として符号化$\pi$を  \[\begin{cases} \pi(00) = 000 \cr \pi(01) = 001 \cr \pi(10) = 01 \cr \pi(11) = 1 \end{cases}\]
とすれば，$1$か$000$を区切りとみることで区切り記号を用いずに一意的な表記をすることができる（逆に$\pi(000)=010$などとしてしまうと区切り記号が必要となる）．つまりこの$\pi$は語頭符号化である．
以下簡単のため符号長（函数）を$l(x^n)=|\pi(x^n)|$と定める．語頭符号化について以下が成り立つ．
定理（語頭符号化の必要十分条件，Kraftの不等式） $\pi$が語頭符号化可能であることは$\sum_{x^n}2^{-l(x^n)}\le 1$と必要十分である（一般に$m$元符号化をすれば$2\to m$）
定義（劣確率分布） $p(X^n)$が$\mathscr{X}^n$の劣確率分布であるとは
 任意の$X^n$について$p(X^n)\ge 0$ $\displaystyle \sum_{X^n\in\mathscr{X}^n}p(X^n)\le 1$（等号の時一般の確率分布）  いま$p(X^n)$が劣確率分布であるとすると$l(x)=\lceil-\log_2 P(X^n)\rceil$とすることで符号長函数$l(X^n)$の語頭符号化が存在する．ここでは構成が可能であることを示しているだけで，具体的な手法についてはarithmetic coding, haffmann codingなどを参照．
逆に$l(x^n)$が語頭符号化の符号長函数であるならばKraftの不等式を満たすので$p(x^n)=2^{-l(x^n)}$として得られる劣確率分布が存在する．
以上から劣確率分布$p(X^n)$と符号長函数$l(x^n)$とが表裏一体の関係にあることが分かる．ところがここで劣確率分布$p(X^n)$に$p(\bar{X})=1-\sum p(X^n)$を加えた$p(\tilde{X}^n)$は$p(\tilde{X}^n)\ge 0$と$\sum p(\tilde{X}^n)=1$をみたす確率分布である．
つまり劣確率分布は即座に確率分布に変換することができるので，確率分布と符号化とが表裏一体である，ということができる．
定理（平均符号長の下限，シャノンの符号化定理） いま真の分布$P$が既知であるとし，$L$を任意の語頭符号化符号長函数であるとする．このとき
\[\mathbb{E}_P[L(X^n)]\ge H_n(P)\]
で，この下限は$L(X^n)=-\ln P(X^n)$をとれば達成可能である．ただし$H_n(P)$は$P$のエントロピー函数で$-\sum P(X^n)\ln P(X^n)$．
これは適当な確率分布$q$によって$L(X^n)=-\ln q(X^n)$として$\mathbb{E}_P[L(X^n)]=-\sum p(X^n)\ln q(X^n)$を考えれば導かれる．
確率的複雑さとMDL規準 k次元のパラメーター集合$\Theta_k$に対してk次元のモデル集合を</description>
    </item>
    
    <item>
      <title>情報論的学習理論3</title>
      <link>https://mosko.tokyo/notes/info_ml/3/</link>
      <pubDate>Tue, 24 Oct 2017 20:05:47 +0900</pubDate>
      
      <guid>https://mosko.tokyo/notes/info_ml/3/</guid>
      <description>勾配降下法 データ$D^n=D_1,\ldots,D_n$，損失函数$\mathcal{L}(D;\theta)$に対して
\[\mathcal{L}(\theta):=\frac1n\sum_{t=1}^n\mathcal{L}(D_t;\theta)\]
とする．特に$\mathcal{L}(\theta)$を$\theta$について最小化したいが，解析的に行えないときに効果を発揮するのが勾配降下法である．
1次の勾配降下法  $\theta^{(0)}$を適当な初期値とする． $\theta^{(t)}$を逐次的に$\theta^{(t+1)}=\theta^{(t)}-\alpha\nabla\mathcal{L}(\theta)|_{\theta=\theta^{(t)}}$と更新する．ここで$\alpha$は学習率と呼ばれる値である．  2次の勾配降下法  $\theta^{(t+1)}=\theta^{(t)}-H^{-1}\nabla\mathcal{L}(\theta)|_{\theta=\theta^{(t)}}$によって更新を行う．  確率的勾配降下法 $\mathcal{L}(\theta)=\frac1n\sum_{t=1}^n\mathcal{L}(D_t;\theta)$について$n$が充分に大きいとすると計算のコストがかかる．そこで$D^n$から一部を乱択した$\tilde{D}^{\tilde{n}}$を用いて
\[\tilde{\mathcal{L}}(\theta):=\frac{1}{\tilde{n}}\sum_{t=1}^{\tilde{n}}\mathcal{L}(\tilde{D}_t;\theta)\]
で近似する．
モデル選択 いま簡単のためモデルの複雑さがモデルのパラメータ数のみで決定されるとして，$k$次元のパラメータ集合$\Theta_k$に対して$k$次元のパラメータモデルを
\[\mathscr{P}_k:=\{p(x;\theta,k):\theta\in\Theta_k\}\]
と定める．また
\[\mathscr{P}:=\bigcup_k\mathscr{P}_k\]
このとき$\mathscr{P}_1\subset\mathscr{P}_2\cdots\subset\cdots$という入れ子構造を持つ．モデル選択とはデータ$x^n=x_1,\ldots,x_n$が与えられたときに「最良の」$k$を決定する問題である．例えばクラスタリングであればクラスタの数がこの$k$に相当するし，多項式近似であれば多項式の最大次数が$k$である．
この「最良」を決定する手法は幾つか存在するが，さらにその手法を選択する目的に応じたメタな規準が必要となる．
情報量規準 情報量規準は函数$f(k|x^n)$で，$f$を最小とする$k$が最良となるようなもののことである．AIC,BIC,MDL,交差検証法などが有名である．
AIC（赤池情報量規準） \[f(k|x^n)=-\ln p(x^n;\hat{\theta}(x^n),k)+k\]
ただし$\hat{\theta}$は最尤推定量である．この第1項はデータに対する適合性，第2項はモデルの複雑さにそれぞれ対応し，互いにトレードオフの関係にある．つまり一般に複雑なモデルはよい適合性を持つ．
AICは期待平均対数尤度の不偏推定量となる．ここで期待平均対数尤度は$n\mathbb{E}_{X^n}\mathbb{E}_Z[-\ln p(Z;\hat{\theta}(X^n))]$で$X^n,Z$は同一の分布から独立に生成され，それぞれ訓練データとテストデータである．
補題1 中心極限定理を仮定する．つまり
\[\sqrt{n}(\hat{\theta}(x^n)-\theta)\rightsquigarrow\mathcal{N}(0,I^{-1}(\theta))\]
である．ただし，$\theta$は真の分布のパラメータで$\rightsquigarrow$は法則収束を指すのであった．このとき
\[n\mathbb{E}_{X^n}\mathbb{E}_Z[-\ln p(Z;\hat{\theta}(X^n))]=n\mathbb{E}_Z[-\ln p(Z;\theta)]+\frac{k}{2}+o(1)\]
が成立する．
証明(補題1) $\hat{\theta}$の$\theta$周りでのTaylor展開を考える．
\[\begin{aligned} n\mathbb{E}_{X^n}\mathbb{E}_Z[-\ln p(Z;\hat{\theta}(X^n))] &amp;amp;= n\mathbb{E}_Z[-\ln p(z;\hat{\theta})] - n\mathbb{E}_{X^n}\mathbb{E}_Z[\nabla\ln p(z;\theta)(\hat{\theta}-\theta)] \cr &amp;amp; + \mathbb{E}_{X^n}[\frac12\sqrt{n}(\hat{\theta}-\theta)^{\top}\mathbb{E}_Z[-\nabla^2\ln p(z;\theta)]\sqrt{n}(\hat{\theta}-\theta)]+R \end{aligned}\]
ここで右辺第2項について
\[\begin{aligned} \mathbb{E}_{Z}[-\nabla\ln p(x;\theta)] &amp;amp;= \sum_z p(z;\theta)\frac{1}{p(z;\theta)}\nabla p(x;\theta) \cr &amp;amp;= \sum \nabla p(z;\theta)=\nabla\sum p(z;\theta)=0 \end{aligned}\]</description>
    </item>
    
    <item>
      <title>情報論的学習理論2</title>
      <link>https://mosko.tokyo/notes/info_ml/2/</link>
      <pubDate>Tue, 17 Oct 2017 21:13:08 +0900</pubDate>
      
      <guid>https://mosko.tokyo/notes/info_ml/2/</guid>
      <description>線型回帰モデル 線型回帰モデルは教師あり学習の枠組みで，
\[ p(y|x;\theta)=\frac{1}{\sqrt{s\pi\sigma^2}}\exp(-\frac{(y-\theta^\top x)^2}{2\sigma^2}) \]
つまり
\[ y=\theta^\top x-\epsilon ~~\epsilon\sim\mathscr{N}(0, \sigma^2) \]
ここで観測されるデータ列を$(x_1,y_1),\ldots,(x_n,y_n)$として，$X=[x_1,\ldots,x_n],Y=(y_1,\ldots,y_n)^\top$とすると線型モデルの負の対数尤度は
\[ \frac{1}{\sigma^2}\sum_t(y_t-\theta^\top x_t)^2+n\ln\sqrt{2\pi\sigma^2} \]
の第一項の和は
\[ (Y-X\theta)^\top(Y-X\theta) \]
と書ける．$\frac{\partial \mathcal{L}(\theta)}{\partial \theta}|_{\theta=\hat{\theta}_{\mathrm{NLE}}}=0$より
\[X^\top Y-X^\top X\hat{\theta}=0\]
これは$X^\top X$が正則の時に
\[\hat{\theta}=(X^\top X)^{-1}X^\top Y\]
と求まるが$x$が$n$次の時に$(X^\top X)^{-1}$は$O(d^3)$のオーダーなのであまり計算をしたくない．
スパース正則 対数尤度に正則化項を加えた
\[-\sum_t\ln p(y_t|x_t;\theta)+\lambda R(\theta)\]
を考える．特に$R(\theta)=\sum|\theta|^p$を考える．上の式の最小化は，ある$B&amp;gt;0$が存在して
\[\sum\ln(y_t|x_t;\theta)=\sum(y_t-\theta^\top x_t)\]
を$R(\theta)\le B$と等価である．
損失函数 損失函数はデータ$\mathscr{D}=(\mathscr{X}, \mathscr{Y})$，(確率)モデル空間$\mathscr{P}$に対して
\[\mathcal{L}:\mathscr{D}\times\mathscr{P}\to\mathbb{R}\]
で定義される．
 対数損失は$P_\theta=p(y|x;\theta)$として$\mathcal{L}(\mathscr{D};P_\theta)=-\ln p(y|x;\theta)$
 2乗損失は確率ではなく適当の函数$f_\theta$によって$\mathcal{L}(\mathcal{D};f_\theta)=(y-f_\theta(x))^2$
 0-1損失は$\mathcal{L}(\mathcal{D};f_\theta)=1-\mathbf{1}[y+f_\theta(x)]$
 ロジステック損失は$y\in\{-1,1\}$で$\mathcal{L}(\mathcal{D};f_\theta)=-\ln\frac{1}{1+\exp{(-yf_\theta(x))}}$
  結局，最尤推定とMAP推定は経験的損失$\sum_t\mathcal{L}(\mathscr{D}_t;P_\theta)$と正則化項$\lambda R(\theta)$を$\theta$について最小化することなのであった．
$L_1$正則化 a.k.a LASSO LASSOはLeast Absolute Shrinkage and Selection Operatorの略らしく，スパースな解が得やすいことが知られている．</description>
    </item>
    
    <item>
      <title>情報論的学習理論1</title>
      <link>https://mosko.tokyo/notes/info_ml/1/</link>
      <pubDate>Tue, 10 Oct 2017 20:56:15 +0900</pubDate>
      
      <guid>https://mosko.tokyo/notes/info_ml/1/</guid>
      <description> 情報論的学習理論では情報論の立場から学習理論を扱う．
パラメータの推定 確率モデルを以下のように表す．
\[\mathscr{P}:=\{p(X^n;\theta);\theta\in\Theta\}\]
ただし$p(X^n;\theta)$は確率密度函数がパラメータ$\theta$が決定することによって（ひとつに）定められることを示す．条件付き確率は$p(X^n|w)$など$|$を用いる．また$X^n=(X_0,\ldots,X_n)$は確率変数列であり，観測されたデータ列$x^n=(x_0,\ldots,x_n)$とは区別される（つまり$x\mathop{\sim}\limits^{\text{i.i.d.}} p(X;\theta)$）．$\Theta$はパラメータ空間を指す．
パラメータ推定手法は$x^n$が与えられたときに$\theta$を推測する．
最尤推定法 最尤推定法では尤度関数$\mathcal{L}(\theta):=p(x^n;\theta)=\prod_i p(x_i; \theta)$を最大とするような$\theta$を求める．このような$\hat{\theta}$は$\hat{\theta}(x_n)=\mathop{\text{argmax}}\limits_{\theta}\ln p(x^n;\theta)$である．
最尤推定は以下のふたつの点においてすぐれている．
 最尤推定量の一致性  ある正則条件の下で任意の$\epsilon&amp;gt;0$に対して
\[\lim_{n\to\infty}\text{Prob}[||\hat{\theta}-\theta||_2&amp;gt;\epsilon]=0\]
 最尤推定量の漸近正規性，有効性  中心極限定理が成立するようなモデルのクラスに対して以下が成り立つ．
\[\sqrt{n}(\hat{\theta}(x^n)-\theta)\rightsquigarrow\mathcal{N}(0,I^{=1}(\theta))\]
ただし$\theta$は真の分布が$q(X)$のときに$q(X)=p(x;\theta)$となるように$p$を指定する$\theta$．$I(\theta)$はフィッシャー情報行列で$i,j$成分は以下で与えられる1．
\[\lim_{n\to\infty}\frac{1}{n}\mathbb{E}_{\theta}[-\frac{\partial^2\ln p(x^n;\theta)}{\partial \theta_i\partial \theta_j}]\]
また$y^n\rightsquigarrow y$は$\{y_0,\ldots,y_n\}$の確率分布が真の確率分布に法則収束することを指す（充分大きな$n$で分布が一致する意味）．
さらに，特に$\hat{\theta}$が不偏で，つまり$\mathbb{E}_{\theta}[\hat{\theta}(x_n)]=\theta$の時，分散はCramel-Raoの下限に達する（$\Sigma-I^{-1}(\theta)\geq 0$）．
MAP推定量 最尤推定量では$\theta$は一つの値であったが，これが確率分布から生成されていると考えたらどうだろうか．このように考えたとき$p(\theta)$を事前分布と呼ぶ．事後分布を
\[p(\theta|x^n)=\frac{p(x^n;\theta)p(\theta)}{\int p(x^n;\theta)p(\theta) d\theta}\]
と定める．そうしてMAP推定量を
\[\hat{\theta}_{\text{MAP}}:=\mathop{\text{argmax}}\limits_{\theta}p(\theta|x^n)\]
と定義する．
\[\ln p(\theta|x^n)=\ln p(x^n;\theta)+\ln p(\theta)+C\]
右辺第二項がなければ最尤推定量のときと変わらない．この$\ln p(\theta)$は従って正規化項として作用する．特に$p(\theta)\propto \exp(-\lambda f(\theta))$として
 $f(\theta)=||\theta||_1$のとき$p(\theta)$をLaplace分布 $f(\theta)=||\theta||_2$のとき$p(\theta)$をGauss分布  Bayse推定量 ベイズ推定量を
\[\hat{\theta}_{\text{Bayse}}:=\int\theta p(\theta|x^n)d\theta\]
により定める．
 個人的には$I$は単位行列に予約されているので使いたくないが，他でも見られるので一般的の使い方なのかもしれない．単位行列には$\mathbf{I}$などを使うのがよいのだろうか． [return]   </description>
    </item>
    
  </channel>
</rss>