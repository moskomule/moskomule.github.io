<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pytorch on moskomule log</title>
    <link>https://mosko.tokyo/tags/pytorch/</link>
    <description>Recent content in Pytorch on moskomule log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 01 Dec 2017 15:10:30 +0900</lastBuildDate>
    
	<atom:link href="https://mosko.tokyo/tags/pytorch/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PyTorchでDQNを実装した</title>
      <link>https://mosko.tokyo/post/pytorch-dqn/</link>
      <pubDate>Fri, 01 Dec 2017 15:10:30 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/pytorch-dqn/</guid>
      <description>はじめに DQN(Deep Q Network)は Minh et al. 20151（以下論文）で登場した深層強化学習の先駆けです．Atariのゲームで非常に高い得点を修めるというパフォーマンスで有名になりました．
  9月頃に強化学習の勉強をした際に実装してみたのですが，一向に学習が進まず放置していたのですが，最近Implementing the Deep Q-Network 2を読み再開してみたところ，動いてしまったので，この記事を書くことになりました．
今回の実装はこちらにあります．
強化学習とは David Silver先生に聞きましょう．ただしこの講義では深層強化学習は扱われていません．
  Deep Q-Networkとは 論文を読みましょう．Q-Learningの応用で，複雑ではありませんが，学習を安定させるための工夫が各所にあるので見逃すと動かないようです．
  DQNの学習アルゴリズム．論文より．   実装について 画像の処理 DQNではAtariのゲームの画像をグレースケールにしてスタックするなどの処理がありますが，このあたりは各アルゴリズムをTensorFlowで実装し，公開しているOpen AI baselinesを一部変更して用いています．
 OpenCV2をPillowに変更した 画像のスタックの仕方をPyTorchに合わせて変更した．  また今回の改良ではtensorboard-pytorchを導入して，入力画像が正しいかを確認できるようにしました．
  ネットワーク Deepとは言えない気がしますが論文通りの構成です．何か工夫すると多少変わるのかもしれません．
class DQN(nn.Module): def __init__(self, output_size: int): super(DQN, self).__init__() self.feature = nn.Sequential( nn.Conv2d(4, 32, kernel_size=8, stride=4), nn.ReLU(inplace=True), nn.Conv2d(32, 64, kernel_size=4, stride=2), nn.ReLU(inplace=True), nn.Conv2d(64, 64, kernel_size=3, stride=1), nn.ReLU(inplace=True)) self.</description>
    </item>
    
    <item>
      <title>Double Backpropagationについて</title>
      <link>https://mosko.tokyo/post/double-backprop/</link>
      <pubDate>Sun, 01 Oct 2017 19:40:24 +0900</pubDate>
      
      <guid>https://mosko.tokyo/post/double-backprop/</guid>
      <description>はじめに PyTorch v0.2では&amp;rdquo;Higher order gradients&amp;rdquo; (double backpropagation)がサポートされました．Chainerもv3においてこれがサポートされます．今回Chainer Meetupの資料を読んで雰囲気が分かったのでまとめました．
 Comparison of deep learning frameworks from a viewpoint of double backpropagation  Chainer v3  筆者は長くdouble backpropagationという名称から
\[\mathrm{loss}\longrightarrow \frac{\partial^2 \mathrm{loss}}{\partial x_i \partial x_j} \]
と思い込んでいました．そう思っているのでdocumentを読んでもいまいちよく分からない．ところが上に挙げた資料では，そうではなくて
\[\mathrm{loss}=g(f(x), \frac{\partial f(x)}{\partial x})\]
のような場合にも計算が出来る，ということなのだということが説明されていて救われました．
PyTorchの例 これで以上，でもよいのですが，PyTorchでの例を．
$x=1, y=x^3, z=y^2+\frac{dy}{dx}$をとして，$\frac{dz}{dx}|_{x=1}$を求めます．
&amp;gt;&amp;gt;&amp;gt; x = Variable(torch.Tensor([1]), requires_grad=True) &amp;gt;&amp;gt;&amp;gt; y = x ** 3 &amp;gt;&amp;gt;&amp;gt; grad_y, = autograd.grad(y, x, create_graph=True) &amp;gt;&amp;gt;&amp;gt; (grad_y + y ** 2).backward() &amp;gt;&amp;gt;&amp;gt; x.grad Variable containing: 12 [torch.</description>
    </item>
    
  </channel>
</rss>