<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pytorch on moskomule log</title>
    <link>http://mosko.tokyo/tags/pytorch/</link>
    <description>Recent content in Pytorch on moskomule log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Written by Ryuichiro Hataya</copyright>
    <lastBuildDate>Thu, 08 Jun 2017 16:33:50 +0900</lastBuildDate>
    
	<atom:link href="http://mosko.tokyo/tags/pytorch/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PyTorchでディープラーニング</title>
      <link>http://mosko.tokyo/post/pytorch_tutorial/</link>
      <pubDate>Thu, 08 Jun 2017 16:33:50 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/pytorch_tutorial/</guid>
      <description>PyTorchとは PyTorchはFacebookの開発するPython上でのテンソル計算・自動微分ライブラリで，特にディープラーニングに必要な機能が充実しています．2017年の初頭に公開され，瞬く間にTensorflow, Keras, Caffeに続くディープラーニングライブラリとして人気を博すこととなりました．
Bonus: stars (not an indicator of usage, just proportional to how many people have landed on the GitHub page over the period). pic.twitter.com/IugHJqHSii
&amp;mdash; François Chollet (@fchollet) April 12, 2017  PyTorchはPreferred NetworkのディープラーニングライブラリChainerから影響を受けており，GoogleのTensorFlowやUniversité de MontréalのTheanoとは異なり，実行時に動的にグラフを構築するため，柔軟なコードを書くことができます．
PyTorchは，製品にも用いられているTensorFlowとは異なり，研究向けであることが明言されています．新機能の変更は多いものの，疎テンソルにいち早く対応するなど，最新の研究動向を追うにはよいのではないでしょうか．また，適当なレベルで書くことができて，素のTensorflowのように低レベルでもなく，Kerasの様に高度に抽象化されているわけでもなく，ラッパーによって書き方が多様でサンプルを見てもよく分からない，ということはないので，学びやすいと思います．
チュートリアル とりあえず動かせるようになるチュートリアルです．
インストール GPU環境は勿論，CPU環境でも動かすことができます．Linux，macOSの場合は 公式, Windowsの場合は Anaconda Cloudからインストールできます．
GPUを利用する場合，環境の設定が面倒なことが多いですがPyTorchでは特に設定せずにGPU対応版をダウンロードするとGPUが使えるようになるようです．
Tensor PyTorchの基本はテンソルを操作するTensorです．テンソルというと難しく聞こえますが，この場合は多次元配列と同義で，物理学のテンソルのような共変・反変を意識する必要はありません．慣例に従ってテンソル，と言う語を用います．
PyTorchにおけるTensorは端的に言えば「GPU上でも動くnumpy.ndarrayのようなもの」ですが，違いも多いので注意が必要です．例えば
import numpy as np import torch # PyTorch &amp;gt;&amp;gt;&amp;gt; np_tensor = np.zeros([1, 2, 3]) array([[[ 0., 0., 0.</description>
    </item>
    
    <item>
      <title>PyTorchでテキスト生成</title>
      <link>http://mosko.tokyo/post/pytorch_text_generation/</link>
      <pubDate>Sat, 28 Jan 2017 07:31:45 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/pytorch_text_generation/</guid>
      <description>相変わらずPyTorchをいじっている．後発のこともあって，まだDocは完全ではないけれど，Discussionなどのサポート体制は充実している(気がする)．
コミュニティの助けを借りてRNNでのテキスト生成をおこなった．これはKerasのサンプルをPyTorchで書き換えたもので時流に乗ってオーウェルの 1984 を学習する．Kerasのように内部状態を特に考える必要がないのとは異なって，隠れ変数$h_{\star}$を意識しなくてはいけないので勉強になる．
 function var: CUDAが使えればtorch.autograd.VariableをGPUにおく(variable.cuda())．
 function sample: RNNモデルの出力から適当なindexを取り出す．
 function __init__ in class Net: inputはfeature数で，今回であればアルファベットをonehotにしているので，len(chars)．
  def __init__(self, features, cls_size): super(Net, self).__init__() self.rnn1 = nn.GRU(input_size=features, hidden_size=hidden_size, num_layers=1) self.dense1 = nn.Linear(hidden_size, cls_size)   function forward in class Net: 系列の最後の入力に対する隠れ層の状態をとるためにx=select(0, maxlen-1)を行っている(追記:実はx[-1]で充分)．reshapeに相当するviewを行うためにはcontiguousが必要．またテンソルxは$\text{系列の長さ}\times\text{バッチ数}\times\text{feature数}$である点に注意．  def forward(self, x, hidden): x, hidden = self.rnn1(x, hidden) x = x.select(0, maxlen-1).contiguous() x = x.view(-1, hidden_size) x = F.softmax(self.dense1(x)) return x, hidden   function train: 入力した文を1通り読み込むのを1エポックにしている．Kerasと異なり，PyTorchのCrossEntropyLossではtargetはクラスのインデックスである．この目標のインデクス配列の型はnp.</description>
    </item>
    
    <item>
      <title>PyTorchはじめ</title>
      <link>http://mosko.tokyo/post/getting_started_pytorch/</link>
      <pubDate>Tue, 24 Jan 2017 15:15:55 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/getting_started_pytorch/</guid>
      <description>先日Facebookが PyTorch を公開していたので，早速試してみた．PyTorchは
 Tensors and Dynamic neural networks in Python with strong GPU acceleration.
 とのことで，TensorFlowやTheanoより，Chainerに似ている気がする．後発ということもあってか，ウェブページにある導入の説明が丁寧で，Linux，Python 3.5，conda，Cuda8.0なら
conda install pytorch torchvision cuda80 -c soumith  を叩くだけでよい．その下にはMNISTなどの例やJupyterのチュートリアルへのリンクがあるのも丁寧．ただ，ニューラルネットワークの知識に乏しくともレイヤーを重ねてscikit-learn風によしなにすればよいkerasよりは難しいが，その分柔軟に書けそう．メモリを大量消費するTensorFlowに較べて，GPUに対する負荷はかなり小さそう．
基本的にはnn.Moduleを継承してネットワークを定義する． 以下のコードはGithubに挙げた．
class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_bn = nn.BatchNorm2d(20) self.dense1 = nn.Linear(in_features=320, out_features=50) self.dense1_bn = nn.BatchNorm1d(50) self.dense2 = nn.Linear(50, 10) def forward(self, x): x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_bn(self.conv2(x)), 2)) x = x.</description>
    </item>
    
  </channel>
</rss>