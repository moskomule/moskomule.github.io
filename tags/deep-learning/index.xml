<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on moskomule log</title>
    <link>http://mosko.tokyo/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on moskomule log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Written by Ryuichiro Hataya</copyright>
    <lastBuildDate>Tue, 24 Jan 2017 15:15:55 +0900</lastBuildDate>
    
	<atom:link href="http://mosko.tokyo/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PyTorchはじめ</title>
      <link>http://mosko.tokyo/post/getting_started_pytorch/</link>
      <pubDate>Tue, 24 Jan 2017 15:15:55 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/getting_started_pytorch/</guid>
      <description>先日Facebookが PyTorch を公開していたので，早速試してみた．PyTorchは
 Tensors and Dynamic neural networks in Python with strong GPU acceleration.
 とのことで，TensorFlowやTheanoより，Chainerに似ている気がする．後発ということもあってか，ウェブページにある導入の説明が丁寧で，Linux，Python 3.5，conda，Cuda8.0なら
conda install pytorch torchvision cuda80 -c soumith  を叩くだけでよい．その下にはMNISTなどの例やJupyterのチュートリアルへのリンクがあるのも丁寧．ただ，ニューラルネットワークの知識に乏しくともレイヤーを重ねてscikit-learn風によしなにすればよいkerasよりは難しいが，その分柔軟に書けそう．メモリを大量消費するTensorFlowに較べて，GPUに対する負荷はかなり小さそう．
基本的にはnn.Moduleを継承してネットワークを定義する． 以下のコードはGithubに挙げた．
class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride=1) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_bn = nn.BatchNorm2d(20) self.dense1 = nn.Linear(in_features=320, out_features=50) self.dense1_bn = nn.BatchNorm1d(50) self.dense2 = nn.Linear(50, 10) def forward(self, x): x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_bn(self.conv2(x)), 2)) x = x.</description>
    </item>
    
    <item>
      <title>「日本古典籍字形データセット」で遊ぶ</title>
      <link>http://mosko.tokyo/post/mnist_kuzushiji/</link>
      <pubDate>Fri, 13 Jan 2017 13:18:40 +0900</pubDate>
      
      <guid>http://mosko.tokyo/post/mnist_kuzushiji/</guid>
      <description>日本語版MNIST,というわけではないけれど日本古典籍字形データセットの識別をkerasで実装したresnetによって行った．現在validation accuracyは93.3%．少なくとも自分よりはきちんと分類できるようだ．
このデータセットには2017年1月現在，「8点の画像データから切り取ったくずし字1,521文字種の字形データ86,176文字」が収録されているので，そのまま1521に分類している．
今回はMNIST的に使うので，つまり文脈を考慮しないので変体仮名の「志」（し）と漢字としての「志」とを区別する，というようなタスクも含まれてしまうが，特に考慮しない．kerasのImageDataGeneratorで前処理を一括して行う．本当はもう少し丁寧にした方がいいのかもしれないけれど，とりあえず．
 # data generator train_datagen = ImageDataGenerator( shear_range=0.05, width_shift_range=0.05, height_shift_range=0.05, rotation_range=10, fill_mode=&amp;quot;constant&amp;quot;, cval=200, zoom_range=0.2) train_generator = train_datagen.flow_from_directory( &#39;train&#39;, color_mode=&amp;quot;grayscale&amp;quot;, target_size=target_size, batch_size=batch_size, class_mode=&#39;categorical&#39; ) val_datagen = ImageDataGenerator() val_generator = val_datagen.flow_from_directory( &#39;val&#39;, color_mode=&amp;quot;grayscale&amp;quot;, target_size=target_size, batch_size=batch_size, class_mode=&#39;categorical&#39; )  training dataには変形を施した．resnetはkeras.jsを参考にして実装(下記のres_a,res_b)．
# model input_layer = Input(shape=input_shape) x = Convolution2D(nb_filters, 4, 4, subsample=(2,2))(input_layer) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = MaxPooling2D(pool_size, strides=stride_size)(x) x = res_a([32,32,128])(x) x = res_b([32,32,128])(x) x = res_b([32,32,128])(x) x = res_a([64,64,256])(x) x = res_b([64,64,256])(x) x = res_b([128,128,256])(x) x = res_a([128,128,512])(x) x = res_b([128,128,512])(x) x = res_b([256,256,512])(x) x = AveragePooling2D((4,4))(x) x = Flatten()(x) output_layer = Dense(nb_classes, activation=&#39;softmax&#39;)(x) model = Model(input=input_layer, output=output_layer) model.</description>
    </item>
    
  </channel>
</rss>