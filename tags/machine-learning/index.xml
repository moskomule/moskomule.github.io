<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on moskomule log</title>
    <link>https://mosko.tokyo/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on moskomule log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <copyright>Written by Ryuichiro Hataya</copyright>
    <lastBuildDate>Tue, 24 Oct 2017 20:05:47 +0900</lastBuildDate>
    
	<atom:link href="https://mosko.tokyo/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>情報論的学習理論3</title>
      <link>https://mosko.tokyo/notes/info_ml/3/</link>
      <pubDate>Tue, 24 Oct 2017 20:05:47 +0900</pubDate>
      
      <guid>https://mosko.tokyo/notes/info_ml/3/</guid>
      <description>勾配降下法 データ$D^n=D_1,\ldots,D_n$，損失函数$\mathcal{L}(D;\theta)$に対して
\[\mathcal{L}(\theta):=\frac1n\sum_{t=1}^n\mathcal{L}(D_t;\theta)\]
とする．特に$\mathcal{L}(\theta)$を$\theta$について最小化したいが，解析的に行えないときに効果を発揮するのが勾配降下法である．
1次の勾配降下法  $\theta^{(0)}$を適当な初期値とする． $\theta^{(t)}$を逐次的に$\theta^{(t+1)}=\theta^{(t)}-\alpha\nabla\mathcal{L}(\theta)|_{\theta=\theta^{(t)}}$と更新する．ここで$\alpha$は学習率と呼ばれる値である．  2次の勾配降下法  $\theta^{(t+1)}=\theta^{(t)}-H^{-1}\nabla\mathcal{L}(\theta)|_{\theta=\theta^{(t)}}$によって更新を行う．  確率的勾配降下法 $\mathcal{L}(theta)=\frac1n\sum_{t=1}^n\mathcal{L}(D_t;\theta)$について$n$が充分に大きいとすると計算のコストがかかる．そこで$D^n$から一部を乱択した$\tilde{D}^{\tilde{n}}$を用いて
\[\tilde{\mathcal{L}}(\theta):=\frac{1}{\tilde{n}}\sum_{t=1}^{\tilde{n}}\mathcal{L}(\tilde{D}_t;\theta)\]
で近似する．
モデル選択 いま簡単のためモデルの複雑さがモデルのパラメータ数のみで決定されるとして，$k$次元のパラメータ集合$\Theta_k$に対して$k$次元のパラメータモデルを
\[\mathscr{P}_k:=\{p(x;\theta,k):\theta\in\Theta_k\}\]
と定める．また
\[\mathscr{P}:=\bigcup_k\mathscr{P}_k\]
このとき$\mathscr{P}_1\subset\mathscr{P}_2\cdots\subset\cdots$という入れ子構造を持つ．モデル選択とはデータ$x^n=x_1,\ldots,x_n$が与えられたときに「最良の」$k$を決定する問題である．例えばクラスタリングであればクラスタの数がこの$k$に相当するし，多項式近似であれば多項式の最大次数が$k$である．
この「最良」を決定する手法は幾つか存在するが，さらにその手法を選択する目的に応じたメタな規準が必要となる．
情報量規準 情報量規準は函数$f(k|x^n)$で，$f$を最小とする$k$が最良となるようなもののことである．AIC,BIC,MDL,交差検証法などが有名である．
AIC（赤池情報量規準） \[f(k|x^n)=-\ln p(x^n;\hat{\theta}(x^n),k)+k\]
ただし$\hat{\theta}$は最尤推定量である．この第1項はデータに対する適合性，第2項はモデルの複雑さにそれぞれ対応し，互いにトレードオフの関係にある．つまり一般に複雑なモデルはよい適合性を持つ．
AICは期待平均対数尤度の不偏推定量となる．ここで期待平均対数尤度は$n\mathbb{E}_{X^n}\mathbb{E}_Z[-\ln p(Z;\hat{\theta}(X^n))]$で$X^n,Z$は同一の分布から独立に生成され，それぞれ訓練データとテストデータである．
補題1 中心極限定理を仮定する．つまり
\[\sqrt{n}(\hat{\theta}(x^n)-\theta)\rightsquigarrow\mathcal{N}(0,I^{-1}(\theta))\]
である．ただし，$\theta$は真の分布のパラメータで$\rightsquigarrow$は法則収束を指すのであった．このとき
\[n\mathbb{E}_{X^n}\mathbb{E}_Z[-\ln p(Z;\hat{\theta}(X^n))]=n\mathbb{E}_Z[-\ln p(Z;\theta)]+\frac{k}{2}+o(1)\]
が成立する．
証明(補題1) $\hat{\theta}$の$\theta$周りでのTaylor展開を考える．
\[\begin{aligned} n\mathbb{E}_{X^n}\mathbb{E}_Z[-\ln p(Z;\hat{\theta}(X^n))] &amp;amp;= n\mathbb{E}_Z[-\ln p(z;\hat{\theta})] - n\mathbb{E}_{X^n}\mathbb{E}_Z[\nabla\ln p(z;\theta)(\hat{\theta}-\theta)] \cr &amp;amp; + \mathbb{E}_{X^n}[\frac12\sqrt{n}(\hat{\theta}-\theta)^{\top}\mathbb{E}_Z[-\nabla^2\ln p(z;\theta)]\sqrt{n}(\hat{\theta}-\theta)]+R \end{aligned}\]
ここで右辺第2項について
\[\begin{aligned} \mathbb{E}_{Z}[-\nabla\ln p(x;\theta)] &amp;amp;= \sum_z p(z;\theta)\frac{1}{p(z;\theta)}\nabla p(x;\theta) \cr &amp;amp;= \sum \nabla p(z;\theta)=\nabla\sum p(z;\theta)=0 \end{aligned}\]</description>
    </item>
    
    <item>
      <title>情報論的学習理論2</title>
      <link>https://mosko.tokyo/notes/info_ml/2/</link>
      <pubDate>Tue, 17 Oct 2017 21:13:08 +0900</pubDate>
      
      <guid>https://mosko.tokyo/notes/info_ml/2/</guid>
      <description>線型回帰モデル 線型回帰モデルは教師あり学習の枠組みで，
\[ p(y|x;\theta)=\frac{1}{\sqrt{s\pi\sigma^2}}\exp(-\frac{(y-\theta^\top x)^2}{2\sigma^2}) \]
つまり
\[ y=\theta^\top x-\epsilon ~~\epsilon\sim\mathscr{N}(0, \sigma^2) \]
ここで観測されるデータ列を$(x_1,y_1),\ldots,(x_n,y_n)$として，$X=[x_1,\ldots,x_n],Y=(y_1,\ldots,y_n)^\top$とすると線型モデルの負の対数尤度は
\[ \frac{1}{\sigma^2}\sum_t(y_t-\theta^\top x_t)^2+n\ln\sqrt{2\pi\sigma^2} \]
の第一項の和は
\[ (Y-X\theta)^\top(Y-X\theta) \]
と書ける．$\frac{\partial \mathcal{L}(\theta)}{\partial \theta}|_{\theta=\hat{\theta}_{\mathrm{NLE}}}=0$より
\[X^\top Y-X^\top X\hat{\theta}=0\]
これは$X^\top X$が正則の時に
\[\hat{\theta}=(X^\top X)^{-1}X^\top Y\]
と求まるが$x$が$n$次の時に$(X^\top X)^{-1}$は$O(d^3)$のオーダーなのであまり計算をしたくない．
スパース正則 対数尤度に正則化項を加えた
\[-\sum_t\ln p(y_t|x_t;\theta)+\lambda R(\theta)\]
を考える．特に$R(\theta)=\sum|\theta|^p$を考える．上の式の最小化は，ある$B&amp;gt;0$が存在して
\[\sum\ln(y_t|x_t;\theta)=\sum(y_t-\theta^\top x_t)\]
を$R(\theta)\le B$と等価である．
損失函数 損失函数はデータ$\mathscr{D}=(\mathscr{X}, \mathscr{Y})$，(確率)モデル空間$\mathscr{P}$に対して
\[\mathcal{L}:\mathscr{D}\times\mathscr{P}\to\mathbb{R}\]
で定義される．
 対数損失は$P_\theta=p(y|x;\theta)$として$\mathcal{L}(\mathscr{D};P_\theta)=-\ln p(y|x;\theta)$
 2乗損失は確率ではなく適当の函数$f_\theta$によって$\mathcal{L}(\mathcal{D};f_\theta)=(y-f_\theta(x))^2$
 0-1損失は$\mathcal{L}(\mathcal{D};f_\theta)=1-\mathbf{1}[y+f_\theta(x)]$
 ロジステック損失は$y\in\{-1,1\}$で$\mathcal{L}(\mathcal{D};f_\theta)=-\ln\frac{1}{1+\exp{(-yf_\theta(x))}}$
  結局，最尤推定とMAP推定は経験的損失$\sum_t\mathcal{L}(\mathscr{D}_t;P_\theta)$と正則化項$\lambda R(\theta)$を$\theta$について最小化することなのであった．
$L_1$正則化 a.k.a LASSO LASSOはLeast Absolute Shrinkage and Selection Operatorの略らしく，スパースな解が得やすいことが知られている．</description>
    </item>
    
    <item>
      <title>情報論的学習理論1</title>
      <link>https://mosko.tokyo/notes/info_ml/1/</link>
      <pubDate>Tue, 10 Oct 2017 20:56:15 +0900</pubDate>
      
      <guid>https://mosko.tokyo/notes/info_ml/1/</guid>
      <description> 情報論的学習理論では情報論の立場から学習理論を扱う．
パラメータの推定 確率モデルを以下のように表す．
\[\mathscr{P}:=\{p(X^n;\theta);\theta\in\Theta\}\]
ただし$p(X^n;\theta)$は確率密度函数がパラメータ$\theta$が決定することによって（ひとつに）定められることを示す．条件付き確率は$p(X^n|w)$など$|$を用いる．また$X^n=(X_0,\ldots,X_n)$は確率変数列であり，観測されたデータ列$x^n=(x_0,\ldots,x_n)$とは区別される（つまり$x\mathop{\sim}\limits^{\text{i.i.d.}} p(X;\theta)$）．$\Theta$はパラメータ空間を指す．
パラメータ推定手法は$x^n$が与えられたときに$\theta$を推測する．
最尤推定法 最尤推定法では尤度関数$\mathcal{L}(\theta):=p(x^n;\theta)=\prod_i p(x_i; \theta)$を最大とするような$\theta$を求める．このような$\hat{\theta}$は$\hat{\theta}(x_n)=\mathop{\text{argmax}}\limits_{\theta}\ln p(x^n;\theta)$である．
最尤推定は以下のふたつの点においてすぐれている．
 最尤推定量の一致性  ある正則条件の下で任意の$\epsilon&amp;gt;0$に対して
\[\lim_{n\to\infty}\text{Prob}[||\hat{\theta}-\theta||_2&amp;gt;\epsilon]=0\]
 最尤推定量の漸近正規性，有効性  中心極限定理が成立するようなモデルのクラスに対して以下が成り立つ．
\[\sqrt{n}(\hat{\theta}(x^n)-\theta)\rightsquigarrow\mathcal{N}(0,I^{=1}(\theta))\]
ただし$\theta$は真の分布が$q(X)$のときに$q(X)=p(x;\theta)$となるように$p$を指定する$\theta$．$I(\theta)$はフィッシャー情報行列で$i,j$成分は以下で与えられる1．
\[\lim_{n\to\infty}\frac{1}{n}\mathbb{E}_{\theta}[-\frac{\partial^2\ln p(x^n;\theta)}{\partial \theta_i\partial \theta_j}]\]
また$y^n\rightsquigarrow y$は$\{y_0,\ldots,y_n\}$の確率分布が真の確率分布に法則収束することを指す（充分大きな$n$で分布が一致する意味）．
さらに，特に$\hat{\theta}$が不偏で，つまり$\mathbb{E}_{\theta}[\hat{\theta}(x_n)]=\theta$の時，分散はCramel-Raoの下限に達する（$\Sigma-I^{-1}(\theta)\geq 0$）．
MAP推定量 最尤推定量では$\theta$は一つの値であったが，これが確率分布から生成されていると考えたらどうだろうか．このように考えたとき$p(\theta)$を事前分布と呼ぶ．事後分布を
\[p(\theta|x^n)=\frac{p(x^n;\theta)p(\theta)}{\int p(x^n;\theta)p(\theta) d\theta}\]
と定める．そうしてMAP推定量を
\[\hat{\theta}_{\text{MAP}}:=\mathop{\text{argmax}}\limits_{\theta}p(\theta|x^n)\]
と定義する．
\[\ln p(\theta|x^n)=\ln p(x^n;\theta)+\ln p(\theta)+C\]
右辺第二項がなければ最尤推定量のときと変わらない．この$\ln p(\theta)$は従って正規化項として作用する．特に$p(\theta)\propto \exp(-\lambda f(\theta))$として
 $f(\theta)=||\theta||_1$のとき$p(\theta)$をLaplace分布 $f(\theta)=||\theta||_2$のとき$p(\theta)$をGauss分布  Bayse推定量 ベイズ推定量を
\[\hat{\theta}_{\text{Bayse}}:=\int\theta p(\theta|x^n)d\theta\]
により定める．
 個人的には$I$は単位行列に予約されているので使いたくないが，他でも見られるので一般的の使い方なのかもしれない．単位行列には$\mathbf{I}$などを使うのがよいのだろうか． [return]   </description>
    </item>
    
  </channel>
</rss>