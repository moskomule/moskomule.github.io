---
title: "ヘッセ行列の低ランク近似を用いた勾配法によるハイパーパラメータ最適化方法の提案"
date: 2023-03-01
tags: ["研究"]
---

本研究ではヘッセ行列を低ランク近似することで，勾配法を用いたハイパーパラメータ最適化が効率的に行えることを示しました．
実験的にはこの方法は設定の差異に対して鈍感であり，応用上使いやすいと期待されます．

以下のようなハイパーパラメータ最適化を考えます．

\\[ \min_\phi g(\theta^\ast, \phi)\quad\text{s.t.}\quad \theta^\ast\in\argmin_\theta f(\theta, \phi) \\]

ここで$f, g$は訓練損失，評価損失，$\theta, \phi$はモデルパラメータ，ハイパーパラメータで，右側がモデルの最適化，左側がハイパーパラメータの最適化を表しています．
このような問題は機械学習の実用においてはしばしば現れ，通常 $\phi$ の最適化はブラックボックス最適化によりますが，例えばベイズ最適化は $\phi$ の次元が高くなると効率が極端に低下します．
一部の問題ではハイパーパラメータの勾配（超勾配） $\nabla_\phi g$ を得ることができ，ハイパーパラメータ最適化を勾配法によって実現できます．

この超勾配は $\nabla_{\theta} f= 0$ 周辺では陰関数微分を用いて

\\[ \frac{\partial g}{\partial \phi}=\frac{\partial g}{\partial \theta}\left(\frac{\partial^2 f}{\partial \theta^2}\right)^{-1}\frac{\partial^ g}{\partial \theta \partial \phi}+\frac{\partial g}{\partial \phi} \\]

と表現することができます．
ヘッセ行列 $\frac{\partial^2 f}{\partial \theta^2}$ が現れますが，特にニューラルネットワークを考える場合にはヘッセ行列がパラメータ数の2乗個の要素を持つことになり，比較的小さなニューラルネットワークであってもメモリに保持できないほど大きくなってしまいます．
ヘッセ行列の逆行列であれば当然計算が困難です．
ここでヘッセ行列の逆行列自体は必要ではなく，ヘッセ行列の逆行列のベクトル積（**i**nverse **H**essian-**v**ector **p**roduct）だけが必要なことに着目し，ヘッセ行列のベクトル積（Hessian-vector product）を組み合わせてIHVPの近似を図ります．
なお，HVPは最近の自動微分ライブラリ（PyTorchやJAX）などではニューラルネットワークの評価程度の計算コストで得ることができます．

既存法では逐次的な近似方法を用いていました．
共役勾配法は正定値行列 $A$ に対して $\argmin_v\|Av-x\|$ を逐次計算し $v=A^{-1}x$ を近似します．
ノイマン級数法による近似では正定値行列 $\|A\|<1$ に対して $A^{-1}=I+A+A^2+\cdots$ を用いています．
共役勾配法は悪条件の行列の場合に収束が遅いことが知られており，ノイマン級数法はノルムを抑える必要があります．

本研究ではヘッセ行列を低ランク近似することでIHVPを効率的に計算します．
ニューラルネットワークのヘッセ行列では0に近い固有値が圧倒的多数で，大きな固有値が少ないため，低ランクだと思えば相性が良いと思われます．
低ランク近似にはNyström法を用い，適当に選んだヘッセ行列の列のインデックス集合を $K$として，

\\[ H\approx H_k=H_{[:,K]}H_{[K,K]}^{-1}H_{[:,K]}^\top \\]

とします．ここで $H_{[:,K]}$ はヘッセ行列の $K$ に対応する列を抽出したものです．
$H_k$ は低ランクで逆行列が存在しないため，対角成分に $\rho$ を足します．
するとWoodburyの行列恒等式が使えて，適当なベクトル $v$ に対するIHVPは

\\[ (\rho I+H_{[:, K]}H_{[K, K]}^{-1}H_{[:, K]}^\top)^{-1}v = \frac{1}{\rho}v-\frac{1}{\rho^2}H_{[:, K]}\left(H_{[K,K]}+\frac{1}{\rho}H_{[:, K]}^\top H_{[:, K]}\right)^{-1}H_{[:, K]}^\top v \\]

と表すことができます．
右辺では $k\times k$ 行列の逆行列が必要となりますが， $k\ll p$ なのでこれは簡単に得られます．
またこの右辺には逐次的な計算が含まれないので，GPU上では高速に計算が可能です．

